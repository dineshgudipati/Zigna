{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2a49b0d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wideformat7_function'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9296/2485689593.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m#import Format_functions_487_main\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# import Functions_remaining\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mwideformat7_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpytz\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'wideformat7_function'"
     ]
    }
   ],
   "source": [
    "# Import all the dependencies\n",
    "\n",
    "import getpass\n",
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "import re\n",
    "import warnings\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import traceback\n",
    "#import Format_functions_0911             # Importing the python functions file\n",
    "#import Format_functions_main\n",
    "#import Format_functions_487_main\n",
    "# import Functions_remaining\n",
    "import wideformat7_function\n",
    "import time\n",
    "import pytz\n",
    "# from Format_functions_487_main import*\n",
    "# from Functions_remaining import*\n",
    "from wideformat7_function import*\n",
    "#from Format_functions_0911 import *      # Importing all the functions from the Format_functions file\n",
    "#from Format_functions_main import *      # Importing all the functions from the Format_functions file\n",
    "from inspect import getmembers, isfunction\n",
    "#pip install pywin32\n",
    "#import multiprocessing as mp\n",
    "#import win32com.client as client\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b32a45ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\user'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be980e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "wf4_6_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c905c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Version of the packages\n",
    "\n",
    "print('Version Of Python: ' + sys.version)\n",
    "print('Version Of Pandas: ' + pd.__version__)\n",
    "print('Version Of Numpy: ' + np.version.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041b6374",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# STEP-1 : Listing out all the functions used in the Format_functions file \n",
    "\n",
    "functions_list = getmembers(wf4_6_function, isfunction)\n",
    "\n",
    "res = [list(ele) for ele in functions_list]    # convert list of tuples to list of list\n",
    "\n",
    "# To extract first and last element of each sublist in a list of lists\n",
    "def Extract(lst):\n",
    "    return [item[0] for item in lst]\n",
    "res_1 = Extract(res)           # res_1 list of functions present in the Functions_format file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1839899",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214e8ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# STEP-2 : Read the Hospital base file \n",
    "\n",
    "# Common path for the hosp_data file  \"C:\" + os.path.sep + \"Users\"+ os.path.sep + \"zigna\" + os.path.sep + \"Zigna AI Pvt Ltd\"+ os.path.sep + \"Zigna AI Corp - RightPx\"+ os.path.sep +\"Hospital Application_2022-03-09\" + os.path.sep + \n",
    "folder =  \"C:\" + os.path.sep + \"Users\"+ os.path.sep + \"zigna\" + os.path.sep + \"Zigna AI Pvt Ltd\"+ os.path.sep + \"Zigna AI Corp - RightPx\"+ os.path.sep +\"Hospital Application_2022-03-09\" + os.path.sep + \"Hospitals with shoppables Links Base file.xlsx\"                                \n",
    "\n",
    "Hosp_data = pd.read_excel(folder,sheet_name=\"Sheet1\")\n",
    "Hosp_data_1 = Hosp_data[[\"Hospital_Id\" ,\"Format_type\",\"Remarks\"]]             # Considering only the required columns\n",
    "Hosp_data_1 = Hosp_data_1.rename(columns = {'Hospital_Id': 'ID'})   # Changing the column name\n",
    "Hosp_data_1['ID']= Hosp_data_1['ID'].astype(str) \n",
    "#Converting ID type to string from int\n",
    "Hosp_data_1\n",
    "\n",
    "Hosp_data_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cafa7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample files\n",
    "\n",
    "\n",
    "\n",
    "# 487 sample files IDs \n",
    "\n",
    "rawfileID = pd.read_excel(r\"C:\\Users\\zigna\\Zigna AI Pvt Ltd\\Zigna AI Corp - RightPx\\Hospital Application_2022-03-09\\Automation_task\\4_6files.xlsx\",dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2146c4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawfileID\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "70236ca6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8145ff54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the raw file folder\n",
    "raw_file_path = \"C:\" + os.path.sep + \"Users\"+ os.path.sep + \"zigna\" + os.path.sep + \"Zigna AI Pvt Ltd\"+ os.path.sep + \"Zigna AI Corp - RightPx\"+ os.path.sep +\"Hospital Application_2022-03-09\" + os.path.sep +\"Structured files\" + os.path.sep + \"487 files list\" + os.path.sep + \"487 files\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18d9a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(raw_file_path)\n",
    "path = os.getcwd()\n",
    "files = os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c5ad6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6073363a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#List of Files \n",
    "mylinks=[]\n",
    "for i in files:\n",
    "    i\n",
    "    mylinks.append(i)\n",
    "mylinks  \n",
    "cols=['FILE_NAMES']\n",
    "#Creating the dataframe\n",
    "CNames=pd.DataFrame(mylinks,columns=cols)\n",
    "CNames\n",
    "\n",
    "# #extracting ids and type of file from CNames dataframe\n",
    "CNames[['ID']]=CNames.FILE_NAMES.str.extract('(\\d+)')\n",
    "CNames['Type'] = CNames.FILE_NAMES.str.split('.',expand= True)[1]\n",
    "# for i in CNames.FILE_NAMES:\n",
    "#     i\n",
    "#     CNames[['Type']] = i.split('.')[-1]\n",
    "#     print(CNames.columns)\n",
    "# CNames\n",
    "CNames\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe492b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "CNames1 = CNames.merge(rawfileID, how=\"inner\", left_on = \"ID\", right_on=\"Hospital_Id\")\n",
    "#CNames1.drop(['Format_Type'],axis=1, inplace=True)\n",
    "raw_file_count = len(CNames1)                       # Number of files in the raw file folder\n",
    "raw_file_count\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b769dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032d10e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "CNames1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f12c94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP-4 : Merging CNames and Hosp_data_1 using left join based on Hospital ID\n",
    "\n",
    "Final = CNames1.merge(Hosp_data_1, on='ID', how='left')  # Left join on bases of ID\n",
    "\n",
    "#Final = Final.drop ('Format_type_y', axis =1)\n",
    "\n",
    "Format_type_NA = [Final[Final['Format_type'].isna()]]   # Files that are not categorized from the raw file folder are taken into a list\n",
    "Final = Final[Final['Format_type'].notna()]             # Whereever Format type is Nan the rows are dropped and the files details are listed out \n",
    "Final[\"Error\"] = np.nan                                 # Creating an empty column \"Error\" to store the error occured\n",
    "Final[\"Structured_time(seconds)\"] = np.nan              # Creating an empty column \"Structured_time(seconds)\" to store the execution time for each file\n",
    "Final.drop(['Hospital_Id','Hospital_Name'],axis=1, inplace=True)\n",
    "files_categorized = len(Final)                          # categorized files count is taken from the raw files folder\n",
    "files_categorized\n",
    "\n",
    "\n",
    "Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed76aed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Final\n",
    "Final[\"Format_type\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382b789d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab382fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP-5 : If the format type matches with the list of functions then that function works\n",
    "\n",
    "# It iterates through each row in the dataframe and gives the output\n",
    "\n",
    "not_struc_files = []       # struc_failed\n",
    "struc_files = []            # struc_passed\n",
    "not_matched_files = []      # Creating an empty list for storing the files that are not structured or throwing error\n",
    "\n",
    "#error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e19d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(len(Final)):\n",
    "    y = Final[\"Format_type\"].iloc[i]                  # Iterates through each and every row \n",
    "#     if y in res_1:                                    # If that function presents in list of functions\n",
    "#         s = Final[\"Format_type\"].iloc[i]              # Iterating through each row in Format type\n",
    "#         x = globals()[s]                              # Converting the format type to function\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a31d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05aa935e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dd4032",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.DataFrame(Final.iloc[i:i+1,0:6])       # The entire column is passed into that particular function row by row\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfa83f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "    final = pd.DataFrame(Final.iloc[i:i+1,0:6])       # The entire column is passed into that particular function row by row\n",
    "        # \n",
    "        #x(final)\n",
    "        try:                                          # Used try and except and running the function\n",
    "            start = time.time()                       # start time\n",
    "            x(final)\n",
    "            end = time.time()                         # end time\n",
    "            code_exec = end-start\n",
    "            final[\"Structured_time(seconds)\"] = round(code_exec,2)\n",
    "            struc_files.append(final)                                      # executes the function  \n",
    "        except Exception as e:                                       # If it throws any error \n",
    "            final[\"Error\"] = e\n",
    "            not_struc_files.append(final)                     # All the files that are throwing errors are apppended into empty list created above\n",
    "            pass\n",
    "    else:\n",
    "        final = pd.DataFrame(Final.iloc[i:i+1,0:6])\n",
    "        not_matched_files.append(final)\n",
    "\n",
    "try:\n",
    "    not_struc_files = pd.concat(not_struc_files)                  # Finally we will concatenate all the files names and their IDs in a dataframe   \n",
    "    not_struc_files.insert(4,\"Status\",\"Structuring Failed\")\n",
    "except:\n",
    "    not_struc_files = pd.DataFrame()\n",
    "\n",
    "try:\n",
    "    struc_files = pd.concat(struc_files)\n",
    "    struc_files.insert(4,\"Status\",\"Structuring Passed\")\n",
    "except:\n",
    "    struc_files = pd.DataFrame()\n",
    "\n",
    "try:\n",
    "    not_matched_files = pd.concat(not_matched_files)\n",
    "    not_matched_files.insert(4,\"Status\",\"Function does not exist\")  \n",
    "except:\n",
    "    not_matched_files = pd.DataFrame()\n",
    "\n",
    "not_categorized_files = pd.concat(Format_type_NA)   \n",
    "files_not_categorized = len(not_categorized_files)             # not categorized files count is taken from raw files folder               \n",
    "not_categorized_files.insert(4,\"Status\",\"File not categorized\")\n",
    "\n",
    "# number_of_rows = len(struc_files) find length of index.\n",
    "# print(struc_files)\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b1ff5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44afc592",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_categorized_files = pd.concat(Format_type_NA)   \n",
    "files_not_categorized = len(not_categorized_files)             # not categorized files count is taken from raw files folder               \n",
    "not_categorized_files.insert(4,\"Status\",\"File not categorized\")\n",
    "\n",
    "report_list = [not_struc_files,struc_files,not_matched_files]  # All the report dataframes of each case are taken into a list\n",
    "report = pd.concat(report_list)                                # Got a final report by concatenating all of them\n",
    "report[\"Indian_datestamp\"] = pd.datetime.now().strftime(\"%d-%m-%Y\")\n",
    "usa_timezone = pytz.timezone('America/New_York')\n",
    "usa_time = pd.datetime.now(usa_timezone)\n",
    "report[\"US_datestamp\"] = usa_time.strftime(\"%d-%m-%Y\")\n",
    "\n",
    "passed_file_count = len(report[report['Status'] == 'Structuring Passed'])\n",
    "failed_file_count = len(report[report['Status'] == 'Structuring Failed'])\n",
    "not_matched_file_count = len(report[report['Status'] == 'Function does not exist'])\n",
    "\n",
    "#report[\"Structured_time(seconds)\"].sum() # Time taken to structure the files present in CNames\n",
    "\n",
    "body_text = \"Hi mam!\\nReport for structuring automation: \\nTotal number of raw_files in the folder are {}\\nNumber of files that are categorized in the raw files folder are {}\\nNumber of files that are not categorized in the raw files folder are {}\\nNumber of structured files are {}\\nNumber of not structured files are {}\\nNumber of files that are not matched with the existing formats are {}\\nThe attachment has the clear report of all the files.\"\n",
    "\n",
    "body_final_text = body_text.format(raw_file_count,files_categorized,files_not_categorized,passed_file_count,failed_file_count,not_matched_file_count)\n",
    "body_text.format(raw_file_count,files_categorized,files_not_categorized,passed_file_count,failed_file_count,not_matched_file_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c62933",
   "metadata": {},
   "outputs": [],
   "source": [
    "struc_report_path = \"C:\" + os.path.sep + \"Users\"+ os.path.sep + \"zigna\" + os.path.sep + \"Zigna AI Pvt Ltd\"+ os.path.sep + \"Zigna AI Corp - RightPx\"+ os.path.sep +\"Hospital Application_2022-03-09\" + os.path.sep +\"Automation_task\" + os.path.sep + \"Struc_reports\" + os.path.sep + \"structuring_report_42.csv\" \n",
    "#report.to_csv(struc_report_path.format(pd.datetime.now().strftime(\"%Y%m%d%H%M%S\")), index = False)\n",
    "try:\n",
    "    check = pd.read_csv(struc_report_path) # It checks for the report file in the particular path\n",
    "    report.to_csv(struc_report_path, mode='a', header=False, index = False) # If already a report file exists the current report will be appended to the same sheet\n",
    "except:\n",
    "    report.to_csv(struc_report_path,index= False) # If there is no particular file it creates one file\n",
    "\n",
    "# Move all the Raw files from raw_file folder into another folder once the status of the file is \"Structuring Passed\" \n",
    "file_name_list = report[\"FILE_NAMES\"].where(report[\"Status\"]==\"Structuring Passed\").dropna()\n",
    "file_name_list = file_name_list.tolist()\n",
    "\n",
    "#List all files in path\n",
    "for filename in os.listdir(raw_file_path):  \n",
    "    #If file is present in list\n",
    "    if filename in file_name_list:  \n",
    "        # assigned a common path in sharepoint to move the \"Structured raw files\"\n",
    "        try:\n",
    "            new_path = \"C:\" + os.path.sep + \"Users\"+ os.path.sep + zigna + os.path.sep + \"Zigna Analytics Private Limited\"+ os.path.sep + \"Zigna Analytics Private Limited Team Site - Hospital Application\"+ os.path.sep +\"Automation_task\" + os.path.sep + \"moved_sample20struc_files\"\n",
    "            full_file_path = os.path.join(path, filename)  # Old path\n",
    "            new_file_path = os.path.join(new_path,filename) # New path\n",
    "            #os.remove(full_file_path)\n",
    "            os.rename(full_file_path,new_file_path)          # To rename the old path with new path\n",
    "            #shutil.move(full_file_path,new_file_path)      # To move the file from old path to new path\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2704c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Create a folder with present datestamp to move all the outputs into it #############\n",
    "\n",
    "# create directory to shift all the outputs into that folder with that date timestamp\n",
    "directory = \"output_{}\".format(pd.datetime.now().strftime(\"%m%d%Y\"))\n",
    "    \n",
    "# Parent Directories path is outputs \n",
    "parent_dir = \"C:\" + os.path.sep + \"Users\"+ os.path.sep + \"zigna\" + os.path.sep + \"Zigna AI Pvt Ltd\"+ os.path.sep + \"Zigna AI Corp - RightPx\"+ os.path.sep +\"Hospital Application_2022-03-09\" + os.path.sep +\"Automation_task\" + os.path.sep + \"outputs\"\n",
    "    \n",
    "# Path is combined\n",
    "path = os.path.join(parent_dir, directory) \n",
    "os.makedirs(path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee53e694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All_outputs_path = \"C:\" + os.path.sep + \"Users\"+ os.path.sep + \"zigna\" + os.path.sep + \"Zigna AI Pvt Ltd\"+ os.path.sep + \"Zigna AI Corp - RightPx\"+ os.path.sep +\"Hospital Application_2022-03-09\" + os.path.sep +\"Automation_task\" + os.path.sep + \"outputs\"\n",
    "# os.chdir(All_outputs_path)\n",
    "\n",
    "# # Define the source and destination path\n",
    "# source = All_outputs_path\n",
    "# destination = path\n",
    "\n",
    "# extension = 'csv'\n",
    "# all_filenames = [i for i in glob.glob(f\"*{extension}\")]\n",
    "\n",
    "# for file in all_filenames:\n",
    "#     file_name = os.path.join(source, file)\n",
    "#     shutil.move(file_name, destination)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cc832f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs_path = path\n",
    "# os.chdir(outputs_path)\n",
    "\n",
    "# extension = 'csv'\n",
    "# all_filenames = [i for i in glob.glob(f\"*{extension}\")]\n",
    "\n",
    "# def x(f):\n",
    "#     try:\n",
    "#         try:\n",
    "#             z=pd.read_csv(f)\n",
    "#         except:\n",
    "#             z=pd.read_csv(f,encoding='utf-8')\n",
    "#     except:\n",
    "#         z=pd.read_csv(f,encoding='latin1')\n",
    "#     return z\n",
    "\n",
    "# combined_csv = pd.concat([ x(i) for i in all_filenames ])\n",
    "# output_path = path + os.path.sep + \"files_combined_{}.csv\" \n",
    "# combined_csv.to_csv(output_path.format(pd.datetime.now().strftime(\"%Y%m%d%H%M%S\")), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013f925b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
