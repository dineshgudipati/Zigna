{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ddfb4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "import warnings\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statistics import *\n",
    "import re\n",
    "import time\n",
    "from datetime import datetime\n",
    "# from fuzzywuzzy import fuzz\n",
    "# from fuzzywuzzy import process\n",
    "from difflib import SequenceMatcher\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1becd4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "payers_list_path = r\"D:\\Zigna AI Corp\\Zigna AI Corp - Hospital Application_2022-03-09\\Automation_task\\DHC and payerlist\\Renaming list (1).xlsx\"\n",
    "\n",
    "\n",
    "DF5=pd.read_excel(payers_list_path,sheet_name='2022_idvars')\n",
    "DF6=pd.read_excel(payers_list_path,sheet_name='2022_Renaming')\n",
    "# DF6['Hospital_ID'] = DF6['Hospital_ID'].astype(str).replace('\\.0', '', regex=True)\n",
    "# DF6['Hospital_ID'] = DF6['Hospital_ID'].replace(\"nan\",\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "971372da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Old Columns</th>\n",
       "      <th>New Columns</th>\n",
       "      <th>Hospital_ID</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eapg</td>\n",
       "      <td>eap</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eapg v3.14</td>\n",
       "      <td>eap</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eap</td>\n",
       "      <td>eap</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>visit apg</td>\n",
       "      <td>apg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>visit apg</td>\n",
       "      <td>apg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6219</th>\n",
       "      <td>primarycode</td>\n",
       "      <td>billing_code</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6220</th>\n",
       "      <td>shoppable bundled inpatient services** (apr-dr...</td>\n",
       "      <td>APRDRG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6221</th>\n",
       "      <td>apc</td>\n",
       "      <td>apc_codes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6222</th>\n",
       "      <td>medicare cptÂ®/hcpcs</td>\n",
       "      <td>cpt_hcpcs_drg_icdx10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6223</th>\n",
       "      <td>billing_revenue_service_code</td>\n",
       "      <td>cpt_hcpcs_drg_icdx10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6224 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Old Columns           New Columns  \\\n",
       "0                                                  eapg                   eap   \n",
       "1                                            eapg v3.14                   eap   \n",
       "2                                                   eap                   eap   \n",
       "3                                             visit apg                   apg   \n",
       "4                                             visit apg                   apg   \n",
       "...                                                 ...                   ...   \n",
       "6219                                        primarycode          billing_code   \n",
       "6220  shoppable bundled inpatient services** (apr-dr...                APRDRG   \n",
       "6221                                                apc             apc_codes   \n",
       "6222                               medicare cptÂ®/hcpcs  cpt_hcpcs_drg_icdx10   \n",
       "6223                       billing_revenue_service_code  cpt_hcpcs_drg_icdx10   \n",
       "\n",
       "      Hospital_ID Unnamed: 3  \n",
       "0             NaN        NaN  \n",
       "1             NaN        NaN  \n",
       "2             NaN        NaN  \n",
       "3             NaN        NaN  \n",
       "4             NaN        NaN  \n",
       "...           ...        ...  \n",
       "6219          NaN        NaN  \n",
       "6220          NaN        NaN  \n",
       "6221          NaN        NaN  \n",
       "6222          NaN        NaN  \n",
       "6223          NaN        NaN  \n",
       "\n",
       "[6224 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4471061b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF8=pd.read_excel(payers_list_path,sheet_name='Dropping columns')\n",
    "folder = pd.read_excel (r\"D:\\Zigna AI Corp\\Zigna AI Corp - Hospital Application_2022-03-09\\shoppable services data files\\Research team downloaded\\2022\\Hospitals with shoppables Links Base file(Final).xlsx\", sheet_name = \"Raw file\")\n",
    "df7 = folder[[\"Hospital_Id\",\"iloc\"]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "DF6['Hospital_ID'] = DF6['Hospital_ID'].astype(str).replace('\\.0', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "727fdfbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hospital_Id</th>\n",
       "      <th>iloc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5267</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2654</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3601</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3604</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4426</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6313</th>\n",
       "      <td>4615</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6314</th>\n",
       "      <td>4600</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6315</th>\n",
       "      <td>4599</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6316</th>\n",
       "      <td>4854</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6317</th>\n",
       "      <td>6081</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6318 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Hospital_Id  iloc\n",
       "0            5267   NaN\n",
       "1            2654   0.0\n",
       "2            3601   0.0\n",
       "3            3604   0.0\n",
       "4            4426   0.0\n",
       "...           ...   ...\n",
       "6313         4615   NaN\n",
       "6314         4600   NaN\n",
       "6315         4599   NaN\n",
       "6316         4854   5.0\n",
       "6317         6081   NaN\n",
       "\n",
       "[6318 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7eaa46ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def df_column_uniquify(df):\n",
    "    df_columns = df.columns\n",
    "    new_columns = []\n",
    "    for item in df_columns:\n",
    "        counter = 0\n",
    "        newitem = item\n",
    "        while newitem in new_columns:\n",
    "            counter += 1\n",
    "            newitem = \"{}_{}\".format(item, counter)\n",
    "        new_columns.append(newitem)\n",
    "    df.columns = new_columns\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "810a2b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "############# wideFormat1018 #############\n",
    "def wideFormat1018(CNames):\n",
    "    global df7\n",
    "    \n",
    "    Combined_data = []\n",
    "    combined_final = []\n",
    "    non_prep_data = []\n",
    "    #Getting the details as list from files\n",
    "    for k in CNames.itertuples(index=False):\n",
    "        f=k[0] \n",
    "        #Checking the file type- xlsx   \n",
    "        if k[2]== 'csv':\n",
    "            try:\n",
    "                DF_FINAL=pd.read_csv(f)\n",
    "            except:\n",
    "                DF_FINAL=pd.read_csv(f,encoding='latin1')\n",
    "\n",
    "            non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        elif k[2]== 'xlsx':\n",
    "            sheet_to = pd.read_excel(f,sheet_name=None,dtype=str,header=None)\n",
    "\n",
    "            for sh in sheet_to.keys():\n",
    "\n",
    "                DF_FINAL = pd.read_excel(f,sheet_name=sh,dtype=str)\n",
    "                print(sh)\n",
    "                non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        for j in df2.itertuples(index=False):\n",
    "            if str(k[1]) == str(j[0]):\n",
    "                s = j[1]\n",
    "\n",
    "        for DF_FINAL in non_prep_data:\n",
    "            try:\n",
    "                if DF_FINAL.iloc[:, [s]].empty == False:\n",
    "                    DF_10=DF_FINAL.iloc[:, [s]]    \n",
    "                    m=0\n",
    "                    c=0\n",
    "\n",
    "                    #Getting the count of  empty rows\n",
    "                    for index, row in DF_10.iterrows():\n",
    "                        if(pd.notnull(row[0])): \n",
    "                            m=m+1\n",
    "                            break\n",
    "                        else:\n",
    "                            c=c+1\n",
    "\n",
    "                    if c==0:\n",
    "                    #This Case works when description is in one row\n",
    "                        if \"Unnamed: 5\" in DF_10:\n",
    "                            DF_FINAL.columns=DF_FINAL.iloc[0]\n",
    "                            FINAL=DF_FINAL.drop([c])\n",
    "                            FINAL['id']=k[1]\n",
    "                            for i in FINAL.columns:\n",
    "                                x = str(i).lower().strip()\n",
    "                                FINAL=FINAL.rename(columns= {i:x})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                            for k in CNames.itertuples(index=False):\n",
    "                                for r in DF6.itertuples(index=False):\n",
    "                                    if str(k[1]) == str(r[2]):\n",
    "                                        try:\n",
    "                                            for i in FINAL.columns.tolist():\n",
    "                                                if str(i) == str(r[0]):\n",
    "                                                    FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                                        except:\n",
    "                                            pass\n",
    "                            for i in FINAL.columns.tolist():\n",
    "\n",
    "                                for r in DF6.itertuples(index=False):\n",
    "\n",
    "\n",
    "\n",
    "                                    if str(r[2]) == \"nan\" :\n",
    "\n",
    "                                        if str(i) == str(r[0]):\n",
    "                                            FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                            combined_final.append(FINAL)\n",
    "                        else:\n",
    "                            #This Case works when description is not found\n",
    "                            FINAL=DF_FINAL\n",
    "                            FINAL['id']=k[1]\n",
    "                            for i in FINAL.columns:\n",
    "                                x = str(i).lower().strip()\n",
    "                                FINAL=FINAL.rename(columns= {i:x})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                            for k in CNames.itertuples(index=False):\n",
    "                                for r in DF6.itertuples(index=False):\n",
    "                                    if str(k[1]) == str(r[2]):\n",
    "                                        try:\n",
    "                                            for i in FINAL.columns.tolist():\n",
    "                                                if str(i) == str(r[0]):\n",
    "                                                    FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                                        except:\n",
    "                                            pass\n",
    "                            for i in FINAL.columns.tolist():\n",
    "\n",
    "                                for r in DF6.itertuples(index=False):\n",
    "\n",
    "\n",
    "\n",
    "                                    if str(r[2]) == \"nan\" :\n",
    "\n",
    "                                        if str(i) == str(r[0]):\n",
    "                                            FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                            combined_final.append(FINAL)\n",
    "\n",
    "                    elif c>=1:\n",
    "                        #This Case works when description is more than 1 row\n",
    "                        #Dropping 'c' rows\n",
    "                        DF_11=DF_FINAL.iloc[c:]\n",
    "                        #row values as column names\n",
    "                        DF_11.columns=DF_11.iloc[0]\n",
    "                        #Dropping the row\n",
    "                        FINAL=DF_11.drop([c])\n",
    "                        FINAL['id']=k[1]\n",
    "\n",
    "                        if CNames['id'].isin(['3295']).any():\n",
    "                            try:\n",
    "                                FINAL.drop(['Description'], axis = 1,inplace = True)\n",
    "                            except:\n",
    "                                pass\n",
    "                        for i in FINAL.columns:\n",
    "                            x = str(i).lower().strip()\n",
    "                            FINAL=FINAL.rename(columns= {i:x})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                        for k in CNames.itertuples(index=False):\n",
    "                            for r in DF6.itertuples(index=False):\n",
    "                                if str(k[1]) == str(r[2]):\n",
    "                                    try:\n",
    "                                        for i in FINAL.columns.tolist():\n",
    "                                            if str(i) == str(r[0]):\n",
    "                                                FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                                    except:\n",
    "                                        pass\n",
    "                        for i in FINAL.columns.tolist():\n",
    "\n",
    "                            for r in DF6.itertuples(index=False):\n",
    "\n",
    "\n",
    "\n",
    "                                if str(r[2]) == \"nan\" :\n",
    "\n",
    "                                    if str(i) == str(r[0]):\n",
    "                                        FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                        combined_final.append(FINAL)\n",
    "                    else:\n",
    "                        None\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass\n",
    "        try:\n",
    "            FINAL = pd.concat(combined_final)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            FINAL = FINAL.loc[:, FINAL.columns.notnull()]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            for col in FINAL.columns:\n",
    "                if col =='unnamed: 0':\n",
    "                    FINAL=FINAL.drop([\"unnamed: 0\"],axis=1)\n",
    "                else:\n",
    "                       None\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        Search_List = list(DF8[\"Dropping columns\"])\n",
    "        #dropping columns\n",
    "        FINAL= FINAL.drop(columns=[col for col in FINAL if col  in Search_List])\n",
    "\n",
    "        column_list = ['inpatient_outpatient']\n",
    "        for col in column_list:\n",
    "            if col not in FINAL.columns:\n",
    "                FINAL[col] = ' ' \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        df2=FINAL\n",
    "        df2 = df_column_uniquify(df2)\n",
    "        #Required format - variable list\n",
    "        Col_list = list(DF5[\"Columns\"])\n",
    "        df3=df2.melt(id_vars=[col for col in df2 if col in Col_list],var_name=\"name\",value_name='cost')\n",
    "        #df3=df1.melt(id_vars=['ID','Description','Cpt Code','Rev_Cd','Units'],var_name=\"Name\",value_name='Cost')\n",
    "\n",
    "\n",
    "\n",
    "        df4=df3\n",
    "        df4=df4[df4['cost'].notnull()]\n",
    "        df4=df4[df4['name'].notnull()]\n",
    "        #Dropping_columns=['Not offered','Not Contracted','N/A','Not a covered service','Not Offered','Not contracted','Not a covered service','N/A']\n",
    "        #df4 = df4[~df4['Cost'].isin(Dropping_columns)]\n",
    "        df4\n",
    "        Combined_data.append(df4)\n",
    "    Combined_data = pd.concat(Combined_data)\n",
    "\n",
    "    Combined_data\n",
    "    Combined_data.drop_duplicates()\n",
    "    #Combined_data[\"id\"]=Combined_data.id.astype('int64')\n",
    "    #Combined_data.dtypes\n",
    "\n",
    "    #Joining both hospital data with shoppable data by ID\n",
    "    #Sample_output=pd.merge(left=DHC_Hosp_data1, right=Combined_data,how='inner',left_on=['Hospital_Id'],right_on=['id'])\n",
    "    Sample_output = Combined_data\n",
    "    #Dropping the columns\n",
    "    #Sample_output.drop([\"id\"], axis = 1, inplace = True)\n",
    "    #Sample_output['inpatient-outpatient'] = np.where((Sample_output['inpatient-outpatient'] ==' ') & (Sample_output['name'].str.contains('inpatient/outpatient/drug')) , 'IP/OP', Sample_output['inpatient-outpatient'])\n",
    "    #Sample_output['inpatient-outpatient'] = np.where((Sample_output['inpatient-outpatient'] ==' ') & (Sample_output['name'].str.contains('inpatient/outpatient/drug')) , 'IP/OP', Sample_output['inpatient-outpatient'])\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains('ip & op')) , 'IP & OP', Sample_output['inpatient_outpatient'])\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains('ip & op')) , 'IP & OP', Sample_output['inpatient_outpatient'])\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains('ip/op')) , 'Inpatient', Sample_output['inpatient_outpatient'])\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains('ip/op')) , 'Outpatient', Sample_output['inpatient_outpatient'])\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains('inpatient')) , 'Inpatient', Sample_output['inpatient_outpatient'])\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains('outpatient')) , 'Outpatient', Sample_output['inpatient_outpatient'])\n",
    "    #Sample_output['inpatient-outpatient'] = np.where((Sample_output['inpatient-outpatient'] ==' ') & (Sample_output['name'].str.contains('ip')) , 'Inpatient', Sampl\n",
    "\n",
    "\n",
    "    output_path = r\"C:\\Users\\User\\Zigna AI Corp\\Zigna AI Corp - RightPx\\Hospital Application_2022-03-09\\Automation_task\\outputs\\Wideformat1018_{}.csv\"\n",
    "    Sample_output.to_csv(output_path.format((k[1])), index=False)\n",
    "    return Sample_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcadc521",
   "metadata": {},
   "outputs": [],
   "source": [
    "################# wideFormat1019 ###############\n",
    "def wideFormat1019(CNames):\n",
    "    global df7\n",
    "    \n",
    "    Combined_data = []\n",
    "    combined_final = []\n",
    "    non_prep_data = []\n",
    "    #Getting the details as list from files\n",
    "    for k in CNames.itertuples(index=False):\n",
    "        f=k[0] \n",
    "        #Checking the file type- xlsx   \n",
    "        if k[2]== 'csv':\n",
    "            try:\n",
    "                DF_FINAL=pd.read_csv(f)\n",
    "            except:\n",
    "                DF_FINAL=pd.read_csv(f,encoding='latin1')\n",
    "\n",
    "            non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        elif k[2]== 'xlsx':\n",
    "            sheet_to = pd.read_excel(f,sheet_name=None,dtype=str,header=None)\n",
    "\n",
    "            for sh in sheet_to.keys():\n",
    "\n",
    "                DF_FINAL = pd.read_excel(f,sheet_name=sh,dtype=str)\n",
    "                print(sh)\n",
    "                non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        for j in df7.itertuples(index=False):\n",
    "            if str(k[1]) == str(j[0]):\n",
    "                s = j[1]\n",
    "\n",
    "        for DF_FINAL in non_prep_data:\n",
    "            try:\n",
    "                if DF_FINAL.iloc[:, [s]].empty == False:\n",
    "                    DF_10=DF_FINAL.iloc[:, [s]]    \n",
    "                    m=0\n",
    "                    c=0\n",
    "\n",
    "                    #Getting the count of  empty rows\n",
    "                    for index, row in DF_10.iterrows():\n",
    "                        if(pd.notnull(row[0])): \n",
    "                            m=m+1\n",
    "                            break\n",
    "                        else:\n",
    "                            c=c+1\n",
    "\n",
    "                    if c==0:\n",
    "                    #This Case works when description is in one row\n",
    "                        if \"Unnamed: 5\" in DF_10:\n",
    "                            DF_FINAL.columns=DF_FINAL.iloc[0]\n",
    "                            FINAL=DF_FINAL.drop([c])\n",
    "                            FINAL['id']=k[1]\n",
    "                            for i in FINAL.columns:\n",
    "                                x = str(i).lower().strip()\n",
    "                                FINAL=FINAL.rename(columns= {i:x})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                            for k in CNames.itertuples(index=False):\n",
    "                                for r in DF6.itertuples(index=False):\n",
    "                                    if str(k[1]) == str(r[2]):\n",
    "                                        try:\n",
    "                                            for i in FINAL.columns.tolist():\n",
    "                                                if str(i) == str(r[0]):\n",
    "                                                    FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                                        except:\n",
    "                                            pass\n",
    "                            for i in FINAL.columns.tolist():\n",
    "\n",
    "                                for r in DF6.itertuples(index=False):\n",
    "\n",
    "\n",
    "\n",
    "                                    if str(r[2]) == \"nan\" :\n",
    "\n",
    "                                        if str(i) == str(r[0]):\n",
    "                                            FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                            combined_final.append(FINAL)\n",
    "                        else:\n",
    "                            #This Case works when description is not found\n",
    "                            FINAL=DF_FINAL\n",
    "                            FINAL['id']=k[1]\n",
    "                            for i in FINAL.columns:\n",
    "                                x = str(i).lower().strip()\n",
    "                                FINAL=FINAL.rename(columns= {i:x})\n",
    "\n",
    "                            for k in CNames.itertuples(index=False):\n",
    "                                for r in DF6.itertuples(index=False):\n",
    "                                    if str(k[1]) == str(r[2]):\n",
    "                                        try:\n",
    "                                            for i in FINAL.columns.tolist():\n",
    "                                                if str(i) == str(r[0]):\n",
    "                                                    FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                                        except:\n",
    "                                            pass\n",
    "                            for i in FINAL.columns.tolist():\n",
    "\n",
    "                                for r in DF6.itertuples(index=False):\n",
    "\n",
    "\n",
    "\n",
    "                                    if str(r[2]) == \"nan\" :\n",
    "\n",
    "                                        if str(i) == str(r[0]):\n",
    "                                            FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                            combined_final.append(FINAL)\n",
    "\n",
    "                    elif c>=1:\n",
    "                        DF_11=DF_FINAL.iloc[c:]\n",
    "                        #DF_111 = DF_11\n",
    "                        #print(DF_11)\n",
    "                        list2=[\"Shoppable Services Effective January 1,2021 St. Catherine's  Rehabilitation Hospital\",'Shoppable Service','CMG','Charge Code','Description',\"Medicine and Surgery Services\",\"Radiology Services\",\"Laboratory and Pathology Services\",\"Evaluation and Mangagement Services\"]\n",
    "\n",
    "                        DF_11[\"ROW\"] = DF_11.iloc[:,0].isin(list2)\n",
    "                        n =0\n",
    "                        for index, row in DF_11['ROW'].iteritems():\n",
    "                            if row == True:\n",
    "\n",
    "                                DF_11['ROW'][index] = n\n",
    "                            else:\n",
    "\n",
    "                                DF_11['ROW'][index] = np.nan\n",
    "\n",
    "                        DF_11['ROW'].fillna(method='ffill', inplace=True)\n",
    "\n",
    "                        List_ids=[]\n",
    "                        for i in DF_11['ROW']:\n",
    "                            List_ids.append(i)\n",
    "\n",
    "                            List_ids=list(set(List_ids))\n",
    "                        list2 = pd.DataFrame()\n",
    "                        for i in List_ids:\n",
    "                            list2 = DF_11[DF_11['ROW']==i]\n",
    "                            list2 = list2.drop(['ROW'],axis=1)\n",
    "                            list2.columns = list2.iloc[0]\n",
    "                            list2 = list2.iloc[1:]\n",
    "                            list2 = list2.dropna(how='all',axis=1)\n",
    "                            list2 = list2.dropna(how='all',axis=0)                    \n",
    "                            list2 = list2.reset_index(drop=True)\n",
    "                            list2['id']=k[1]\n",
    "                            for i in list2.columns:\n",
    "                                x = str(i).lower().strip()\n",
    "                                list2=list2.rename(columns= {i:x})   \n",
    "                            #print(DF_FINAL1.columns)\n",
    "                            for i in list2.columns.tolist():\n",
    "                                for r in DF6.itertuples(index=False):\n",
    "                                    if str(i) == str(r[0]):\n",
    "                                        list2.rename(columns={i:r[1]}, inplace=True)\n",
    "                            combined_final.append(list2)\n",
    "                            FINAL = pd.concat(combined_final) \n",
    "    #                    Combined_data.append(FINAL)\n",
    "\n",
    "                else:\n",
    "                    None \n",
    "\n",
    "\n",
    "\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass\n",
    "        try:\n",
    "            FINAL = pd.concat(combined_final)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            FINAL = FINAL.loc[:, FINAL.columns.notnull()]\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            FINAL = FINAL.loc[:, ~FINAL.columns.str.contains('^unnamed')]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            for col in FINAL.columns:\n",
    "                if col =='unnamed: 0':\n",
    "                    FINAL=FINAL.drop([\"unnamed: 0\"],axis=1)\n",
    "                else:\n",
    "                       None\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        Search_List = list(DF8[\"Dropping columns\"])\n",
    "        #dropping columns\n",
    "        FINAL= FINAL.drop(columns=[col for col in FINAL if col in Search_List])\n",
    "\n",
    "        #for r in DF6.itertuples(index=False):\n",
    "            #FINAL.rename(columns={r[0]:r[1]}, inplace=True)\n",
    "            #Search_List = list(DF8[\"Dropping columns\"])\n",
    "            #dropping columns\n",
    "            #FINAL= FINAL.drop(columns=[col for col in FINAL if col in Search_List])\n",
    "        #Checking the  Inpatient/Outpatient column exists or not\n",
    "        column_list = ['inpatient_outpatient']\n",
    "        for col in column_list:\n",
    "            if col not in FINAL.columns:\n",
    "                FINAL[col] = ' '\n",
    "\n",
    "\n",
    "        df2=FINAL\n",
    "        df2 = df_column_uniquify(df2)\n",
    "        #Required format - variable list\n",
    "        Col_list = list(DF5[\"Columns\"])\n",
    "        df3=df2.melt(id_vars=[col for col in df2 if col in Col_list],var_name=\"name\",value_name='cost')\n",
    "        #df3=df1.melt(id_vars=['ID','Description','Cpt Code','Rev_Cd','Units'],var_name=\"Name\",value_name='Cost')\n",
    "\n",
    "\n",
    "        df4=df3\n",
    "        df4=df4[df4['cost'].notnull()]\n",
    "\n",
    "        #Dropping_columns=['Not offered','Not Contracted','N/A','Not a covered service','Not Offered','Not contracted','Not a covered service','N/A']\n",
    "        #df4 = df4[~df4['Cost'].isin(Dropping_columns)]\n",
    "        df4\n",
    "        Combined_data.append(df4)\n",
    "    Combined_data = pd.concat(Combined_data)\n",
    "    Combined_data = Combined_data.drop_duplicates()      \n",
    "    Combined_data\n",
    "\n",
    "    output_path = r\"C:\\Users\\User\\Zigna AI Corp\\Zigna AI Corp - RightPx\\Hospital Application_2022-03-09\\Automation_task\\outputs\\Wideformat1019_{}.csv\"\n",
    "    Combined_data.to_csv(output_path.format((k[1])), index=False)\n",
    "    return Combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a038b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "################ wideFormat1020 ##################\n",
    "def wideFormat1020(CNames):\n",
    "    global df7\n",
    "    \n",
    "    Combined_data = []\n",
    "    combined_final = []\n",
    "    non_prep_data = []\n",
    "    #Getting the details as list from files\n",
    "    for k in CNames.itertuples(index=False):\n",
    "        f=k[0] \n",
    "        #Checking the file type- xlsx   \n",
    "        if k[2]== 'csv':\n",
    "            try:\n",
    "                DF_FINAL=pd.read_csv(f)\n",
    "            except:\n",
    "                DF_FINAL=pd.read_csv(f,encoding='latin1')\n",
    "\n",
    "            non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        elif k[2]== 'xlsx':\n",
    "            sheet_to = pd.read_excel(f,sheet_name=None,dtype=str,header=None)\n",
    "\n",
    "            for sh in sheet_to.keys():\n",
    "\n",
    "                DF_FINAL = pd.read_excel(f,sheet_name=sh,dtype=str)\n",
    "                print(sh)\n",
    "                non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        for j in df7.itertuples(index=False):\n",
    "            if str(k[1]) == str(j[0]):\n",
    "                s = j[1]\n",
    "\n",
    "        for DF_FINAL in non_prep_data:\n",
    "            try:\n",
    "                if DF_FINAL.iloc[:, [s]].empty == False:\n",
    "                    DF_10=DF_FINAL.iloc[:, [s]]    \n",
    "                    m=0\n",
    "                    c=0\n",
    "\n",
    "                    #Getting the count of  empty rows\n",
    "                    for index, row in DF_10.iterrows():\n",
    "                        if(pd.notnull(row[0])): \n",
    "                            m=m+1\n",
    "                            break\n",
    "                        else:\n",
    "                            c=c+1\n",
    "\n",
    "                    if c==0:\n",
    "                    #This Case works when description is in one row\n",
    "                        if \"Unnamed: 5\" in DF_10:\n",
    "                            DF_FINAL.columns=DF_FINAL.iloc[0]\n",
    "                            FINAL=DF_FINAL.drop([c])\n",
    "                            FINAL['id']=k[1]\n",
    "\n",
    "                            FINAL\n",
    "                        else:\n",
    "                            #This Case works when description is not found\n",
    "                            FINAL=DF_FINAL\n",
    "                            FINAL['id']=k[1]\n",
    "\n",
    "                            FINAL\n",
    "\n",
    "                    elif c>=1:\n",
    "                        #This Case works when description is more than 1 row\n",
    "                        #Dropping 'c' rows\n",
    "                        DF_11=DF_FINAL.iloc[c:]\n",
    "                        #row values as column names\n",
    "                        DF_11.columns=DF_11.iloc[0]\n",
    "                        #Dropping the row\n",
    "                        FINAL=DF_11.drop([c])\n",
    "                        FINAL['id']=k[1]\n",
    "\n",
    "\n",
    "\n",
    "                        FINAL\n",
    "                    else:\n",
    "                        None\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass\n",
    "        try:\n",
    "            FINAL = pd.concat(combined_final)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            FINAL = FINAL.loc[:, FINAL.columns.notnull()]\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            FINAL = FINAL.loc[:, ~FINAL.columns.str.contains('^unnamed')]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            for col in FINAL.columns:\n",
    "                if col =='unnamed: 0':\n",
    "                    FINAL=FINAL.drop([\"unnamed: 0\"],axis=1)\n",
    "                else:\n",
    "                       None\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "        for i in FINAL.columns:\n",
    "            x = str(i).lower().strip()\n",
    "            FINAL=FINAL.rename(columns= {i:x})\n",
    "        for k in CNames.itertuples(index=False):\n",
    "            for r in DF6.itertuples(index=False):\n",
    "                if str(k[1]) == str(r[2]):\n",
    "                    try:\n",
    "                        for i in FINAL.columns.tolist():\n",
    "                            if str(i) == str(r[0]):\n",
    "                                FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                    except:\n",
    "                        pass\n",
    "        for i in FINAL.columns.tolist():\n",
    "            for r in DF6.itertuples(index=False):\n",
    "                if str(r[2]) == \"nan\" :\n",
    "                    if str(i) == str(r[0]):\n",
    "                        FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "\n",
    "        Search_List = list(DF8[\"Dropping columns\"])\n",
    "        #dropping columns\n",
    "        FINAL= FINAL.drop(columns=[col for col in FINAL if col  in Search_List])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        column_list = ['inpatient_outpatient']\n",
    "        for col in column_list:\n",
    "            if col not in FINAL.columns:\n",
    "                FINAL[col] = ' ' \n",
    "\n",
    "        FINAL['cpt_hcpcs'].fillna(method='ffill', inplace=True)\n",
    "        FINAL['description'].fillna(method='ffill', inplace=True)\n",
    "        try:\n",
    "            FINAL=FINAL[~(FINAL[\"cpt_hcpcs\"]=='Professional Services not provided by hospital/may be billed separately')]\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            cols=[i for i in FINAL.columns if i not in [\"description\",\"cpt_hcpcs\",'hospital_Id']]\n",
    "            for col in cols:\n",
    "                FINAL[col] = pd.to_numeric(FINAL[col], errors='coerce')\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        FINAL[\"lineitem_cnt\"] = FINAL.groupby([\"description\",\"cpt_hcpcs\"])[\"cpt_hcpcs\"].transform('count')\n",
    "        FINAL[\"lineitem_cnt\"]=FINAL[\"lineitem_cnt\"]\n",
    "\n",
    "        FINAL=FINAL.groupby(['description','cpt_hcpcs','lineitem_cnt','hospital_Id']).aggregate(['sum']).reset_index()\n",
    "        FINAL.columns = FINAL.columns.get_level_values(0)\n",
    "\n",
    "\n",
    "\n",
    "        df2=FINAL\n",
    "        df2 = df_column_uniquify(df2)\n",
    "        #Required format - variable list\n",
    "        Col_list = list(DF5[\"Columns\"])\n",
    "        df3=df2.melt(id_vars=[col for col in df2 if col in Col_list],var_name=\"name\",value_name='cost')\n",
    "        #df3=df1.melt(id_vars=['ID','Description','Cpt Code','Rev_Cd','Units'],var_name=\"Name\",value_name='Cost')\n",
    "\n",
    "\n",
    "\n",
    "        df4=df3\n",
    "        df4=df4[df4['cost'].notnull()]\n",
    "        df4=df4[df4['name'].notnull()]\n",
    "        #Dropping_columns=['Not offered','Not Contracted','N/A','Not a covered service','Not Offered','Not contracted','Not a covered service','N/A']\n",
    "        #df4 = df4[~df4['Cost'].isin(Dropping_columns)]\n",
    "        df4\n",
    "        Combined_data.append(df4)\n",
    "    Combined_data = pd.concat(Combined_data)\n",
    "\n",
    "    Combined_data\n",
    "    Combined_data.drop_duplicates()\n",
    "    #Combined_data[\"id\"]=Combined_data.id.astype('int64')\n",
    "    #Combined_data.dtypes\n",
    "\n",
    "    #Joining both hospital data with shoppable data by ID\n",
    "    #Sample_output=pd.merge(left=DHC_Hosp_data1, right=Combined_data,how='inner',left_on=['Hospital_Id'],right_on=['id'])\n",
    "    Sample_output = Combined_data\n",
    "    #Dropping the columns\n",
    "    #Sample_output.drop([\"id\"], axis = 1, inplace = True)\n",
    "    #Sample_output['inpatient-outpatient'] = np.where((Sample_output['inpatient-outpatient'] ==' ') & (Sample_output['name'].str.contains('inpatient/outpatient/drug')) , 'IP/OP', Sample_output['inpatient-outpatient'])\n",
    "    #Sample_output['inpatient-outpatient'] = np.where((Sample_output['inpatient-outpatient'] ==' ') & (Sample_output['name'].str.contains('inpatient/outpatient/drug')) , 'IP/OP', Sample_output['inpatient-outpatient'])\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains('ip & op')) , 'IP & OP', Sample_output['inpatient_outpatient'])\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains('ip & op')) , 'IP & OP', Sample_output['inpatient_outpatient'])\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains('ip/op')) , 'Inpatient', Sample_output['inpatient_outpatient'])\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains('ip/op')) , 'Outpatient', Sample_output['inpatient_outpatient'])\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains('inpatient')) , 'Inpatient', Sample_output['inpatient_outpatient'])\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains('outpatient')) , 'Outpatient', Sample_output['inpatient_outpatient'])\n",
    "    #Sample_output['inpatient-outpatient'] = np.where((Sample_output['inpatient-outpatient'] ==' ') & (Sample_output['name'].str.contains('ip')) , 'Inpatient', Sampl\n",
    "\n",
    "\n",
    "    output_path = r\"C:\\Users\\User\\Zigna AI Corp\\Zigna AI Corp - RightPx\\Hospital Application_2022-03-09\\Automation_task\\outputs\\Wideformat1020_{}.csv\"\n",
    "    Sample_output.to_csv(output_path.format((k[1])), index=False)\n",
    "    return Sample_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7f13d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "################# wideFormat1009 ################\n",
    "def wideFormat10009(CNames):\n",
    "    global df7\n",
    "    \n",
    "    Combined_data = []\n",
    "    combined_final = []\n",
    "    non_prep_data = []\n",
    "    #Getting the details as list from files\n",
    "    for k in CNames.itertuples(index=False):\n",
    "        f=k[0] \n",
    "        #Checking the file type- xlsx   \n",
    "        if k[2]== 'csv':\n",
    "            try:\n",
    "                DF_FINAL=pd.read_csv(f)\n",
    "            except:\n",
    "                DF_FINAL=pd.read_csv(f,encoding='latin1')\n",
    "\n",
    "            non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        elif k[2]== 'xlsx':\n",
    "            sheet_to = pd.read_excel(f,sheet_name=None,dtype=str,header=None)\n",
    "\n",
    "            for sh in sheet_to.keys():\n",
    "\n",
    "                DF_FINAL = pd.read_excel(f,sheet_name=sh,dtype=str)\n",
    "                print(sh)\n",
    "                non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        for j in df7.itertuples(index=False):\n",
    "            if str(k[1]) == str(j[0]):\n",
    "                s = j[1]\n",
    "\n",
    "        for DF_FINAL in non_prep_data:\n",
    "            try:\n",
    "                if DF_FINAL.iloc[:, [s]].empty == False:\n",
    "                    DF_10=DF_FINAL.iloc[:, [s]]    \n",
    "                    m=0\n",
    "                    c=0\n",
    "\n",
    "                    #Getting the count of  empty rows\n",
    "                    for index, row in DF_10.iterrows():\n",
    "                        if(pd.notnull(row[0])): \n",
    "                            m=m+1\n",
    "                            break\n",
    "                        else:\n",
    "                            c=c+1\n",
    "\n",
    "                    if c==0:\n",
    "                    #This Case works when description is in one row\n",
    "                        if \"Unnamed: 5\" in DF_10:\n",
    "                            DF_FINAL.columns=DF_FINAL.iloc[0]\n",
    "                            FINAL=DF_FINAL.drop([c])\n",
    "                            FINAL['id']=k[1]\n",
    "\n",
    "                            FINAL\n",
    "                        else:\n",
    "                            #This Case works when description is not found\n",
    "                            FINAL=DF_FINAL\n",
    "                            FINAL['id']=k[1]\n",
    "\n",
    "                            FINAL\n",
    "\n",
    "                    elif c>=1:\n",
    "                        #This Case works when description is more than 1 row\n",
    "                        #Dropping 'c' rows\n",
    "                        DF_11=DF_FINAL.iloc[c:]\n",
    "                        #row values as column names\n",
    "                        DF_11.columns=DF_11.iloc[0]\n",
    "                        #Dropping the row\n",
    "                        FINAL=DF_11.drop([c])\n",
    "                        FINAL['id']=k[1]\n",
    "\n",
    "\n",
    "\n",
    "                        FINAL\n",
    "                    else:\n",
    "                        None\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass\n",
    "        try:\n",
    "            FINAL = pd.concat(combined_final)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            FINAL = FINAL.loc[:, FINAL.columns.notnull()]\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            FINAL = FINAL.loc[:, ~FINAL.columns.str.contains('^unnamed')]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            for col in FINAL.columns:\n",
    "                if col =='unnamed: 0':\n",
    "                    FINAL=FINAL.drop([\"unnamed: 0\"],axis=1)\n",
    "                else:\n",
    "                       None\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "        for i in FINAL.columns:\n",
    "            x = str(i).lower().strip()\n",
    "            FINAL=FINAL.rename(columns= {i:x})\n",
    "        for k in CNames.itertuples(index=False):\n",
    "            for r in DF6.itertuples(index=False):\n",
    "                if str(k[1]) == str(r[2]):\n",
    "                    try:\n",
    "                        for i in FINAL.columns.tolist():\n",
    "                            if str(i) == str(r[0]):\n",
    "                                FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                    except:\n",
    "                        pass\n",
    "        for i in FINAL.columns.tolist():\n",
    "            for r in DF6.itertuples(index=False):\n",
    "                if str(r[2]) == \"nan\" :\n",
    "                    if str(i) == str(r[0]):\n",
    "                        FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "\n",
    "        Search_List = list(DF8[\"Dropping columns\"])\n",
    "        #dropping columns\n",
    "        FINAL= FINAL.drop(columns=[col for col in FINAL if col  in Search_List])\n",
    "\n",
    "\n",
    "        FINAL['cpt_hcpcs'].fillna(method='ffill', inplace=True)\n",
    "        FINAL['description'].fillna(method='ffill', inplace=True)\n",
    "        FINAL['drg'].fillna(method='ffill', inplace=True)\n",
    "        FINAL['drg'] = FINAL['drg'].fillna(0)\n",
    "\n",
    "\n",
    "        try:\n",
    "            cols=[i for i in FINAL.columns if i not in [\"description\",\"cpt_hcpcs\",'inpatient-outpatient','drg']]\n",
    "            for col in cols:\n",
    "                FINAL[col] = pd.to_numeric(FINAL[col], errors='coerce')\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        FINAL[\"lineitem_cnt\"] = FINAL.groupby([\"description\",\"cpt_hcpcs\",\"drg\"])[\"description\"].transform('count')\n",
    "        FINAL[\"lineitem_cnt\"]=FINAL[\"lineitem_cnt\"]\n",
    "\n",
    "        FINAL=FINAL.groupby(['description','cpt_hcpcs','drg','lineitem_cnt']).aggregate(['sum']).reset_index()\n",
    "        FINAL.columns = FINAL.columns.get_level_values(0)\n",
    "\n",
    "\n",
    "\n",
    "        column_list = ['inpatient_outpatient']\n",
    "        for col in column_list:\n",
    "            if col not in FINAL.columns:\n",
    "                FINAL[col] = ' ' \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        df2=FINAL\n",
    "        df2 = df_column_uniquify(df2)\n",
    "        #Required format - variable list\n",
    "        Col_list = list(DF5[\"Columns\"])\n",
    "        df3=df2.melt(id_vars=[col for col in df2 if col in Col_list],var_name=\"name\",value_name='cost')\n",
    "        #df3=df1.melt(id_vars=['ID','Description','Cpt Code','Rev_Cd','Units'],var_name=\"Name\",value_name='Cost')\n",
    "\n",
    "\n",
    "\n",
    "        df4=df3\n",
    "        df4=df4[df4['cost'].notnull()]\n",
    "        df4=df4[df4['name'].notnull()]\n",
    "        #Dropping_columns=['Not offered','Not Contracted','N/A','Not a covered service','Not Offered','Not contracted','Not a covered service','N/A']\n",
    "        #df4 = df4[~df4['Cost'].isin(Dropping_columns)]\n",
    "        df4\n",
    "        Combined_data.append(df4)\n",
    "    Combined_data = pd.concat(Combined_data)\n",
    "\n",
    "    Combined_data\n",
    "    Combined_data.drop_duplicates()\n",
    "    #Combined_data[\"id\"]=Combined_data.id.astype('int64')\n",
    "    #Combined_data.dtypes\n",
    "\n",
    "    #Joining both hospital data with shoppable data by ID\n",
    "    #Sample_output=pd.merge(left=DHC_Hosp_data1, right=Combined_data,how='inner',left_on=['Hospital_Id'],right_on=['id'])\n",
    "    Sample_output = Combined_data\n",
    "    #Dropping the columns\n",
    "    #Sample_output.drop([\"id\"], axis = 1, inplace = True)\n",
    "    #Sample_output['inpatient-outpatient'] = np.where((Sample_output['inpatient-outpatient'] ==' ') & (Sample_output['name'].str.contains('inpatient/outpatient/drug')) , 'IP/OP', Sample_output['inpatient-outpatient'])\n",
    "    #Sample_output['inpatient-outpatient'] = np.where((Sample_output['inpatient-outpatient'] ==' ') & (Sample_output['name'].str.contains('inpatient/outpatient/drug')) , 'IP/OP', Sample_output['inpatient-outpatient'])\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains('ip & op')) , 'IP & OP', Sample_output['inpatient_outpatient'])\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains('ip & op')) , 'IP & OP', Sample_output['inpatient_outpatient'])\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains('ip/op')) , 'Inpatient', Sample_output['inpatient_outpatient'])\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains('ip/op')) , 'Outpatient', Sample_output['inpatient_outpatient'])\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains('inpatient')) , 'Inpatient', Sample_output['inpatient_outpatient'])\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains('outpatient')) , 'Outpatient', Sample_output['inpatient_outpatient'])\n",
    "    #Sample_output['inpatient-outpatient'] = np.where((Sample_output['inpatient-outpatient'] ==' ') & (Sample_output['name'].str.contains('ip')) , 'Inpatient', Sampl\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains(' ip')) , 'Inpatient', Sample_output['inpatient_outpatient'])\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains(' op')) , 'Outpatient', Sample_output['inpatient_outpatient'])\n",
    "\n",
    "\n",
    "    output_path = r\"C:\\Users\\User\\Zigna AI Corp\\Zigna AI Corp - RightPx\\Hospital Application_2022-03-09\\Automation_task\\outputs\\Wideformat1009_{}.csv\"\n",
    "    Sample_output.to_csv(output_path.format((k[1])), index=False)\n",
    "    return Sample_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1c79635",
   "metadata": {},
   "outputs": [],
   "source": [
    "################## wideFormat1010 ################\n",
    "def wideFormat1010(CNames):\n",
    "    global df7\n",
    "    \n",
    "    Combined_data = []\n",
    "    combined_final = []\n",
    "    non_prep_data = []\n",
    "    #Getting the details as list from files\n",
    "    for k in CNames.itertuples(index=False):\n",
    "        f=k[0] \n",
    "        #Checking the file type- xlsx   \n",
    "        if k[2]== 'csv':\n",
    "            try:\n",
    "                DF_FINAL=pd.read_csv(f)\n",
    "            except:\n",
    "                DF_FINAL=pd.read_csv(f,encoding='latin1')\n",
    "\n",
    "            non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        elif k[2]== 'xlsx':\n",
    "            sheet_to = pd.read_excel(f,sheet_name=None,dtype=str,header=None)\n",
    "\n",
    "            for sh in sheet_to.keys():\n",
    "\n",
    "                DF_FINAL = pd.read_excel(f,sheet_name=sh,dtype=str)\n",
    "                print(sh)\n",
    "                non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        for j in df7.itertuples(index=False):\n",
    "            if str(k[1]) == str(j[0]):\n",
    "                s = j[1]\n",
    "\n",
    "        for DF_FINAL in non_prep_data:\n",
    "            try:\n",
    "                if DF_FINAL.iloc[:, [s]].empty == False:\n",
    "                    DF_10=DF_FINAL.iloc[:, [s]]    \n",
    "                    m=0\n",
    "                    c=0\n",
    "\n",
    "                    #Getting the count of  empty rows\n",
    "                    for index, row in DF_10.iterrows():\n",
    "                        if(pd.notnull(row[0])): \n",
    "                            m=m+1\n",
    "                            break\n",
    "                        else:\n",
    "                            c=c+1\n",
    "\n",
    "                    if c==0:\n",
    "                    #This Case works when description is in one row\n",
    "                        if \"Unnamed: 5\" in DF_10:\n",
    "                            DF_FINAL.columns=DF_FINAL.iloc[0]\n",
    "                            FINAL=DF_FINAL.drop([c])\n",
    "                            FINAL['id']=k[1]\n",
    "\n",
    "                            FINAL\n",
    "                        else:\n",
    "                            #This Case works when description is not found\n",
    "                            FINAL=DF_FINAL\n",
    "                            FINAL['id']=k[1]\n",
    "\n",
    "                            FINAL\n",
    "\n",
    "                    elif c>=1:\n",
    "                        #This Case works when description is more than 1 row\n",
    "                        #Dropping 'c' rows\n",
    "                        DF_11=DF_FINAL.iloc[c:]\n",
    "                        #row values as column names\n",
    "                        DF_11.columns=DF_11.iloc[0]\n",
    "                        #Dropping the row\n",
    "                        FINAL=DF_11.drop([c])\n",
    "                        FINAL['id']=k[1]\n",
    "\n",
    "\n",
    "\n",
    "                        FINAL\n",
    "                    else:\n",
    "                        None\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass\n",
    "        try:\n",
    "            FINAL = pd.concat(combined_final)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            FINAL = FINAL.loc[:, FINAL.columns.notnull()]\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            FINAL = FINAL.loc[:, ~FINAL.columns.str.contains('^unnamed')]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            for col in FINAL.columns:\n",
    "                if col =='unnamed: 0':\n",
    "                    FINAL=FINAL.drop([\"unnamed: 0\"],axis=1)\n",
    "                else:\n",
    "                       None\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "\n",
    "        for i in FINAL.columns:\n",
    "            x = str(i).lower().strip()\n",
    "            FINAL=FINAL.rename(columns= {i:x})\n",
    "        for k in CNames.itertuples(index=False):\n",
    "            for r in DF6.itertuples(index=False):\n",
    "                if str(k[1]) == str(r[2]):\n",
    "                    try:\n",
    "                        for i in FINAL.columns.tolist():\n",
    "                            if str(i) == str(r[0]):\n",
    "                                FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                    except:\n",
    "                        pass\n",
    "        for i in FINAL.columns.tolist():\n",
    "            for r in DF6.itertuples(index=False):\n",
    "                if str(r[2]) == \"nan\" :\n",
    "                    if str(i) == str(r[0]):\n",
    "                        FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "\n",
    "        Search_List = list(DF8[\"Dropping columns\"])\n",
    "        #dropping columns\n",
    "        FINAL= FINAL.drop(columns=[col for col in FINAL if col  in Search_List])\n",
    "\n",
    "        try:\n",
    "            FINAL.dropna(subset = [\"procedure_chargenumber\"], inplace=True)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            FINAL = FINAL.rename(columns={\"description_1\":\"description\"})\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "        try:\n",
    "            FINAL['description'].fillna(method='ffill', inplace=True)\n",
    "            FINAL[\"cpt_hcpcs\"].fillna(method=\"ffill\",inplace=True)\n",
    "            FINAL[\"lineitem_cnt\"] = FINAL.groupby([\"description\"])[\"description\"].transform('count')\n",
    "\n",
    "            all_columns = list(FINAL)\n",
    "            FINAL[all_columns] = FINAL[all_columns].replace(r'^\\s*$', '', regex=True)\n",
    "\n",
    "            cols=[i for i in FINAL.columns if i not in [\"description\",'cpt_hcpcs',\"hospital_Id\"]]\n",
    "            for col in cols:\n",
    "                FINAL[col] = pd.to_numeric(FINAL[col], errors='coerce')\n",
    "            #FINAL[\"LineItem_cnt\"] = FINAL.groupby([\"HCPCS\"])[\"HCPCS\"].transform('count')\n",
    "            FINAL[\"lineitem_cnt\"]=FINAL[\"lineitem_cnt\"]-1   \n",
    "            FINAL=FINAL.groupby(['cpt_hcpcs','lineitem_cnt','description',\"hospital_Id\"]).aggregate(['sum']).reset_index()\n",
    "            FINAL.columns = FINAL.columns.get_level_values(0)\n",
    "            FINAL\n",
    "        except: \n",
    "            FINAL['cpt_hcpcs'].fillna(method='ffill', inplace=True)\n",
    "            FINAL[\"lineitem_cnt\"] = FINAL.groupby([\"cpt_hcpcs\"])[\"cpt_hcpcs\"].transform('count')\n",
    "\n",
    "            all_columns = list(FINAL)\n",
    "            FINAL[all_columns] = FINAL[all_columns].replace(r'^\\s*$', '', regex=True)\n",
    "\n",
    "            cols=[i for i in FINAL.columns if i not in [\"description\",'cpt_hcpcs','shoppable_service_category',\"hospital_Id\"]]\n",
    "            for col in cols:\n",
    "                FINAL[col] = pd.to_numeric(FINAL[col], errors='coerce')\n",
    "            #FINAL[\"LineItem_cnt\"] = FINAL.groupby([\"HCPCS\"])[\"HCPCS\"].transform('count')\n",
    "            FINAL[\"lineitem_cnt\"]=FINAL[\"lineitem_cnt\"]-1   \n",
    "            FINAL=FINAL.groupby(['cpt_hcpcs','lineitem_cnt','description','shoppable_service_category',\"hospital_Id\"]).aggregate(['sum']).reset_index()\n",
    "            FINAL.columns = FINAL.columns.get_level_values(0)\n",
    "            FINAL\n",
    "\n",
    "        column_list = ['inpatient_outpatient']\n",
    "        for col in column_list:\n",
    "            if col not in FINAL.columns:\n",
    "                FINAL[col] = ' ' \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        df2=FINAL\n",
    "        df2 = df_column_uniquify(df2)\n",
    "        #Required format - variable list\n",
    "        Col_list = list(DF5[\"Columns\"])\n",
    "        df3=df2.melt(id_vars=[col for col in df2 if col in Col_list],var_name=\"name\",value_name='cost')\n",
    "        #df3=df1.melt(id_vars=['ID','Description','Cpt Code','Rev_Cd','Units'],var_name=\"Name\",value_name='Cost')\n",
    "\n",
    "\n",
    "\n",
    "        df4=df3\n",
    "        df4=df4[df4['cost'].notnull()]\n",
    "        df4=df4[df4['name'].notnull()]\n",
    "        #Dropping_columns=['Not offered','Not Contracted','N/A','Not a covered service','Not Offered','Not contracted','Not a covered service','N/A']\n",
    "        #df4 = df4[~df4['Cost'].isin(Dropping_columns)]\n",
    "        df4\n",
    "        Combined_data.append(df4)\n",
    "    Combined_data = pd.concat(Combined_data)\n",
    "\n",
    "    Combined_data\n",
    "    Combined_data.drop_duplicates()\n",
    "    #Combined_data[\"id\"]=Combined_data.id.astype('int64')\n",
    "    #Combined_data.dtypes\n",
    "\n",
    "    #Joining both hospital data with shoppable data by ID\n",
    "    #Sample_output=pd.merge(left=DHC_Hosp_data1, right=Combined_data,how='inner',left_on=['Hospital_Id'],right_on=['id'])\n",
    "    Sample_output = Combined_data\n",
    "    #Dropping the columns\n",
    "    #Sample_output.drop([\"id\"], axis = 1, inplace = True)\n",
    "    #Sample_output['inpatient-outpatient'] = np.where((Sample_output['inpatient-outpatient'] ==' ') & (Sample_output['name'].str.contains('inpatient/outpatient/drug')) , 'IP/OP', Sample_output['inpatient-outpatient'])\n",
    "    #Sample_output['inpatient-outpatient'] = np.where((Sample_output['inpatient-outpatient'] ==' ') & (Sample_output['name'].str.contains('inpatient/outpatient/drug')) , 'IP/OP', Sample_output['inpatient-outpatient'])\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains('ip & op')) , 'IP & OP', Sample_output['inpatient_outpatient'])\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains('ip & op')) , 'IP & OP', Sample_output['inpatient_outpatient'])\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains('ip/op')) , 'Inpatient', Sample_output['inpatient_outpatient'])\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains('ip/op')) , 'Outpatient', Sample_output['inpatient_outpatient'])\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains('inpatient')) , 'Inpatient', Sample_output['inpatient_outpatient'])\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains('outpatient')) , 'Outpatient', Sample_output['inpatient_outpatient'])\n",
    "    #Sample_output['inpatient-outpatient'] = np.where((Sample_output['inpatient-outpatient'] ==' ') & (Sample_output['name'].str.contains('ip')) , 'Inpatient', Sampl\n",
    "\n",
    "\n",
    "    output_path = r\"C:\\Users\\User\\Zigna AI Corp\\Zigna AI Corp - RightPx\\Hospital Application_2022-03-09\\Automation_task\\outputs\\Wideformat1010_{}.csv\"\n",
    "    Sample_output.to_csv(output_path.format((k[1])), index=False)\n",
    "    return Sample_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4a7480c",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### wideFormat1011 #################\n",
    "def wideFormat1011(CNames):\n",
    "    global df7\n",
    "    \n",
    "    Combined_data = []\n",
    "    combined_final = []\n",
    "    non_prep_data = []\n",
    "    #Getting the details as list from files\n",
    "    for k in CNames.itertuples(index=False):\n",
    "        f=k[0] \n",
    "        #Checking the file type- xlsx   \n",
    "        if k[2]== 'csv':\n",
    "            try:\n",
    "                DF_FINAL=pd.read_csv(f)\n",
    "            except:\n",
    "                DF_FINAL=pd.read_csv(f,encoding='latin1')\n",
    "\n",
    "            non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        elif k[2]== 'xlsx':\n",
    "            sheet_to = pd.read_excel(f,sheet_name=None,dtype=str,header=None)\n",
    "\n",
    "            for sh in sheet_to.keys():\n",
    "\n",
    "                DF_FINAL = pd.read_excel(f,sheet_name=sh,dtype=str)\n",
    "                print(sh)\n",
    "                non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        for j in df7.itertuples(index=False):\n",
    "            if str(k[1]) == str(j[0]):\n",
    "                s = j[1]\n",
    "\n",
    "        for DF_FINAL in non_prep_data:\n",
    "            try:\n",
    "                if DF_FINAL.iloc[:, [s]].empty == False:\n",
    "                    DF_10=DF_FINAL.iloc[:, [s]]    \n",
    "                    m=0\n",
    "                    c=0\n",
    "\n",
    "                    #Getting the count of  empty rows\n",
    "                    for index, row in DF_10.iterrows():\n",
    "                        if(pd.notnull(row[0])): \n",
    "                            m=m+1\n",
    "                            break\n",
    "                        else:\n",
    "                            c=c+1\n",
    "\n",
    "                    if c==0:\n",
    "                    #This Case works when description is in one row\n",
    "                        if \"Unnamed: 5\" in DF_10:\n",
    "                            DF_FINAL.columns=DF_FINAL.iloc[0]\n",
    "                            FINAL=DF_FINAL.drop([c])\n",
    "                            FINAL['id']=k[1]\n",
    "                            for i in FINAL.columns:\n",
    "                                x = str(i).lower().strip()\n",
    "                                FINAL=FINAL.rename(columns= {i:x})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                            for k in CNames.itertuples(index=False):\n",
    "                                for r in DF6.itertuples(index=False):\n",
    "                                    if str(k[1]) == str(r[2]):\n",
    "                                        try:\n",
    "                                            for i in FINAL.columns.tolist():\n",
    "                                                if str(i) == str(r[0]):\n",
    "                                                    FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                                        except:\n",
    "                                            pass\n",
    "                            for i in FINAL.columns.tolist():\n",
    "\n",
    "                                for r in DF6.itertuples(index=False):\n",
    "\n",
    "\n",
    "\n",
    "                                    if str(r[2]) == \"nan\" :\n",
    "\n",
    "                                        if str(i) == str(r[0]):\n",
    "                                            FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                            combined_final.append(FINAL)\n",
    "                        else:\n",
    "                            #This Case works when description is not found\n",
    "                            FINAL=DF_FINAL\n",
    "                            FINAL['id']=k[1]\n",
    "                            for i in FINAL.columns:\n",
    "                                x = str(i).lower().strip()\n",
    "                                FINAL=FINAL.rename(columns= {i:x})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                            for k in CNames.itertuples(index=False):\n",
    "                                for r in DF6.itertuples(index=False):\n",
    "                                    if str(k[1]) == str(r[2]):\n",
    "                                        try:\n",
    "                                            for i in FINAL.columns.tolist():\n",
    "                                                if str(i) == str(r[0]):\n",
    "                                                    FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                                        except:\n",
    "                                            pass\n",
    "                            for i in FINAL.columns.tolist():\n",
    "\n",
    "                                for r in DF6.itertuples(index=False):\n",
    "\n",
    "\n",
    "\n",
    "                                    if str(r[2]) == \"nan\" :\n",
    "\n",
    "                                        if str(i) == str(r[0]):\n",
    "                                            FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                            combined_final.append(FINAL)\n",
    "\n",
    "                    elif c>=1:\n",
    "                        #This Case works when description is more than 1 row\n",
    "                        #Dropping 'c' rows\n",
    "                        DF_11=DF_FINAL.iloc[c:]\n",
    "                        #row values as column names\n",
    "                        DF_11.columns=DF_11.iloc[0]\n",
    "                        #Dropping the row\n",
    "                        FINAL=DF_11.drop([c])\n",
    "                        FINAL['id']=k[1]\n",
    "\n",
    "\n",
    "                        for i in FINAL.columns:\n",
    "                            x = str(i).lower().strip()\n",
    "                            FINAL=FINAL.rename(columns= {i:x})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                        for k in CNames.itertuples(index=False):\n",
    "                            for r in DF6.itertuples(index=False):\n",
    "                                if str(k[1]) == str(r[2]):\n",
    "                                    try:\n",
    "                                        for i in FINAL.columns.tolist():\n",
    "                                            if str(i) == str(r[0]):\n",
    "                                                FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                                    except:\n",
    "                                        pass\n",
    "                        for i in FINAL.columns.tolist():\n",
    "\n",
    "                            for r in DF6.itertuples(index=False):\n",
    "\n",
    "\n",
    "\n",
    "                                if str(r[2]) == \"nan\" :\n",
    "\n",
    "                                    if str(i) == str(r[0]):\n",
    "                                        FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                        combined_final.append(FINAL)\n",
    "                    else:\n",
    "                        None\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass\n",
    "        try:\n",
    "            FINAL = pd.concat(combined_final)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            FINAL = FINAL.loc[:, FINAL.columns.notnull()]\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            FINAL = FINAL.loc[:, ~FINAL.columns.str.contains('^unnamed')]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            for col in FINAL.columns:\n",
    "                if col =='unnamed: 0':\n",
    "                    FINAL=FINAL.drop([\"unnamed: 0\"],axis=1)\n",
    "                else:\n",
    "                       None\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "\n",
    "        Search_List = list(DF8[\"Dropping columns\"])\n",
    "        #dropping columns\n",
    "        FINAL= FINAL.drop(columns=[col for col in FINAL if col  in Search_List])\n",
    "        try:\n",
    "            try:\n",
    "                FINAL['cpt_hcpcs_drg_aprdrg_icdx10'].fillna(method='ffill', inplace=True)\n",
    "                # FINAL=FINAL[FINAL['Procedure/Charge Number'].notnull()]\n",
    "                FINAL[\"lineitem_cnt\"] = FINAL.groupby(\"cpt_hcpcs_drg_aprdrg_icdx10\")[\"cpt_hcpcs_drg_aprdrg_icdx10\"].transform('count')\n",
    "                FINAL[\"lineitem_cnt\"]=FINAL[\"lineitem_cnt\"]-1\n",
    "\n",
    "                FINAL=FINAL[(FINAL[\"lineitem_cnt\"] ==0) | ((FINAL[\"lineitem_cnt\"] >=1) & (FINAL[\"primary_service_and_ancillary_service\"].str.contains(\"Total\",case=False))) ]\n",
    "                FINAL  \n",
    "            except:\n",
    "                FINAL['billing_code'].fillna(method='ffill', inplace=True)\n",
    "                FINAL=FINAL[FINAL['procedure_chargenumber'].notnull()]\n",
    "                FINAL[\"lineitem_cnt\"] = FINAL.groupby(\"billing_code\")[\"billing_code\"].transform('count')\n",
    "                FINAL[\"lineitem_cnt\"]=FINAL[\"lineitem_cnt\"]-1\n",
    "\n",
    "                FINAL=FINAL[(FINAL[\"lineitem_cnt\"] ==0) | ((FINAL[\"lineitem_cnt\"] >=1) & (FINAL[\"procedure_chargenumber\"].str.contains(\"CLAIM\",case=False))) ]\n",
    "                FINAL  \n",
    "                FINAL.drop([\"procedure_chargenumber\"], axis = 1, inplace = True)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        column_list = ['inpatient_outpatient']\n",
    "        for col in column_list:\n",
    "            if col not in FINAL.columns:\n",
    "                FINAL[col] = ' ' \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        df2=FINAL\n",
    "        df2 = df_column_uniquify(df2)\n",
    "        #Required format - variable list\n",
    "        Col_list = list(DF5[\"Columns\"])\n",
    "        df3=df2.melt(id_vars=[col for col in df2 if col in Col_list],var_name=\"name\",value_name='cost')\n",
    "        #df3=df1.melt(id_vars=['ID','Description','Cpt Code','Rev_Cd','Units'],var_name=\"Name\",value_name='Cost')\n",
    "\n",
    "\n",
    "\n",
    "        df4=df3\n",
    "        df4=df4[df4['cost'].notnull()]\n",
    "        df4=df4[df4['name'].notnull()]\n",
    "        #Dropping_columns=['Not offered','Not Contracted','N/A','Not a covered service','Not Offered','Not contracted','Not a covered service','N/A']\n",
    "        #df4 = df4[~df4['Cost'].isin(Dropping_columns)]\n",
    "        df4\n",
    "        Combined_data.append(df4)\n",
    "    Combined_data = pd.concat(Combined_data)\n",
    "\n",
    "    Combined_data\n",
    "    Combined_data.drop_duplicates()\n",
    "    #Combined_data[\"id\"]=Combined_data.id.astype('int64')\n",
    "    #Combined_data.dtypes\n",
    "\n",
    "    #Joining both hospital data with shoppable data by ID\n",
    "    #Sample_output=pd.merge(left=DHC_Hosp_data1, right=Combined_data,how='inner',left_on=['Hospital_Id'],right_on=['id'])\n",
    "    Sample_output = Combined_data\n",
    "    #Dropping the columns\n",
    "    #Sample_output.drop([\"id\"], axis = 1, inplace = True)\n",
    "    #Sample_output['inpatient-outpatient'] = np.where((Sample_output['inpatient-outpatient'] ==' ') & (Sample_output['name'].str.contains('inpatient/outpatient/drug')) , 'IP/OP', Sample_output['inpatient-outpatient'])\n",
    "    #Sample_output['inpatient-outpatient'] = np.where((Sample_output['inpatient-outpatient'] ==' ') & (Sample_output['name'].str.contains('inpatient/outpatient/drug')) , 'IP/OP', Sample_output['inpatient-outpatient'])\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains('ip & op')) , 'IP & OP', Sample_output['inpatient_outpatient'])\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains('ip & op')) , 'IP & OP', Sample_output['inpatient_outpatient'])\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains('ip/op')) , 'Inpatient', Sample_output['inpatient_outpatient'])\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains('ip/op')) , 'Outpatient', Sample_output['inpatient_outpatient'])\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains('inpatient')) , 'Inpatient', Sample_output['inpatient_outpatient'])\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains('outpatient')) , 'Outpatient', Sample_output['inpatient_outpatient'])\n",
    "    #Sample_output['inpatient-outpatient'] = np.where((Sample_output['inpatient-outpatient'] ==' ') & (Sample_output['name'].str.contains('ip')) , 'Inpatient', Sampl\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains(' ip')) , 'Inpatient', Sample_output['inpatient_outpatient'])\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains(' op')) , 'Outpatient', Sample_output['inpatient_outpatient'])\n",
    "\n",
    "\n",
    "    output_path = r\"C:\\Users\\User\\Zigna AI Corp\\Zigna AI Corp - RightPx\\Hospital Application_2022-03-09\\Automation_task\\outputs\\Wideformat1011_{}.csv\"\n",
    "    Sample_output.to_csv(output_path.format((k[1])), index=False)\n",
    "    return Sample_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be3b3500",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### wideFormat1012 #####################\n",
    "def wideFormat1012(CNames):\n",
    "    global df7\n",
    "    \n",
    "    Combined_data = []\n",
    "    combined_final = []\n",
    "    non_prep_data = []\n",
    "    #Getting the details as list from files\n",
    "    for k in CNames.itertuples(index=False):\n",
    "        f=k[0] \n",
    "        #Checking the file type- xlsx   \n",
    "        if k[2]== 'csv':\n",
    "            try:\n",
    "                DF_FINAL=pd.read_csv(f)\n",
    "            except:\n",
    "                DF_FINAL=pd.read_csv(f,encoding='latin1')\n",
    "\n",
    "            non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        elif k[2]== 'xlsx':\n",
    "            sheet_to = pd.read_excel(f,sheet_name=None,dtype=str,header=None)\n",
    "\n",
    "            for sh in sheet_to.keys():\n",
    "\n",
    "                DF_FINAL = pd.read_excel(f,sheet_name=sh,dtype=str)\n",
    "                print(sh)\n",
    "                non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        for j in df7.itertuples(index=False):\n",
    "            if str(k[1]) == str(j[0]):\n",
    "                s = j[1]\n",
    "\n",
    "        for DF_FINAL in non_prep_data:\n",
    "            try:\n",
    "                if DF_FINAL.iloc[:, [s]].empty == False:\n",
    "                    DF_10=DF_FINAL.iloc[:, [s]]    \n",
    "                    m=0\n",
    "                    c=0\n",
    "\n",
    "                    #Getting the count of  empty rows\n",
    "                    for index, row in DF_10.iterrows():\n",
    "                        if(pd.notnull(row[0])): \n",
    "                            m=m+1\n",
    "                            break\n",
    "                        else:\n",
    "                            c=c+1\n",
    "\n",
    "                    if c==0:\n",
    "                    #This Case works when description is in one row\n",
    "                        if \"Unnamed: 5\" in DF_10:\n",
    "                            DF_FINAL.columns=DF_FINAL.iloc[0]\n",
    "                            FINAL=DF_FINAL.drop([c])\n",
    "                            FINAL['id']=k[1]\n",
    "                            FINAL\n",
    "                        else:\n",
    "                            #This Case works when description is not found\n",
    "                            FINAL=DF_FINAL\n",
    "                            FINAL['id']=k[1]\n",
    "                            FINAL\n",
    "\n",
    "                    elif c>=1:\n",
    "                        #This Case works when description is more than 1 row\n",
    "                        #Dropping 'c' rows\n",
    "                        DF_11=DF_FINAL.iloc[c:]\n",
    "                        #row values as column names\n",
    "                        DF_11.columns=DF_11.iloc[0]\n",
    "                        #Dropping the row\n",
    "                        FINAL=DF_11.drop([c])\n",
    "                        FINAL['id']=k[1]\n",
    "                        FINAL\n",
    "                    else:\n",
    "                        None\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass\n",
    "        try:\n",
    "            FINAL = pd.concat(combined_final)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            FINAL = FINAL.loc[:, FINAL.columns.notnull()]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "        try:\n",
    "            for col in FINAL.columns:\n",
    "                if col =='unnamed: 0':\n",
    "                    FINAL=FINAL.drop([\"unnamed: 0\"],axis=1)\n",
    "                else:\n",
    "                       None\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        for i in FINAL.columns:\n",
    "            x = str(i).lower().strip()\n",
    "            FINAL=FINAL.rename(columns= {i:x})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        for k in CNames.itertuples(index=False):\n",
    "            for r in DF6.itertuples(index=False):\n",
    "                if str(k[1]) == str(r[2]):\n",
    "                    try:\n",
    "                        for i in FINAL.columns.tolist():\n",
    "                            if str(i) == str(r[0]):\n",
    "                                FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                    except:\n",
    "                        pass\n",
    "        for i in FINAL.columns.tolist():\n",
    "\n",
    "            for r in DF6.itertuples(index=False):\n",
    "\n",
    "\n",
    "\n",
    "                if str(r[2]) == \"nan\" :\n",
    "\n",
    "                    if str(i) == str(r[0]):\n",
    "                        FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "\n",
    "        #Checking the  Inpatient/Outpatient column exists or not\n",
    "        column_list = ['inpatient_outpatient']\n",
    "        for col in column_list:\n",
    "            if col not in FINAL.columns:\n",
    "                FINAL[col] = ' '   \n",
    "\n",
    "\n",
    "        new = FINAL['description'].str.split(\" \",n=1,expand=True)\n",
    "        # new = FINAL['description'].str.split(\" \",n=2,expand=True)\n",
    "\n",
    "        FINAL['Cpt Code'] = new[0]\n",
    "\n",
    "        # FINAL['Cpt Code'] = FINAL['Cpt Code'].astype([np.int64], errors = 'coerce')\n",
    "\n",
    "        FINAL[\"Cpt Code\"]= np.where(FINAL['Cpt Code'].str.endswith('-') , FINAL['Cpt Code'].replace('-','', regex=True),FINAL['Cpt Code'])\n",
    "        FINAL['Cpt Code'] = FINAL['Cpt Code'].str.strip()\n",
    "\n",
    "        # FINAL['Cpt Code'] = FINAL[[\"Cpt Code\"]].to_numpy()\n",
    "        #Checking the  Inpatient/Outpatient column exists or not\n",
    "        column_list = ['Cpt Code1']\n",
    "        for col in column_list:\n",
    "            if col not in FINAL.columns:\n",
    "                FINAL[col] = ' '       \n",
    "\n",
    "\n",
    "        # FINAL['Cpt Code'] = re.sub('[^a-zA-Z]', '', FINAL['Cpt Code'])\n",
    "\n",
    "        #df['name_code_is_alphanumeric'] = list(map(lambda x: x.isalnum(), df['name_code']))\n",
    "        # getting all numeric characters.....\n",
    "        # FINAL[\"Cpt Code\"]= np.where(FINAL['Cpt Code'].str.contains('.') , np.nan,FINAL['Cpt Code'])\n",
    "        # for index, row in FINAL.iterrows():\n",
    "        #     if re.findall(r'^[0-9]{2}[0-9]{3}',FINAL['Cpt Code'][index]):\n",
    "        #         FINAL['Cpt Code1'][index] = FINAL['Cpt Code'][index]\n",
    "        #     else:\n",
    "        #         FINAL['Cpt Code1'][index] = np.nan\n",
    "        FINAL['Cpt Code1'] = pd.to_numeric(FINAL['Cpt Code'],errors=\"coerce\")\n",
    "\n",
    "        for index, row in FINAL.iterrows():\n",
    "            if re.findall(r'^[A-Z]{1}[0-9]{4}',FINAL['Cpt Code'][index]):\n",
    "                FINAL['Cpt Code1'][index] = FINAL['Cpt Code'][index]\n",
    "            else:\n",
    "                FINAL['Cpt Code1'][index] = FINAL['Cpt Code1'][index]    \n",
    "        # FINAL['Cpt Code2'] = np.where((FINAL['Cpt  ==' ') & (Combined_data['name'].str.contains('inpatient')) , 'Inpatient', Combined_data['inpatient-outpatient'])\n",
    "        # for getting all hcpcs codes\n",
    "        for index, row in FINAL.iterrows():\n",
    "            if re.findall(r'^[0-9]{5}',FINAL['Cpt Code'][index]):\n",
    "                FINAL['Cpt Code1'][index] = FINAL['Cpt Code'].str[:5][index]\n",
    "            else:\n",
    "                FINAL['Cpt Code1'][index] = FINAL['Cpt Code1'][index]\n",
    "\n",
    "        FINAL['Cpt Code1'] = FINAL['Cpt Code1'].astype(str)\n",
    "\n",
    "        FINAL['Cpt Code1']=FINAL['Cpt Code1'].replace('\\.0', '', regex=True)\n",
    "\n",
    "        FINAL.drop([\"Cpt Code\"], axis = 1, inplace = True)\n",
    "        FINAL=FINAL.rename(columns = {'Cpt Code1': \"cpt_hcpcs_drg_icd10\"}) \n",
    "\n",
    "        FINAL=FINAL[FINAL['cpt_hcpcs_drg_icd10'].notnull()]\n",
    "\n",
    "\n",
    "\n",
    "        df2 = FINAL    \n",
    "        df2 = df_column_uniquify(df2)\n",
    "        Col_list = list(DF5[\"Columns\"])\n",
    "        df3=df2.melt(id_vars=[col for col in df2 if col in Col_list],var_name=\"name\",value_name='cost')\n",
    "        #df3=df1.melt(id_vars=['ID','Description','Cpt Code','Rev_Cd','Units'],var_name=\"Name\",value_name='Cost')\n",
    "        # df3=df3[df3['code'].notnull()] \n",
    "\n",
    "        df4=df3\n",
    "        df4=df4[df4['cost'].notnull()]\n",
    "        df4\n",
    "        Combined_data.append(df4)\n",
    "    Combined_data = pd.concat(Combined_data)\n",
    "\n",
    "    Sample_output = Combined_data\n",
    "    # Sample_output['inpatient-outpatient'] ==' ') & (Sample_output['name'].str.contains('ip')) , 'Inpatient', Sampl\n",
    "\n",
    "\n",
    "    output_path = r\"C:\\Users\\User\\Zigna AI Corp\\Zigna AI Corp - RightPx\\Hospital Application_2022-03-09\\Automation_task\\outputs\\Wideformat1012_{}.csv\"\n",
    "    Sample_output.to_csv(output_path.format((k[1])), index=False)\n",
    "    return Sample_output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e4563f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "################# wideFormat1015 ###################\n",
    "def wideFormat1015(CNames):\n",
    "    global df7\n",
    "    \n",
    "    Combined_data = []\n",
    "    combined_final = []\n",
    "    non_prep_data = []\n",
    "    #Getting the details as list from files\n",
    "    for k in CNames.itertuples(index=False):\n",
    "        f=k[0] \n",
    "        #Checking the file type- xlsx   \n",
    "        if k[2]== 'csv':\n",
    "            try:\n",
    "                DF_FINAL=pd.read_csv(f)\n",
    "            except:\n",
    "                DF_FINAL=pd.read_csv(f,encoding='latin1')\n",
    "\n",
    "            non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        elif k[2]== 'xlsx':\n",
    "            sheet_to = pd.read_excel(f,sheet_name=None,dtype=str,header=None)\n",
    "\n",
    "            for sh in sheet_to.keys():\n",
    "\n",
    "                DF_FINAL = pd.read_excel(f,sheet_name=sh,dtype=str)\n",
    "                print(sh)\n",
    "                non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        for j in df7.itertuples(index=False):\n",
    "            if str(k[1]) == str(j[0]):\n",
    "                s = j[1]\n",
    "\n",
    "        for DF_FINAL in non_prep_data:\n",
    "            try:\n",
    "                if DF_FINAL.iloc[:, [s]].empty == False:\n",
    "                    DF_10=DF_FINAL.iloc[:, [s]]    \n",
    "                    m=0\n",
    "                    c=0\n",
    "\n",
    "                    #Getting the count of  empty rows\n",
    "                    for index, row in DF_10.iterrows():\n",
    "                        if(pd.notnull(row[0])): \n",
    "                            m=m+1\n",
    "                            break\n",
    "                        else:\n",
    "                            c=c+1\n",
    "\n",
    "                    if c==0:\n",
    "                    #This Case works when description is in one row\n",
    "                        if \"Unnamed: 5\" in DF_10:\n",
    "                            DF_FINAL.columns=DF_FINAL.iloc[0]\n",
    "                            FINAL=DF_FINAL.drop([c])\n",
    "                            FINAL['id']=k[1]\n",
    "                            for i in FINAL.columns:\n",
    "                                x = str(i).lower().strip()\n",
    "                                FINAL=FINAL.rename(columns= {i:x})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                            for k in CNames.itertuples(index=False):\n",
    "                                for r in DF6.itertuples(index=False):\n",
    "                                    if str(k[1]) == str(r[2]):\n",
    "                                        try:\n",
    "                                            for i in FINAL.columns.tolist():\n",
    "                                                if str(i) == str(r[0]):\n",
    "                                                    FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                                        except:\n",
    "                                            pass\n",
    "                            for i in FINAL.columns.tolist():\n",
    "\n",
    "                                for r in DF6.itertuples(index=False):\n",
    "\n",
    "\n",
    "\n",
    "                                    if str(r[2]) == \"nan\" :\n",
    "\n",
    "                                        if str(i) == str(r[0]):\n",
    "                                            FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                            combined_final.append(FINAL)\n",
    "                        else:\n",
    "                            #This Case works when description is not found\n",
    "                            DF_11=DF_FINAL.iloc[c:]\n",
    "                            DF_11[:c]=DF_11[:c].fillna(method='ffill', axis=1)\n",
    "                            DF_11[:c] = DF_11[:c].fillna(' ')\n",
    "                            DF_FINAL.columns = (DF_FINAL.iloc[c] +' '+ DF_FINAL.iloc[c+1])\n",
    "                            DF_FINAL = DF_FINAL.iloc[c+2:]\n",
    "                            FINAL = DF_FINAL.reset_index(drop=True)\n",
    "                            FINAL['id']=k[1]\n",
    "                            for i in FINAL.columns:\n",
    "                                x = str(i).lower().strip()\n",
    "                                FINAL=FINAL.rename(columns= {i:x})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                            for k in CNames.itertuples(index=False):\n",
    "                                for r in DF6.itertuples(index=False):\n",
    "                                    if str(k[1]) == str(r[2]):\n",
    "                                        try:\n",
    "                                            for i in FINAL.columns.tolist():\n",
    "                                                if str(i) == str(r[0]):\n",
    "                                                    FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                                        except:\n",
    "                                            pass\n",
    "                            for i in FINAL.columns.tolist():\n",
    "\n",
    "                                for r in DF6.itertuples(index=False):\n",
    "\n",
    "\n",
    "\n",
    "                                    if str(r[2]) == \"nan\" :\n",
    "\n",
    "                                        if str(i) == str(r[0]):\n",
    "                                            FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                            combined_final.append(FINAL)\n",
    "\n",
    "                    elif c>=1:\n",
    "                        #This Case works when description is more than 1 row\n",
    "                        #Dropping 'c' rows\n",
    "                        DF_11=DF_FINAL.iloc[c:]\n",
    "                        DF_11[:c]=DF_11[:c].fillna(method='ffill', axis=1)\n",
    "                        DF_11[:c] = DF_11[:c].fillna(' ')\n",
    "                        DF_FINAL.columns = (DF_FINAL.iloc[c] +' '+ DF_FINAL.iloc[c+1])\n",
    "                        DF_FINAL = DF_FINAL.iloc[c+2:]\n",
    "                        FINAL = DF_FINAL.reset_index(drop=True)\n",
    "                        FINAL['id']=k[1]\n",
    "\n",
    "\n",
    "\n",
    "                        for i in FINAL.columns:\n",
    "                            x = str(i).lower().strip()\n",
    "                            FINAL=FINAL.rename(columns= {i:x})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                        for k in CNames.itertuples(index=False):\n",
    "                            for r in DF6.itertuples(index=False):\n",
    "                                if str(k[1]) == str(r[2]):\n",
    "                                    try:\n",
    "                                        for i in FINAL.columns.tolist():\n",
    "                                            if str(i) == str(r[0]):\n",
    "                                                FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                                    except:\n",
    "                                        pass\n",
    "                        for i in FINAL.columns.tolist():\n",
    "\n",
    "                            for r in DF6.itertuples(index=False):\n",
    "\n",
    "\n",
    "\n",
    "                                if str(r[2]) == \"nan\" :\n",
    "\n",
    "                                    if str(i) == str(r[0]):\n",
    "                                        FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                        combined_final.append(FINAL)\n",
    "                    else:\n",
    "                        None\n",
    "\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass\n",
    "\n",
    "        try:\n",
    "            FINAL = pd.concat(combined_final)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            FINAL = FINAL.loc[:, FINAL.columns.notnull()]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            for col in FINAL.columns:\n",
    "                if col =='unnamed: 0':\n",
    "                    FINAL=FINAL.drop([\"unnamed: 0\"],axis=1)\n",
    "                else:\n",
    "                       None\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        Search_List = list(DF8[\"Dropping columns\"])\n",
    "        #dropping columns\n",
    "        FINAL= FINAL.drop(columns=[col for col in FINAL if col  in Search_List])\n",
    "\n",
    "        column_list = ['inpatient_outpatient']\n",
    "        for col in column_list:\n",
    "            if col not in FINAL.columns:\n",
    "                FINAL[col] = ' ' \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        df2=FINAL\n",
    "        df2 = df_column_uniquify(df2)\n",
    "        #Required format - variable list\n",
    "        Col_list = list(DF5[\"Columns\"])\n",
    "        df3=df2.melt(id_vars=[col for col in df2 if col in Col_list],var_name=\"name\",value_name='cost')\n",
    "        #df3=df1.melt(id_vars=['ID','Description','Cpt Code','Rev_Cd','Units'],var_name=\"Name\",value_name='Cost')\n",
    "\n",
    "\n",
    "\n",
    "        df4=df3\n",
    "        df4=df4[df4['cost'].notnull()]\n",
    "\n",
    "\n",
    "        #Dropping_columns=['Not offered','Not Contracted','N/A','Not a covered service','Not Offered','Not contracted','Not a covered service','N/A']\n",
    "        #df4 = df4[~df4['Cost'].isin(Dropping_columns)]\n",
    "        df4\n",
    "        Combined_data.append(df4)\n",
    "    Combined_data = pd.concat(Combined_data)\n",
    "\n",
    "    Combined_data\n",
    "    Combined_data.drop_duplicates()\n",
    "    #Combined_data[\"id\"]=Combined_data.id.astype('int64')\n",
    "    #Combined_data.dtypes\n",
    "\n",
    "    #Joining both hospital data with shoppable data by ID\n",
    "    #Sample_output=pd.merge(left=DHC_Hosp_data1, right=Combined_data,how='inner',left_on=['Hospital_Id'],right_on=['id'])\n",
    "    Sample_output = Combined_data\n",
    "    #Dropping the columns\n",
    "    #Sample_output.drop([\"id\"], axis = 1, inplace = True)\n",
    "    #Sample_output['inpatient-outpatient'] = np.where((Sample_output['inpatient-outpatient'] ==' ') & (Sample_output['name'].str.contains('inpatient/outpatient/drug')) , 'IP/OP', Sample_output['inpatient-outpatient'])\n",
    "    #Sample_output['inpatient-outpatient'] = np.where((Sample_output['inpatient-outpatient'] ==' ') & (Sample_output['name'].str.contains('inpatient/outpatient/drug')) , 'IP/OP', Sample_output['inpatient-outpatient'])\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains('ip & op')) , 'IP & OP', Sample_output['inpatient_outpatient'])\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains('ip & op')) , 'IP & OP', Sample_output['inpatient_outpatient'])\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains('ip/op')) , 'Inpatient', Sample_output['inpatient_outpatient'])\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains('ip/op')) , 'Outpatient', Sample_output['inpatient_outpatient'])\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains('inpatient')) , 'Inpatient', Sample_output['inpatient_outpatient'])\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains('outpatient')) , 'Outpatient', Sample_output['inpatient_outpatient'])\n",
    "    #Sample_output['inpatient-outpatient'] = np.where((Sample_output['inpatient-outpatient'] ==' ') & (Sample_output['name'].str.contains('ip')) , 'Inpatient', Sampl\n",
    "\n",
    "\n",
    "    output_path = r\"C:\\Users\\User\\Zigna AI Corp\\Zigna AI Corp - RightPx\\Hospital Application_2022-03-09\\Automation_task\\outputs\\Wideformat1015_{}.csv\"\n",
    "    Sample_output.to_csv(output_path.format((k[1])), index=False)\n",
    "    return Sample_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ddfb5fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "################# wideFormat1016 ####################\n",
    "def wideFormat1016(CNames):\n",
    "    global df7\n",
    "    \n",
    "    Combined_data = []\n",
    "    combined_final = []\n",
    "    non_prep_data = []\n",
    "    #Getting the details as list from files\n",
    "    for k in CNames.itertuples(index=False):\n",
    "        f=k[0] \n",
    "        #Checking the file type- xlsx   \n",
    "        if k[2]== 'csv':\n",
    "            try:\n",
    "                DF_FINAL=pd.read_csv(f)\n",
    "            except:\n",
    "                DF_FINAL=pd.read_csv(f,encoding='latin1')\n",
    "\n",
    "            non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        elif k[2]== 'xlsx':\n",
    "            sheet_to = pd.read_excel(f,sheet_name=None,dtype=str,header=None)\n",
    "\n",
    "            for sh in sheet_to.keys():\n",
    "\n",
    "                DF_FINAL = pd.read_excel(f,sheet_name=sh,dtype=str,header=None)\n",
    "                print(sh)\n",
    "                non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        for j in df7.itertuples(index=False):\n",
    "            if str(k[1]) == str(j[0]):\n",
    "                s = j[1]\n",
    "\n",
    "        for DF_FINAL in non_prep_data:\n",
    "            try:\n",
    "                if DF_FINAL.iloc[:, [s]].empty == False:\n",
    "                    DF_10=DF_FINAL.iloc[:, [s]]    \n",
    "                    m=0\n",
    "                    c=0\n",
    "\n",
    "                    #Getting the count of  empty rows\n",
    "                    for index, row in DF_10.iterrows():\n",
    "                        if(pd.notnull(row[2])): \n",
    "                            m=m+1\n",
    "                            break\n",
    "                        else:\n",
    "                            c=c+1\n",
    "\n",
    "                    if c==0:\n",
    "                    #This Case works when description is in one row\n",
    "                        if \"Unnamed: 5\" in DF_10:\n",
    "                            DF_FINAL.columns=DF_FINAL.iloc[0]\n",
    "                            FINAL=DF_FINAL.drop([c])\n",
    "                            FINAL['id']=k[1]\n",
    "                            for i in FINAL.columns:\n",
    "                                x = str(i).lower().strip()\n",
    "                                FINAL=FINAL.rename(columns= {i:x})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                            for k in CNames.itertuples(index=False):\n",
    "                                for r in DF6.itertuples(index=False):\n",
    "                                    if str(k[1]) == str(r[2]):\n",
    "                                        try:\n",
    "                                            for i in FINAL.columns.tolist():\n",
    "                                                if str(i) == str(r[0]):\n",
    "                                                    FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                                        except:\n",
    "                                            pass\n",
    "                            for i in FINAL.columns.tolist():\n",
    "\n",
    "                                for r in DF6.itertuples(index=False):\n",
    "\n",
    "\n",
    "\n",
    "                                    if str(r[2]) == \"nan\" :\n",
    "\n",
    "                                        if str(i) == str(r[0]):\n",
    "                                            FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                            combined_final.append(FINAL)\n",
    "                        else:\n",
    "                            #This Case works when description is not found\n",
    "                            DF_FINAL.iloc[:c, :c] = np.nan\n",
    "\n",
    "                            DF_FINAL[:c] = DF_FINAL[:c].fillna(method='ffill', axis=1)\n",
    "                            DF_FINAL = DF_FINAL.replace(np.nan,'',regex=True)\n",
    "                            idx = DF_FINAL.index.get_loc(c)\n",
    "                            DF_11 = DF_FINAL.iloc[idx - c :]\n",
    "                            j = c+1\n",
    "\n",
    "                            req_rows = np.where(DF_11.index == j)[0][0]\n",
    "                            start = max(0, req_rows - j )\n",
    "                            end = max(1, req_rows)\n",
    "                            DF_12 = DF_11.iloc[start:end]\n",
    "\n",
    "                            DF_12= DF_12.apply(lambda c: ' '.join(c), axis=0)\n",
    "                            DF_12 = DF_12.to_frame()\n",
    "                            DF_13 = DF_12.T\n",
    "\n",
    "                            DF_11.drop(DF_11.head(j).index, inplace = True)\n",
    "                            DF15 = DF_13.append(DF_11)\n",
    "                            DF16 = DF15.reset_index(drop = True)\n",
    "                            DF16.columns = DF16.iloc[0]\n",
    "                            FINAL = DF16[1:]\n",
    "                            FINAL['id']=k[1]\n",
    "                            for i in FINAL.columns:\n",
    "                                x = str(i).lower().strip()\n",
    "                                FINAL=FINAL.rename(columns= {i:x})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                            for k in CNames.itertuples(index=False):\n",
    "                                for r in DF6.itertuples(index=False):\n",
    "                                    if str(k[1]) == str(r[2]):\n",
    "                                        try:\n",
    "                                            for i in FINAL.columns.tolist():\n",
    "                                                if str(i) == str(r[0]):\n",
    "                                                    FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                                        except:\n",
    "                                            pass\n",
    "                            for i in FINAL.columns.tolist():\n",
    "\n",
    "                                for r in DF6.itertuples(index=False):\n",
    "\n",
    "\n",
    "\n",
    "                                    if str(r[2]) == \"nan\" :\n",
    "\n",
    "                                        if str(i) == str(r[0]):\n",
    "                                            FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                            combined_final.append(FINAL)\n",
    "\n",
    "                    elif c>=1:\n",
    "                        #This Case works when description is more than 1 row\n",
    "                        #Dropping 'c' rows\n",
    "                        DF_FINAL.iloc[:c, :c] = np.nan\n",
    "\n",
    "                        DF_FINAL[:c] = DF_FINAL[:c].fillna(method='ffill', axis=1)\n",
    "                        DF_FINAL = DF_FINAL.replace(np.nan,'',regex=True)\n",
    "                        idx = DF_FINAL.index.get_loc(c)\n",
    "                        DF_11 = DF_FINAL.iloc[idx - c :]\n",
    "                        j = c+1\n",
    "\n",
    "                        req_rows = np.where(DF_11.index == j)[0][0]\n",
    "                        start = max(0, req_rows - j )\n",
    "                        end = max(1, req_rows)\n",
    "                        DF_12 = DF_11.iloc[start:end]\n",
    "\n",
    "                        DF_12= DF_12.apply(lambda c: ' '.join(c), axis=0)\n",
    "                        DF_12 = DF_12.to_frame()\n",
    "                        DF_13 = DF_12.T\n",
    "\n",
    "                        DF_11.drop(DF_11.head(j).index, inplace = True)\n",
    "                        DF15 = DF_13.append(DF_11)\n",
    "                        DF16 = DF15.reset_index(drop = True)\n",
    "                        DF16.columns = DF16.iloc[0]\n",
    "                        FINAL = DF16[1:]\n",
    "                        FINAL['id']=k[1]\n",
    "\n",
    "\n",
    "\n",
    "                        for i in FINAL.columns:\n",
    "                            x = str(i).lower().strip()\n",
    "                            FINAL=FINAL.rename(columns= {i:x})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                        for k in CNames.itertuples(index=False):\n",
    "                            for r in DF6.itertuples(index=False):\n",
    "                                if str(k[1]) == str(r[2]):\n",
    "                                    try:\n",
    "                                        for i in FINAL.columns.tolist():\n",
    "                                            if str(i) == str(r[0]):\n",
    "                                                FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                                    except:\n",
    "                                        pass\n",
    "                        for i in FINAL.columns.tolist():\n",
    "\n",
    "                            for r in DF6.itertuples(index=False):\n",
    "\n",
    "\n",
    "\n",
    "                                if str(r[2]) == \"nan\" :\n",
    "\n",
    "                                    if str(i) == str(r[0]):\n",
    "                                        FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                        combined_final.append(FINAL)\n",
    "                    else:\n",
    "                        None\n",
    "\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass\n",
    "\n",
    "        try:\n",
    "            FINAL = pd.concat(combined_final)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            FINAL = FINAL.loc[:, FINAL.columns.notnull()]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            for col in FINAL.columns:\n",
    "                if col =='unnamed: 0':\n",
    "                    FINAL=FINAL.drop([\"unnamed: 0\"],axis=1)\n",
    "                else:\n",
    "                       None\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        Search_List = list(DF8[\"Dropping columns\"])\n",
    "        #dropping columns\n",
    "        FINAL= FINAL.drop(columns=[col for col in FINAL if col  in Search_List])\n",
    "\n",
    "        column_list = ['inpatient_outpatient']\n",
    "        for col in column_list:\n",
    "            if col not in FINAL.columns:\n",
    "                FINAL[col] = ' ' \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        df2=FINAL\n",
    "        df2 = df_column_uniquify(df2)\n",
    "        #Required format - variable list\n",
    "        Col_list = list(DF5[\"Columns\"])\n",
    "        df3=df2.melt(id_vars=[col for col in df2 if col in Col_list],var_name=\"name\",value_name='cost')\n",
    "        #df3=df1.melt(id_vars=['ID','Description','Cpt Code','Rev_Cd','Units'],var_name=\"Name\",value_name='Cost')\n",
    "\n",
    "\n",
    "\n",
    "        df4=df3\n",
    "        df4=df4[df4['cost'].notnull()]\n",
    "        df4=df4[df4['name'].notnull()]\n",
    "\n",
    "        #Dropping_columns=['Not offered','Not Contracted','N/A','Not a covered service','Not Offered','Not contracted','Not a covered service','N/A']\n",
    "        #df4 = df4[~df4['Cost'].isin(Dropping_columns)]\n",
    "        df4\n",
    "        Combined_data.append(df4)\n",
    "    Combined_data = pd.concat(Combined_data)\n",
    "\n",
    "    Combined_data\n",
    "    Combined_data.drop_duplicates()\n",
    "    #Combined_data[\"id\"]=Combined_data.id.astype('int64')\n",
    "    #Combined_data.dtypes\n",
    "\n",
    "    #Joining both hospital data with shoppable data by ID\n",
    "    #Sample_output=pd.merge(left=DHC_Hosp_data1, right=Combined_data,how='inner',left_on=['Hospital_Id'],right_on=['id'])\n",
    "    Sample_output = Combined_data\n",
    "    #Dropping the columns\n",
    "    #Sample_output.drop([\"id\"], axis = 1, inplace = True)\n",
    "    #Sample_output['inpatient-outpatient'] = np.where((Sample_output['inpatient-outpatient'] ==' ') & (Sample_output['name'].str.contains('inpatient/outpatient/drug')) , 'IP/OP', Sample_output['inpatient-outpatient'])\n",
    "    #Sample_output['inpatient-outpatient'] = np.where((Sample_output['inpatient-outpatient'] ==' ') & (Sample_output['name'].str.contains('inpatient/outpatient/drug')) , 'IP/OP', Sample_output['inpatient-outpatient'])\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains('ip & op')) , 'IP & OP', Sample_output['inpatient_outpatient'])\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains('ip & op')) , 'IP & OP', Sample_output['inpatient_outpatient'])\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains('ip/op')) , 'Inpatient', Sample_output['inpatient_outpatient'])\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains('ip/op')) , 'Outpatient', Sample_output['inpatient_outpatient'])\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains('inpatient')) , 'Inpatient', Sample_output['inpatient_outpatient'])\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains('outpatient')) , 'Outpatient', Sample_output['inpatient_outpatient'])\n",
    "    #Sample_output['inpatient-outpatient'] = np.where((Sample_output['inpatient-outpatient'] ==' ') & (Sample_output['name'].str.contains('ip')) , 'Inpatient', Sampl\n",
    "\n",
    "\n",
    "    output_path = r\"C:\\Users\\User\\Zigna AI Corp\\Zigna AI Corp - RightPx\\Hospital Application_2022-03-09\\Automation_task\\outputs\\Wideformat1016_{}.csv\"\n",
    "    Sample_output.to_csv(output_path.format((k[1])), index=False)\n",
    "    return Sample_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a1d3d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "############### longFormat1 ####################\n",
    "def longFormat1(CNames):\n",
    "    global df7\n",
    "    \n",
    "    Combined_data = []\n",
    "    combined_final = []\n",
    "    non_prep_data = []\n",
    "    #Getting the details as list from files\n",
    "    for k in CNames.itertuples(index=False):\n",
    "        f=k[0] \n",
    "        #Checking the file type- xlsx   \n",
    "        if k[2]== 'csv':\n",
    "            try:\n",
    "                df=pd.read_csv(f)\n",
    "            except:\n",
    "                df=pd.read_csv(f,encoding='latin1')\n",
    "\n",
    "            non_prep_data.append(df)\n",
    "\n",
    "        elif k[2]== 'xlsx':\n",
    "            sheet_to = pd.read_excel(f,sheet_name=None)\n",
    "\n",
    "            for sh in sheet_to.keys():\n",
    "\n",
    "                df = pd.read_excel(f,sheet_name=sh,dtype=str)\n",
    "                print(sh)\n",
    "                non_prep_data.append(df)\n",
    "\n",
    "        for j in df7.itertuples(index=False):\n",
    "            if str(k[1]) == str(j[0]):\n",
    "                s = j[1]\n",
    "\n",
    "        for df in non_prep_data:\n",
    "            try:\n",
    "                if df.iloc[:, [s]].empty == False:\n",
    "\n",
    "                    if 'Unnamed: 0' not in df.iloc[:, [0]]:\n",
    "                        if 'Primary Service and Ancillary Services' not in df.iloc[:, [2]]:\n",
    "\n",
    "                            DF_13=df.iloc[:, [s]]\n",
    "                            M=0\n",
    "                            C=0   \n",
    "\n",
    "                            for index, row in DF_13.iterrows():\n",
    "                                if(pd.notnull(row[0])):\n",
    "                                    M=M+1\n",
    "                                    break\n",
    "                                else:\n",
    "                                    C=C+1\n",
    "\n",
    "                            if C==0:\n",
    "                                #This Case works when description is in one row\n",
    "                                if \"Unnamed: 5\" in DF_13:\n",
    "                                    df.columns=df.iloc[0]\n",
    "                                    FINAL=df.drop([C])\n",
    "                                    FINAL['id']=k[1]\n",
    "                                    FINAL \n",
    "\n",
    "                                else:\n",
    "                                    #This Case works when description is not found\n",
    "                                    FINAL=df\n",
    "                                    FINAL['id']=k[1]\n",
    "                                    FINAL\n",
    "                            elif C>=1:\n",
    "                                #This Case works when description is more than 1 row\n",
    "                                #Dropping 'c' rows\n",
    "                                DF_14=df.iloc[C:]\n",
    "                                #row values as column names\n",
    "                                DF_14.columns=DF_14.iloc[0]\n",
    "                                #Dropping the row\n",
    "                                FINAL=DF_14.drop([C])\n",
    "                                FINAL['id']=k[1] \n",
    "                                FINAL \n",
    "                            else:\n",
    "                                None\n",
    "                        else:\n",
    "                            df['Shoppable Services'].fillna(method='ffill', inplace=True)\n",
    "                            df=df.rename(columns = {'Shoppable Services': 'ROWS'})\n",
    "                            df\n",
    "                            df=df[df['Primary Service and Ancillary Services']!='Primary Service and Ancillary Services']\n",
    "\n",
    "                            List_ids=[]\n",
    "                            for i in df['ROWS']:\n",
    "                                List_ids.append(i)\n",
    "\n",
    "                                List_ids=list(set(List_ids))\n",
    "\n",
    "                            combined_df = []\n",
    "                            for i in List_ids:\n",
    "                                #select one part of the data\n",
    "                                df1 = df[df['ROWS']==i] \n",
    "                                #Drop the last row\n",
    "                                #df1 = df1.iloc[:-1]\n",
    "\n",
    "                                try:\n",
    "\n",
    "                                    ds=df1.iloc[:1,:]\n",
    "\n",
    "                                    #ds.drop([\"Unnamed: 0\", \"Unnamed: 1\",\"CPT / HCPCS / ICD-10 Code\",\"Average Unit Count\",\"Rev Code\",\"Charge\"], axis = 1, inplace = True) \n",
    "                                    ds=ds[['Primary Service and Ancillary Services']] \n",
    "                                    ds=ds.reset_index(drop=True)\n",
    "                                    ds_T=ds.transpose()\n",
    "                                    DS1=ds_T.rename(columns = {0: \"CPT_Description\"}) \n",
    "                                    DS1=DS1.reset_index(drop=True)\n",
    "                                    DS1\n",
    "                                    #inpatient-outpatient\n",
    "                                    di = df1.iloc[:2,:]\n",
    "                                    #print(m)\n",
    "                                    di = di.drop([di.index[0]],axis=0)\n",
    "                                    di=di[['Primary Service and Ancillary Services']] \n",
    "                                    di=di.reset_index(drop=True)\n",
    "                                    di_T=di.transpose()\n",
    "                                    di3=di_T.rename(columns = {0: \"inpatient-outpatient1\"}) \n",
    "                                    DS4=di3.reset_index(drop=True)\n",
    "                                    DS4\n",
    "                                    #Total of Charges -PART -2\n",
    "                                    ds=df1[df1['Unnamed: 1'].notnull()]\n",
    "                                    ds.drop([\"ROWS\", \"Unnamed: 1\"], axis = 1, inplace = True) \n",
    "                                    ds=ds.reset_index(drop=True)\n",
    "                                    ds\n",
    "\n",
    "                                    #Total Charges\n",
    "                                    ds1=df1[df1['Average Unit Count']=='Total of Charges:']\n",
    "                                    ds1=ds1[['Charge']] \n",
    "                                    ds1=ds1.reset_index(drop=True)\n",
    "                                    ds1.rename(columns = {'Charge': \"Total Charges\"},inplace = True)\n",
    "                                    ds1\n",
    "\n",
    "                                    DS2=pd.concat([ds,ds1], axis=1)\n",
    "                                    DS2['LineItem_cnt']=DS2.shape[0]\n",
    "                                    C=DS2.shape[0]\n",
    "\n",
    "                                    #Payers\n",
    "                                    ds= df1.iloc[C+2:,:]\n",
    "                                    ds=ds[['Primary Service and Ancillary Services','Charge']]\n",
    "                                    ds=ds[ds['Primary Service and Ancillary Services'].notnull()]\n",
    "                                    #ds1=ds.dropna() \n",
    "\n",
    "                                    #ds['Primary Service and Ancillary Services'] = ds['Primary Service and Ancillary Services'].str.replace('Charge for', '')\n",
    "                                    ds2=ds.transpose()\n",
    "                                    ds2.columns = ds2.iloc[0] \n",
    "\n",
    "                                    #ds2=ds2.drop([\"Primary Service and Ancillary Services\"])\n",
    "                                    ds2=ds2.iloc[1:]\n",
    "                                    DS3=ds2.reset_index(drop=True)\n",
    "\n",
    "                                    DS_F=pd.concat([DS1,DS2,DS3,DS4], axis=1)\n",
    "                                    DS_F = DS_F.dropna(axis='columns', how='all')\n",
    "                                    DS_F['id']=k[1]\n",
    "\n",
    "\n",
    "                                except:\n",
    "                                    pass\n",
    "\n",
    "                                combined_df.append(DS_F)\n",
    "                                #combined_df['id']=k[1]\n",
    "                            combined_df = pd.concat(combined_df)\n",
    "                            combined_df.drop([\"Rev Code\",\"Charge\"], axis = 1, inplace = True)\n",
    "                            FINAL=combined_df[combined_df['CPT_Description'].notnull()]\n",
    "                            FINAL['CPT_Description1'] = FINAL.CPT_Description.str.split('-',1)\n",
    "                            FINAL[['CPT/HCPCS/ICD-10 Code','Cpt_description2']] = pd.DataFrame(FINAL.CPT_Description1.tolist(), index= FINAL.index)\n",
    "                            FINAL.drop([\"CPT_Description\",\"CPT_Description1\", \"Primary Service and Ancillary Services\",\"CPT / HCPCS / ICD-10 Code\"], axis = 1, inplace = True)\n",
    "                            FINAL=FINAL.rename(columns = {'Cpt_description2': \"CPT_Description\"})\n",
    "                            FINAL=FINAL[FINAL['CPT/HCPCS/ICD-10 Code'].str.len().le(8)]\n",
    "                            FINAL                  \n",
    "\n",
    "                    else:\n",
    "                        try:\n",
    "                            try:\n",
    "                                df=pd.read_csv(f)\n",
    "                            except:\n",
    "                                df=pd.read_csv(f,encoding='latin1')\n",
    "                        except:\n",
    "                            df = pd.read_excel(f, header = 1 )\n",
    "\n",
    "                        if 'Unnamed: 0' in df.iloc[:, [0]]:\n",
    "                            if 'Primary Service and Ancillary Services' not in df.iloc[:, [2]]:\n",
    "\n",
    "                                DF_13=df.iloc[:, [5]]\n",
    "                                M=0\n",
    "                                C=0\n",
    "\n",
    "                                for index, row in DF_13.iterrows():\n",
    "                                    if(pd.notnull(row[0])):\n",
    "                                        M=M+1\n",
    "                                        break\n",
    "                                    else:\n",
    "                                        C=C+1\n",
    "                                if C==0:\n",
    "                                    if \"Unnamed: 5\" in DF_13:\n",
    "                                        df.columns=df.iloc[0]\n",
    "                                        FINAL=df.drop([C])\n",
    "                                        FINAL['id']=k[1]\n",
    "                                        FINAL \n",
    "                                    else:\n",
    "                                    #This Case works when description is not found\n",
    "                                        FINAL=df\n",
    "                                        FINAL['id']=k[1]\n",
    "                                        FINAL\n",
    "                                elif C>=1:\n",
    "                                    DF_14=df.iloc[C:]\n",
    "                                        #row values as column names\n",
    "                                    DF_14.columns=DF_14.iloc[0]\n",
    "                                        #Dropping the row\n",
    "                                    FINAL=DF_14.drop([C])\n",
    "                                    FINAL['id']=k[1] \n",
    "                                    FINAL\n",
    "                                    if np.nan in FINAL:\n",
    "                                        FINAL=FINAL.rename(columns={np.nan: 'inpatient'})\n",
    "                                        FINAL\n",
    "                                        FINAL['inpatient'] = FINAL.Inpatient.str.replace('*','')\n",
    "                                        FINAL['inpatient']=FINAL['inpatient'].mask(FINAL['inpatient'].eq('')|FINAL['inpatient'].isnull()).ffill()\n",
    "                                        FINAL=FINAL.rename(columns = {'inpatient': \"inpatient-outpatient\"})\n",
    "                                        FINAL['id']=k[1] \n",
    "                                        FINAL\n",
    "                                    else:\n",
    "                                        None\n",
    "                                else:\n",
    "                                    None\n",
    "\n",
    "\n",
    "\n",
    "                            else:\n",
    "                                try:\n",
    "                                    df=pd.read_csv(f)\n",
    "                                except:\n",
    "                                    df = pd.read_excel(f, header = 1 )\n",
    "\n",
    "                                df['Unnamed: 0'].fillna(method='ffill', inplace=True)\n",
    "                                df=df.rename(columns = {'Unnamed: 0': 'ROWS'})\n",
    "                                df\n",
    "                                df=df[df['Primary Service and Ancillary Services']!='Primary Service and Ancillary Services']\n",
    "\n",
    "\n",
    "                                List_ids=[]\n",
    "                                for i in df['ROWS']:\n",
    "                                    List_ids.append(i)\n",
    "\n",
    "                                    List_ids=list(set(List_ids))\n",
    "\n",
    "                                combined_df = []\n",
    "                                for i in List_ids:\n",
    "                                    #select one part of the data\n",
    "                                    df1 = df[df['ROWS']==i] \n",
    "                                    #Drop the last row\n",
    "                                    #df1 = df1.iloc[:-1]\n",
    "\n",
    "                                    try:\n",
    "\n",
    "                                        ds=df1.iloc[:1,:]\n",
    "\n",
    "                                        #ds.drop([\"Unnamed: 0\", \"Unnamed: 1\",\"CPT / HCPCS / ICD-10 Code\",\"Average Unit Count\",\"Rev Code\",\"Charge\"], axis = 1, inplace = True) \n",
    "                                        ds=ds[['Primary Service and Ancillary Services']] \n",
    "                                        ds=ds.reset_index(drop=True)\n",
    "                                        ds_T=ds.transpose()\n",
    "                                        DS1=ds_T.rename(columns = {0: \"CPT_Description\"}) \n",
    "                                        DS1=DS1.reset_index(drop=True)\n",
    "                                        DS1\n",
    "                                        #inpatient-outpatient\n",
    "                                        di = df1.iloc[:2,:]\n",
    "                                        #print(m)\n",
    "                                        di = di.drop([di.index[0]],axis=0)\n",
    "                                        di=di[['Primary Service and Ancillary Services']] \n",
    "                                        di=di.reset_index(drop=True)\n",
    "                                        di_T=di.transpose()\n",
    "                                        di3=di_T.rename(columns = {0: \"inpatient-outpatient1\"}) \n",
    "                                        DS4=di3.reset_index(drop=True)\n",
    "                                        DS4\n",
    "                                        #Total of Charges -PART -2\n",
    "                                        ds=df1[df1['Unnamed: 1'].notnull()]\n",
    "                                        ds.drop([\"ROWS\", \"Unnamed: 1\"], axis = 1, inplace = True) \n",
    "                                        ds=ds.reset_index(drop=True)\n",
    "                                        ds\n",
    "\n",
    "                                        #Total Charges\n",
    "                                        ds1=df1[df1['Average Unit Count']=='Total of Charges:']\n",
    "                                        ds1=ds1[['Charge']] \n",
    "                                        ds1=ds1.reset_index(drop=True)\n",
    "                                        ds1.rename(columns = {'Charge': \"Total Charges\"},inplace = True)\n",
    "                                        ds1\n",
    "\n",
    "                                        DS2=pd.concat([ds,ds1], axis=1)\n",
    "                                        DS2['LineItem_cnt']=DS2.shape[0]\n",
    "                                        C=DS2.shape[0]\n",
    "\n",
    "                                        #Payers\n",
    "                                        ds= df1.iloc[C+2:,:]\n",
    "                                        ds=ds[['Primary Service and Ancillary Services','Charge']]\n",
    "                                        ds=ds[ds['Primary Service and Ancillary Services'].notnull()]\n",
    "                                        #ds1=ds.dropna() \n",
    "\n",
    "                                        #ds['Primary Service and Ancillary Services'] = ds['Primary Service and Ancillary Services'].str.replace('Charge for', '')\n",
    "                                        ds2=ds.transpose()\n",
    "                                        ds2.columns = ds2.iloc[0] \n",
    "\n",
    "                                        #ds2=ds2.drop([\"Primary Service and Ancillary Services\"])\n",
    "                                        ds2=ds2.iloc[1:]\n",
    "                                        DS3=ds2.reset_index(drop=True)\n",
    "\n",
    "                                        DS_F=pd.concat([DS1,DS2,DS3,DS4], axis=1)\n",
    "                                        #DS_F = DS_F.dropna(axis='columns', how='all')\n",
    "                                        DS_F['id']=k[1]\n",
    "\n",
    "\n",
    "                                    except:\n",
    "                                        pass\n",
    "\n",
    "                                    combined_df.append(DS_F)\n",
    "                                    #combined_df['ID']=k[1]\n",
    "                                combined_df = pd.concat(combined_df)\n",
    "                                combined_df.drop([\"Rev Code\",\"Charge\"], axis = 1, inplace = True)\n",
    "                                FINAL=combined_df[combined_df['CPT_Description'].notnull()]\n",
    "                                FINAL['CPT_Description1'] = FINAL.CPT_Description.str.split('-',1)\n",
    "                                FINAL[['CPT/HCPCS/ICD-10 Code','Cpt_description2']] = pd.DataFrame(FINAL.CPT_Description1.tolist(), index= FINAL.index)\n",
    "                                FINAL.drop([\"CPT_Description\",\"CPT_Description1\", \"Primary Service and Ancillary Services\",\"CPT / HCPCS / ICD-10 Code\"], axis = 1, inplace = True)\n",
    "                                FINAL=FINAL.rename(columns = {'Cpt_description2': \"CPT_Description\"}) \n",
    "                                FINAL=FINAL[FINAL['CPT/HCPCS/ICD-10 Code'].str.len().le(8)]\n",
    "                                FINAL\n",
    "\n",
    "                        else:\n",
    "                            None\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "\n",
    "        try:\n",
    "            FINAL[['service type','inpatient-outpatient']] = FINAL[\"inpatient-outpatient1\"].str.split(\":\", 1, expand=True)\n",
    "            FINAL.drop([\"inpatient-outpatient1\",\"service type\"], axis = 1, inplace = True)\n",
    "        except:\n",
    "            pass\n",
    "        for i in FINAL.columns:\n",
    "\n",
    "            x = str(i).lower().strip()\n",
    "            FINAL=FINAL.rename(columns= {i:x})\n",
    "\n",
    "\n",
    "        for k in CNames.itertuples(index=False):\n",
    "            for r in DF6.itertuples(index=False):\n",
    "                if str(k[1]) == str(r[2]):\n",
    "                    try:\n",
    "\n",
    "                        for i in FINAL.columns.tolist():\n",
    "                            if str(i) == str(r[0]):\n",
    "                                FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                    except:\n",
    "                        pass\n",
    "        for i in FINAL.columns.tolist():\n",
    "\n",
    "            for r in DF6.itertuples(index=False):\n",
    "\n",
    "                if str(r[2]) == \"nan\" :\n",
    "\n",
    "                    if str(i) == str(r[0]):\n",
    "                        FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "\n",
    "        Search_List = list(DF8[\"Dropping columns\"])\n",
    "            #dropping columns\n",
    "        FINAL= FINAL.drop(columns=[col for col in FINAL if col  in Search_List])\n",
    "\n",
    "\n",
    "\n",
    "        column_list = ['inpatient_outpatient']\n",
    "        for col in column_list:\n",
    "            if col not in FINAL.columns:\n",
    "                FINAL[col] = ' '\n",
    "\n",
    "\n",
    "        df2=FINAL\n",
    "        df2 = df_column_uniquify(df2)\n",
    "        #Required format - variable list\n",
    "        Col_list = list(DF5[\"Columns\"])\n",
    "        df3=df2.melt(id_vars=[col for col in df2 if col in Col_list],var_name=\"name\",value_name='cost')\n",
    "        #df3=df1.melt(id_vars=['ID','Description','Cpt Code','Rev_Cd','Units'],var_name=\"Name\",value_name='Cost')\n",
    "\n",
    "\n",
    "        df4=df3\n",
    "        df4=df4[df4['cost'].notnull()]\n",
    "        #Dropping_columns=['Not offered','Not Contracted','N/A','Not a covered service','Not Offered','Not contracted','Not a covered service','N/A']\n",
    "        #df4 = df4[~df4['Cost'].isin(Dropping_columns)]\n",
    "        df4\n",
    "        Combined_data.append(df4)\n",
    "    Combined_data = pd.concat(Combined_data)\n",
    "\n",
    "    Combined_data\n",
    "    #Combined_data[\"id\"]=Combined_data.id.astype('int64')\n",
    "    ##Combined_data.dtypes\n",
    "    Sample_output = Combined_data\n",
    "\n",
    "    output_path = r\"C:\\Users\\User\\Zigna AI Corp\\Zigna AI Corp - RightPx\\Hospital Application_2022-03-09\\Automation_task\\outputs\\Longformat1_{}.csv\"\n",
    "    Sample_output.to_csv(output_path.format((k[1])), index=False)\n",
    "    return Sample_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20674ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### longFormat1000 ########################\n",
    "def longFormat1000(CNames):\n",
    "    global df7\n",
    "    \n",
    "    Combined_data = []\n",
    "    combined_final = []\n",
    "    non_prep_data = []\n",
    "\n",
    "    for k in CNames.itertuples(index=False):\n",
    "        f=k[0]\n",
    "\n",
    "        #Checking the file type- xlsx   \n",
    "        if k[2]== 'csv':\n",
    "            try:\n",
    "                try:\n",
    "                    DF_FINAL=pd.read_csv(f)\n",
    "                except:\n",
    "                    DF_FINAL=pd.read_csv(f,sep=\"|\")\n",
    "            except:\n",
    "                DF_FINAL=pd.read_csv(f,encoding=\"latin1\")\n",
    "            non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        elif k[2]== 'xlsx':\n",
    "            sheet_to = pd.read_excel(f, sheet_name = None,dtype=str)\n",
    "            for sh in sheet_to.keys():\n",
    "                DF_FINAL=pd.read_excel(f,sheet_name=sh,dtype=str)\n",
    "                print(sh)\n",
    "                non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        for j in df7.itertuples(index=False):\n",
    "            if str(k[1]) == str(j[0]):\n",
    "                s = j[1]\n",
    "\n",
    "        for DF_FINAL in non_prep_data:\n",
    "            try:\n",
    "                if DF_FINAL.iloc[:, [s]].empty == False:\n",
    "                    DF_10=DF_FINAL.iloc[:, [s]]    \n",
    "                    m=0\n",
    "                    c=0\n",
    "\n",
    "                    #Getting the count of  empty rows..3\n",
    "                    for index, row in DF_10.iterrows():\n",
    "                        if(pd.notnull(row[0])): \n",
    "                            m=m+1\n",
    "                            break\n",
    "                        else:\n",
    "                            c=c+1\n",
    "\n",
    "                    if c==0:\n",
    "                    #This Case works when description is in one row\n",
    "                        if \"Unnamed: 0\" in DF_10:\n",
    "                            DF_FINAL.columns=DF_FINAL.iloc[0]\n",
    "                            FINAL=DF_FINAL.drop([c])\n",
    "                            FINAL['id']=k[1]\n",
    "                            for i in FINAL.columns:\n",
    "                                x = str(i).lower().strip()\n",
    "                                FINAL=FINAL.rename(columns= {i:x})    \n",
    "\n",
    "\n",
    "                            for i in FINAL.columns.tolist():\n",
    "                                for k in CNames.itertuples(index=False):\n",
    "                                    for r in DF6.itertuples(index=False):\n",
    "                                        if str(k[1]) == str(r[2]):\n",
    "                                            try:\n",
    "                                                for i in FINAL.columns.tolist():\n",
    "                                                    if str(i) == str(r[0]):\n",
    "                                                        FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                                            except:\n",
    "                                                pass\n",
    "\n",
    "                            for i in FINAL.columns.tolist():\n",
    "                                for r in DF6.itertuples(index=False):\n",
    "                                    if str(r[2]) == \"nan\" :\n",
    "                                        if str(i) == str(r[0]):\n",
    "                                            FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                            combined_final.append(FINAL)\n",
    "                        else:\n",
    "                            #This Case works when description is not found\n",
    "                            FINAL=DF_FINAL\n",
    "                            FINAL['id']=k[1]\n",
    "                            for i in FINAL.columns:\n",
    "                                x = str(i).lower().strip()\n",
    "                                FINAL=FINAL.rename(columns= {i:x})    \n",
    "\n",
    "\n",
    "                            for i in FINAL.columns.tolist():\n",
    "\n",
    "                                for k in CNames.itertuples(index=False):\n",
    "\n",
    "                                    for r in DF6.itertuples(index=False):\n",
    "\n",
    "                                        if str(k[1]) == str(r[2]):\n",
    "                                            try:\n",
    "\n",
    "                                                for i in FINAL.columns.tolist():\n",
    "\n",
    "                                                    if str(i) == str(r[0]):\n",
    "\n",
    "                                                        FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                                            except:\n",
    "                                                pass\n",
    "\n",
    "                            for i in FINAL.columns.tolist():\n",
    "\n",
    "\n",
    "                                for r in DF6.itertuples(index=False):\n",
    "\n",
    "\n",
    "\n",
    "                                    if str(r[2]) == \"nan\" :\n",
    "\n",
    "                                        if str(i) == str(r[0]):\n",
    "                                            FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                            combined_final.append(FINAL)\n",
    "\n",
    "                    elif c>=1:\n",
    "                        #This Case works when description is more than 1 row\n",
    "                        #Dropping 'c' rows\n",
    "                        DF_11=DF_FINAL.iloc[c:]\n",
    "                        #row values as column names\n",
    "                        DF_11.columns=DF_11.iloc[0]\n",
    "                        #Dropping the row\n",
    "                        FINAL=DF_11.drop([c])\n",
    "                        FINAL['id']=k[1]\n",
    "                        for i in FINAL.columns:\n",
    "                            x = str(i).lower().strip()\n",
    "                            FINAL=FINAL.rename(columns= {i:x})    \n",
    "\n",
    "\n",
    "                        for i in FINAL.columns.tolist():\n",
    "\n",
    "                            for k in CNames.itertuples(index=False):\n",
    "\n",
    "                                for r in DF6.itertuples(index=False):\n",
    "\n",
    "                                    if str(k[1]) == str(r[2]):\n",
    "                                        try:\n",
    "\n",
    "                                            for i in FINAL.columns.tolist():\n",
    "\n",
    "                                                if str(i) == str(r[0]):\n",
    "\n",
    "                                                    FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                                        except:\n",
    "                                            pass\n",
    "\n",
    "                        for i in FINAL.columns.tolist():\n",
    "\n",
    "\n",
    "                            for r in DF6.itertuples(index=False):\n",
    "\n",
    "\n",
    "\n",
    "                                if str(r[2]) == \"nan\" :\n",
    "\n",
    "                                    if str(i) == str(r[0]):\n",
    "                                        FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                        combined_final.append(FINAL)\n",
    "                    else:\n",
    "                        None    \n",
    "\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass\n",
    "\n",
    "        combined_final.append(FINAL)    \n",
    "        try:\n",
    "            FINAL = pd.concat(combined_final)\n",
    "        except:\n",
    "            pass    \n",
    "\n",
    "        try:\n",
    "            FINAL = FINAL.loc[:, FINAL.columns.notnull()]    \n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            FINAL = FINAL.loc[:, ~FINAL.columns.str.contains('^unnamed')]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            for col in FINAL.columns:\n",
    "                if col =='unnamed: 0':\n",
    "                    FINAL=FINAL.drop([\"unnamed: 0\"],axis=1)\n",
    "                else:\n",
    "                       None\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        Search_List = list(DF8[\"Dropping columns\"])\n",
    "        try:\n",
    "            try:\n",
    "                FINAL[\"plan\"]=FINAL[\"plan\"].astype(str)\n",
    "                FINAL['payer_name'] = FINAL['payer_name'].astype(str)\n",
    "                FINAL['payer_name'] = FINAL[['payer_name','plan']].apply(lambda x: ' '.join(x), axis=1)\n",
    "                FINAL = FINAL.drop(['plan'],axis = 1)\n",
    "            except:\n",
    "                FINAL['payer_name'] = FINAL['payer_name'].astype(str)\n",
    "                FINAL['payer_name'] = FINAL[['payer_name']].apply(lambda x: ' '.join(x), axis=1)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        FINAL= FINAL.drop(columns=[col for col in FINAL if col in Search_List])\n",
    "        df2=FINAL\n",
    "        df2 = df_column_uniquify(df2)\n",
    "        # renaming column made the payor to name.So, manually renamed name to name1 \n",
    "        # name1 is stored in idvars list\n",
    "        try:\n",
    "            try:\n",
    "                df2.rename(columns = {'name': 'name1'}, inplace = True)\n",
    "            except:\n",
    "                pass\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        column_list = ['inpatient_outpatient']\n",
    "        for col in column_list:\n",
    "            if col not in FINAL.columns:\n",
    "                FINAL[col] = ' '\n",
    "\n",
    "        #Required format - variable list\n",
    "\n",
    "        Col_list = list(DF5[\"Columns\"])\n",
    "        df3=df2.melt(id_vars=[col for col in df2 if col in Col_list],var_name=\"name\",value_name='cost')   \n",
    "        df4=df3\n",
    "\n",
    "        try:\n",
    "            try:\n",
    "                df4['name'] = df4[['payer_name', 'name']].apply(lambda x: ' '.join(x), axis=1)\n",
    "            except:\n",
    "                df4['name'] = df4[['name1', 'name']].apply(lambda x: ' '.join(x), axis=1)  \n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "\n",
    "        df4=df4[df4['cost'].notnull()]\n",
    "        try:\n",
    "            df4=df4[df4['hcpcs'].notnull()]\n",
    "        except:\n",
    "            pass\n",
    "        Combined_data.append(df4)\n",
    "    Combined_data = pd.concat(Combined_data)\n",
    "    Combined_data\n",
    "    try:\n",
    "        try:\n",
    "            Combined_data = Combined_data.drop(['payer_name'],axis = 1)\n",
    "        except:\n",
    "            # manually dropped because name is in idvars list\n",
    "            Combined_data = Combined_data.drop(['name1'],axis = 1)\n",
    "    except:\n",
    "        pass\n",
    "    #Combined_data[\"id\"]=Combined_data.id.astype('int64')\n",
    "    #Combined_data.dtypes\n",
    "    Combined_data = Combined_data.drop_duplicates()\n",
    "    try:\n",
    "        Combined_data['inpatient_outpatient'] = np.where((Combined_data['inpatient_outpatient'] ==' ') & (Combined_data['name'].str.contains('inpatient')) , 'Inpatient', Combined_data['inpatient_outpatient'])\n",
    "        Combined_data['inpatient_outpatient'] = np.where((Combined_data['inpatient_outpatient'] ==' ') & (Combined_data['name'].str.contains('outpatient')) , 'Outpatient', Combined_data['inpatient_outpatient'])\n",
    "        Combined_data['inpatient_outpatient'] = np.where((Combined_data['inpatient_outpatient'] ==' ') & (Combined_data['name'].str.contains(' ip')) , 'Inpatient', Combined_data['inpatient_outpatient'])\n",
    "        Combined_data['inpatient_outpatient'] = np.where((Combined_data['inpatient_outpatient'] ==' ') & (Combined_data['name'].str.contains(' op')) , 'Outpatient', Combined_data['inpatient_outpatient'])\n",
    "    except:\n",
    "        pass\n",
    "    Sample_output = Combined_data\n",
    "    Sample_output['name'] = np.where(Sample_output['name'].str.contains('gross charges'), 'gross charge',Sample_output['name'])\n",
    "    Sample_output['name'] = np.where(Sample_output['name'].str.contains('self_pay'), 'self_pay',Sample_output['name'])\n",
    "    Sample_output['name'] = np.where(Sample_output['name'].str.contains('grosscharge'), 'grosscharge',Sample_output['name'])\n",
    "    Sample_output['name'] = np.where(Sample_output['name'].str.contains('gross charge'), 'gross charge',Sample_output['name'])\n",
    "    Sample_output['name'] = np.where(Sample_output['name'].str.contains('gross_charges'), 'gross charge',Sample_output['name'])\n",
    "    Sample_output['name'] = np.where(Sample_output['name'].str.contains('gross_charge'), 'gross charge',Sample_output['name'])\n",
    "\n",
    "\n",
    "    output_path = r\"C:\\Users\\User\\Zigna AI Corp\\Zigna AI Corp - RightPx\\Hospital Application_2022-03-09\\Automation_task\\outputs\\longFormat1000_{}.csv\"\n",
    "    Sample_output.to_csv(output_path.format(k[1]), index=False)\n",
    "    return Sample_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d99c073",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################### longFormat10 ################\n",
    "def longFormat10(CNames):\n",
    "    global df7\n",
    "    \n",
    "    Combined_data = []\n",
    "    combined_final = []\n",
    "    non_prep_data = []\n",
    "    #Getting the details as list from files\n",
    "    for k in CNames.itertuples(index=False):\n",
    "        f=k[0] \n",
    "        #Checking the file type- xlsx   \n",
    "        if k[2]== 'csv':\n",
    "            try:\n",
    "                DF_FINAL=pd.read_csv(f)\n",
    "            except:\n",
    "                DF_FINAL=pd.read_csv(f,encoding='latin1')\n",
    "\n",
    "\n",
    "        elif k[2]== 'xlsx':\n",
    "            sheet_to = pd.read_excel(f,sheet_name=None,dtype=str)\n",
    "\n",
    "            for sh in sheet_to.keys():\n",
    "\n",
    "                DF_FINAL = pd.read_excel(f,sheet_name=sh,dtype=str)\n",
    "                print(sh)\n",
    "\n",
    "\n",
    "                non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        for j in df7.itertuples(index=False):\n",
    "            if str(k[1]) == str(j[0]):\n",
    "                s = j[1]\n",
    "\n",
    "        for DF_FINAL in non_prep_data:\n",
    "\n",
    "\n",
    "            try:\n",
    "                if DF_FINAL.iloc[:, [s]].empty == False:\n",
    "\n",
    "\n",
    "                    DF_10 = DF_FINAL.iloc[:,[s]]\n",
    "                    m=0\n",
    "                    c=0\n",
    "\n",
    "            #Getting the count of  empty rows\n",
    "                for index, row in DF_10.iterrows():\n",
    "                    if(pd.notnull(row[0])): \n",
    "                        m=m+1\n",
    "                        break\n",
    "                    else:\n",
    "                        c=c+1\n",
    "\n",
    "\n",
    "                if c==0:\n",
    "                #This Case works when description is in one row\n",
    "                    if \"Unnamed: 0\" in DF_10:\n",
    "                        DF_FINAL.columns=DF_FINAL.iloc[0]\n",
    "                        FINAL=DF_FINAL.drop([c])\n",
    "                        FINAL['id']=k[1]\n",
    "                        FINAL\n",
    "                    else:\n",
    "                        #This Case works when description is not found\n",
    "                        #DF_FINAL = DF_FINAL.drop(['Unnamed: 0'],axis = 1)\n",
    "                        FINAL=DF_FINAL\n",
    "                        FINAL['id']=k[1]\n",
    "                        FINAL\n",
    "\n",
    "                elif c>=1:\n",
    "                    #This Case works when description is more than 1 row\n",
    "                    #Dropping 'c' rows\n",
    "                    DF_11=DF_FINAL.iloc[c:]\n",
    "                    #row values as column names\n",
    "                    DF_11.columns=DF_11.iloc[0]\n",
    "                    #Dropping the row\n",
    "                    FINAL=DF_11.drop([c])\n",
    "                    FINAL['id']=k[1]\n",
    "                else:\n",
    "                    None   \n",
    "\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass\n",
    "\n",
    "        # if CNames['id'].isin(['3073']).any():\n",
    "        #     try:\n",
    "        #         FINAL.drop(['HospitalDescription','StandardChargeQuantity','FootnoteReference'],axis=1,inplace=True)\n",
    "        #         FINAL= FINAL.rename(columns ={'ServiceType': \"inpatient-outpatient\",'ChargeCode':\"Procedure/Charge Number\",'Code':\"CPT/HCPCS\"})\n",
    "        #     except:\n",
    "        #         None\n",
    "        for i in FINAL.columns:\n",
    "\n",
    "            x = str(i).lower().strip()\n",
    "            FINAL=FINAL.rename(columns= {i:x}) \n",
    "        for i in FINAL.columns.tolist():\n",
    "\n",
    "            for k in CNames.itertuples(index=False):\n",
    "\n",
    "                for r in DF6.itertuples(index=False):\n",
    "\n",
    "                    if str(k[1]) == str(r[2]):\n",
    "                        try:\n",
    "\n",
    "                            for i in FINAL.columns.tolist():\n",
    "\n",
    "                                if str(i) == str(r[0]):\n",
    "\n",
    "                                    FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                        except:\n",
    "                                pass\n",
    "\n",
    "        for i in FINAL.columns.tolist():\n",
    "            for r in DF6.itertuples(index=False):\n",
    "                if str(r[2]) == \"nan\" :\n",
    "                    if str(i) == str(r[0]):\n",
    "                        FINAL.rename(columns={i:r[1]}, inplace=True) \n",
    "\n",
    "        Search_List = list(DF8[\"Dropping columns\"])\n",
    "        #dropping columns\n",
    "        FINAL= FINAL.drop(columns=[col for col in FINAL if col  in Search_List])\n",
    "\n",
    "\n",
    "        column_list = ['inpatient-outpatient']\n",
    "        for col in column_list:\n",
    "            if col not in FINAL.columns:\n",
    "                FINAL[col] = ' '\n",
    "        FINAL['inpatient-outpatient'] = FINAL['inpatient-outpatient'].str.lower()\n",
    "        #Checking the  Inpatient/Outpatient column exists or not\n",
    "\n",
    "        try:\n",
    "            FINAL[\"payer_name\"]=FINAL[\"payer_name\"].astype(str)\n",
    "            #FINAL[\"Benfit Type\"]=FINAL[\"Benfit Type\"].astype(str)\n",
    "            FINAL['payer_name'] = FINAL[['payer_name']].apply(lambda x: ' '.join(x), axis=1)\n",
    "            #FINAL = FINAL.drop(['Benfit Type'],axis = 1)\n",
    "        except:\n",
    "            pass\n",
    "        # FINAL= FINAL.drop(columns=[col for col in FINAL if col in Search_List])\n",
    "        try:\n",
    "            FINAL['inpatient-outpatient'] = FINAL['inpatient-outpatient'].str.lower()\n",
    "        except:\n",
    "            None\n",
    "        #Search_List = list(DF3[\"Keeping columns\"])\n",
    "        #Keeping columns\n",
    "        #df1= FINAL.drop(columns=[col for col in FINAL if col not in Search_List])\n",
    "        #Removing the empty rows from'cpt code'\n",
    "        #df2 = df1.dropna(axis=0, subset=['Cpt Code'])\n",
    "\n",
    "        #df2=FINAL[FINAL['cpt code'].notnull()] \n",
    "\n",
    "        df2=FINAL\n",
    "        df2 = df_column_uniquify(df2)\n",
    "        #Required format - variable list\n",
    "\n",
    "        Col_list = list(DF5[\"Columns\"])\n",
    "        df3=df2.melt(id_vars=[col for col in df2 if col in Col_list],var_name=\"name\",value_name='cost')\n",
    "\n",
    "        #df3=df1.melt(id_vars=['ID','Description','Cpt Code','Rev_Cd','Units'],var_name=\"Name\",value_name='Cost')\n",
    "        try:\n",
    "            df3['name'] = df3[['payer_name', 'name']].apply(lambda x: ' '.join(x), axis=1)\n",
    "            df3 = df3.drop(['payer_name'],axis=1)\n",
    "        except:\n",
    "            None\n",
    "\n",
    "\n",
    "        df4=df3\n",
    "        df4=df4[df4['cost'].notnull()]\n",
    "        #Dropping_columns=['Not offered','Not Contracted','N/A','Not a covered service','Not Offered','Not contracted','Not a covered service','N/A']\n",
    "        #df4 = df4[~df4['Cost'].isin(Dropping_columns)]\n",
    "        df4\n",
    "        Combined_data.append(df4)\n",
    "    Combined_data = pd.concat(Combined_data)\n",
    "\n",
    "    Combined_data\n",
    "    #Combined_data[\"id\"]=Combined_data.id.astype('int64')\n",
    "    #Combined_data.dtypes\n",
    "    # \n",
    "\n",
    "    try:\n",
    "        Combined_data['inpatient_outpatient'] = np.where((Combined_data['inpatient_outpatient'] ==' ') & (Combined_data['name'].str.contains('inpatient')) , 'Inpatient', Combined_data['inpatient_outpatient'])\n",
    "        Combined_data['inpatient_outpatient'] = np.where((Combined_data['inpatient_outpatient'] ==' ') & (Combined_data['name'].str.contains('outpatient')) , 'Outpatient', Combined_data['inpatient_outpatient'])\n",
    "        Combined_data['inpatient_outpatient'] = np.where((Combined_data['inpatient_outpatient'] ==' ') & (Combined_data['name'].str.contains('ip')) , 'Inpatient', Combined_data['inpatient_outpatient'])\n",
    "        Combined_data['inpatient_outpatient'] = np.where((Combined_data['inpatient_outpatient'] ==' ') & (Combined_data['name'].str.contains('op')) , 'Outpatient', Combined_data['inpatient_outpatient'])\n",
    "    except:\n",
    "        pass\n",
    "    Sample_output = Combined_data\n",
    "    Sample_output['name'] = np.where(Sample_output['name'].str.contains('gross charges'), 'gross charge',Sample_output['name'])\n",
    "    Sample_output['name'] = np.where(Sample_output['name'].str.contains('self_pay'), 'self_pay',Sample_output['name'])\n",
    "    Sample_output['name'] = np.where(Sample_output['name'].str.contains('grosscharge'), 'grosscharge',Sample_output['name'])\n",
    "    Sample_output['name'] = np.where(Sample_output['name'].str.contains('gross charge'), 'gross charge',Sample_output['name'])\n",
    "    \n",
    "    output_path = r\"C:\\Users\\User\\Zigna AI Corp\\Zigna AI Corp - RightPx\\Hospital Application_2022-03-09\\Automation_task\\outputs\\longFormat10_{}.csv\"\n",
    "    Sample_output.to_csv(output_path.format(k[1]), index=False)\n",
    "    return Sample_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5dccfa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "################ longFormat2_1 ###############\n",
    "def longFormat2_1(CNames):\n",
    "    global df7\n",
    "    \n",
    "    Combined_data = []\n",
    "    combined_final = []\n",
    "    non_prep_data = []\n",
    "    #Getting the details as list from files\n",
    "    for k in CNames.itertuples(index=False):\n",
    "        f=k[0] \n",
    "        #Checking the file type- xlsx   \n",
    "        if k[2]== 'csv':\n",
    "            try:\n",
    "                df=pd.read_csv(f)\n",
    "            except:\n",
    "                df=pd.read_csv(f,encoding='latin1')\n",
    "\n",
    "            non_prep_data.append(df)\n",
    "\n",
    "        elif k[2]== 'xlsx':\n",
    "            sheet_to = pd.read_excel(f,sheet_name=None)\n",
    "\n",
    "            for sh in sheet_to.keys():\n",
    "\n",
    "                df = pd.read_excel(f,sheet_name=sh,dtype=str)\n",
    "                print(sh)\n",
    "                non_prep_data.append(df)\n",
    "\n",
    "        for j in df7.itertuples(index=False):\n",
    "            if str(k[1]) == str(j[0]):\n",
    "                s = j[1]\n",
    "\n",
    "        for df in non_prep_data:\n",
    "            try:\n",
    "                if df.iloc[:, [5]].empty == False:\n",
    "\n",
    "\n",
    "                    # if 'Unnamed: 0' not in df.iloc[:, [0]]:\n",
    "                    #     if 'Primary Service and Ancillary Services' not in df.iloc[:, [2]]:\n",
    "\n",
    "                    DF_13=df.iloc[:, [5]]\n",
    "                    M=0\n",
    "                    C=0   \n",
    "\n",
    "                    for index, row in DF_13.iterrows():\n",
    "                        if(pd.notnull(row[0])):\n",
    "                            M=M+1\n",
    "                            break\n",
    "                        else:\n",
    "                            C=C+1\n",
    "\n",
    "                    if C==0:\n",
    "                #This Case works when description is in one row\n",
    "                        if \"Unnamed: 3\" in DF_13:\n",
    "                            df.columns=df.iloc[0]\n",
    "                            FINAL=df.drop([C])\n",
    "                            FINAL['id']=k[1]\n",
    "                            FINAL \n",
    "\n",
    "                        else:\n",
    "                                    #This Case works when description is not found\n",
    "                            FINAL=df\n",
    "                            FINAL['id']=k[1]\n",
    "                            FINAL\n",
    "                    elif C>=1:\n",
    "                                #This Case works when description is more than 1 row\n",
    "                                #Dropping 'c' rows\n",
    "                        DF_14=df.iloc[C:]\n",
    "                                #row values as column names\n",
    "                        DF_14.columns=DF_14.iloc[0]\n",
    "                                #Dropping the row\n",
    "                        FINAL=DF_14.drop([C])\n",
    "                        FINAL['id']=k[1] \n",
    "                        FINAL\n",
    "\n",
    "                    else:\n",
    "                        None\n",
    "\n",
    "\n",
    "                    df1=FINAL.dropna(axis = 0, how = 'all')\n",
    "                    df1['Primary Service and Ancillary Services'] = np.where((df1['Shoppable Service'].notnull())&(df1['Primary Service and Ancillary Services'].isnull()),df1['Shoppable Service'],df1['Primary Service and Ancillary Services'])\n",
    "                    df1['CPT/HCPCS ICD-10 Codes_1'] = np.where((df1['Shoppable Service'].notnull())&(df1['Primary Service and Ancillary Services'].notnull())&(df1['CPT/HCPCS ICD-10 Codes'].notnull()),df1['CPT/HCPCS ICD-10 Codes'], \"\")\n",
    "                    df2 = df1.replace(r'^\\s*$', np.NaN, regex=True)\n",
    "                    df2['CPT/HCPCS ICD-10 Codes_1'].fillna(method='ffill', inplace=True)\n",
    "                    df2=df2.rename(columns = {'CPT/HCPCS ICD-10 Codes_1': 'ROWS'})\n",
    "                    df3=df2[df2['Primary Service and Ancillary Services']!='Primary Service and Ancillary Services']\n",
    "\n",
    "                    List_ids=[]\n",
    "                    for i in df3['ROWS']:\n",
    "                        List_ids.append(i)\n",
    "\n",
    "                        List_ids=list(set(List_ids))\n",
    "\n",
    "                    combined_df = []\n",
    "                    for i in List_ids:\n",
    "                    #select one part of the data\n",
    "                        df4 = df3[df3['ROWS']==i] \n",
    "\n",
    "                        try:\n",
    "                            ds=df4.iloc[:1,:] \n",
    "                            ds=ds[['ROWS']]\n",
    "                            ds=ds.reset_index(drop=True)\n",
    "                            ds_T=ds.transpose()\n",
    "\n",
    "                            DS1=ds_T.rename(columns = {0: \"CPT_code\"}) \n",
    "                            DS1=DS1.reset_index(drop=True)\n",
    "\n",
    "                            ds=df4[df4['Primary Service and Ancillary Services'].notnull()]\n",
    "                            ds\n",
    "\n",
    "                            ds_1=ds[ds['CPT/HCPCS ICD-10 Codes'].notnull()]\n",
    "                            ds_1\n",
    "\n",
    "                            ds_1.drop([\"ROWS\"], axis = 1, inplace = True) \n",
    "                            ds_1=ds_1.reset_index(drop=True)\n",
    "                            ds_1\n",
    "\n",
    "                            ds1=df4[df4['Primary Service and Ancillary Services']=='Total of Standard Charges']\n",
    "                            ds1=ds1[[' Standard Charge ']]\n",
    "                            ds1=ds1.reset_index(drop=True)\n",
    "                            ds1.rename(columns = {' Standard Charge ': \"Total Charges\"},inplace = True)\n",
    "                            ds1\n",
    "\n",
    "                            DS2=pd.concat([ds_1,ds1], axis=1)\n",
    "                            DS2 \n",
    "\n",
    "                            DS2['LineItem_cnt']=DS2.shape[0]\n",
    "                            C=DS2.shape[0]\n",
    "                            ds= df4.iloc[C+2:,:]\n",
    "                            ds=ds[['Primary Service and Ancillary Services',' Standard Charge ']]\n",
    "                            ds=ds[ds['Primary Service and Ancillary Services'].notnull()]\n",
    "                            a=['Total of Standard Charges']\n",
    "\n",
    "                            ds = ds[~ds['Primary Service and Ancillary Services'].isin(a)]\n",
    "                            ds2=ds.transpose()\n",
    "                            ds2.reset_index(drop=True,inplace=True)\n",
    "                            ds2.columns = ds2.iloc[0]\n",
    "\n",
    "                            ds2=ds2.iloc[1:]\n",
    "                            ds2.reset_index(drop=True,inplace=True)\n",
    "                            DS_F=pd.concat([DS1,DS2,ds2], axis=1)\n",
    "                            DS_F = DS_F.dropna(axis='columns', how='all')\n",
    "                            DS_F.drop([\"Primary Service and Ancillary Services\",\"CPT/HCPCS ICD-10 Codes\",\" Standard Charge \"], axis = 1, inplace = True)\n",
    "                            FINAL1=DS_F[DS_F['Shoppable Service'].notnull()]\n",
    "                            FINAL1=FINAL1.rename(columns = {'CPT_code': \"CPT/HCPCS/ICD-10 Code\",\"Shoppable Service\":\"description\"})\n",
    "                            FINAL1\n",
    "                        except:pass\n",
    "                        combined_df.append(FINAL1)\n",
    "                                    #combined_df['ID']=k[1]\n",
    "                    combined_df = pd.concat(combined_df)\n",
    "                else:\n",
    "                    None\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass\n",
    "\n",
    "\n",
    "\n",
    "        FINAL = combined_df\n",
    "\n",
    "\n",
    "        for i in FINAL.columns:\n",
    "\n",
    "            x = str(i).lower().strip()\n",
    "            FINAL=FINAL.rename(columns= {i:x}) \n",
    "        for i in FINAL.columns.tolist():\n",
    "\n",
    "            for k in CNames.itertuples(index=False):\n",
    "\n",
    "                for r in DF6.itertuples(index=False):\n",
    "\n",
    "                    if str(k[1]) == str(r[2]):\n",
    "                        try:\n",
    "\n",
    "                            for i in FINAL.columns.tolist():\n",
    "\n",
    "                                if str(i) == str(r[0]):\n",
    "\n",
    "                                    FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                        except:\n",
    "                                pass\n",
    "\n",
    "        for i in FINAL.columns.tolist():\n",
    "            for r in DF6.itertuples(index=False):\n",
    "                if str(r[2]) == \"nan\" :\n",
    "                    if str(i) == str(r[0]):\n",
    "                        FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "        Search_List = list(DF8[\"Dropping columns\"])\n",
    "        #dropping columns\n",
    "        FINAL= FINAL.drop(columns=[col for col in FINAL if col  in Search_List])\n",
    "\n",
    "        column_list = ['inpatient-outpatient']\n",
    "        for col in column_list:\n",
    "            if col not in FINAL.columns:\n",
    "                FINAL[col] = ' '\n",
    "\n",
    "        #Search_List = list(DF3[\"Keeping columns\"])\n",
    "        #Keeping columns\n",
    "        #df1= FINAL.drop(columns=[col for col in FINAL if col not in Search_List])\n",
    "        #Removing the empty rows from'cpt code'\n",
    "        #df2 = df1.dropna(axis=0, subset=['Cpt Code'])\n",
    "\n",
    "        #df2=FINAL[FINAL['cpt code'].notnull()] \n",
    "\n",
    "        df_2=FINAL\n",
    "        df_2 = df_column_uniquify(df_2)\n",
    "        #Required format - variable list\n",
    "        Col_list = list(DF5[\"Columns\"])\n",
    "        df_3=df_2.melt(id_vars=[col for col in df_2 if col in Col_list],var_name=\"name\",value_name='cost')\n",
    "        #df3=df1.melt(id_vars=['ID','Description','Cpt Code','Rev_Cd','Units'],var_name=\"Name\",value_name='Cost')\n",
    "\n",
    "        #df3['payer'] = None\n",
    "        #df3['insurance Type'] = None\n",
    "        #df3['Benefit Type']=None\n",
    "\n",
    "        #Name_List = list(DF1[\"Payers\"])\n",
    "\n",
    "        #Name_List1 = list(DF2[\"Insurance Type\"])\n",
    "\n",
    "        #Name_List2 = list(DF3[\"Benefit Type\"])\n",
    "\n",
    "        #Finding Payers from the list\n",
    "        #for i in Name_List:\n",
    "        #    df3['payer'][(df3['name'].str.contains(i,case=False,na=False))] = i\n",
    "        #Finding Insurancetype from the list    \n",
    "        #for j in Name_List1:\n",
    "        #    df3['insurance Type'][(df3['name'].str.contains(j,case=False,na=False))] = j\n",
    "\n",
    "        #Finding Benefit Type from the list  \n",
    "        #for k in Name_List2:\n",
    "        #    df3['Benefit Type'][(df3['name'].str.contains(k,case=False,na=False))] = k \n",
    "\n",
    "        df_4=df_3\n",
    "        df_4=df_4[df_4['cost'].notnull()]\n",
    "        #Dropping_columns=['Not offered','Not Contracted','N/A','Not a covered service','Not Offered','Not contracted','Not a covered service','N/A']\n",
    "        #df4 = df4[~df4['Cost'].isin(Dropping_columns)]\n",
    "        df_4\n",
    "        Combined_data.append(df_4)\n",
    "    Combined_data = pd.concat(Combined_data)\n",
    "\n",
    "    Combined_data\n",
    "    output_path = r\"C:\\Users\\User\\Zigna AI Corp\\Zigna AI Corp - RightPx\\Hospital Application_2022-03-09\\Automation_task\\outputs\\longFormat2_1_{}.csv\"\n",
    "    Combined_data.to_csv(output_path.format(k[1]), index=False)\n",
    "    return Combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dcc21dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### longFormat2 ####################\n",
    "def longFormat2(CNames):\n",
    "    global df7\n",
    "    \n",
    "    Combined_data = []\n",
    "    combined_final = []\n",
    "    non_prep_data = []\n",
    "    #Getting the details as list from files\n",
    "    for k in CNames.itertuples(index=False):\n",
    "        f=k[0] \n",
    "        #Checking the file type- xlsx   \n",
    "        if k[2]== 'csv':\n",
    "            try:\n",
    "                df=pd.read_csv(f)\n",
    "            except:\n",
    "                df=pd.read_csv(f,encoding='latin1')\n",
    "\n",
    "            non_prep_data.append(df)\n",
    "\n",
    "        elif k[2]== 'xlsx':\n",
    "            sheet_to = pd.read_excel(f,sheet_name=None)\n",
    "\n",
    "            for sh in sheet_to.keys():\n",
    "\n",
    "                df = pd.read_excel(f,sheet_name=sh,dtype=str)\n",
    "                print(sh)\n",
    "                non_prep_data.append(df)\n",
    "\n",
    "        for j in df7.itertuples(index=False):\n",
    "            if str(k[1]) == str(j[0]):\n",
    "                s = j[1]\n",
    "\n",
    "        for df in non_prep_data:\n",
    "            try:\n",
    "                if df.iloc[:, [s]].empty == False:\n",
    "\n",
    "                    if 'Unnamed: 0' not in df.iloc[:, [0]]:\n",
    "                        if 'Primary Service and Ancillary Services' not in df.iloc[:, [2]]:\n",
    "\n",
    "                            DF_13=df.iloc[:, [s]]\n",
    "                            M=0\n",
    "                            C=0   \n",
    "\n",
    "                            for index, row in DF_13.iterrows():\n",
    "                                if(pd.notnull(row[0])):\n",
    "                                    M=M+1\n",
    "                                    break\n",
    "                                else:\n",
    "                                    C=C+1\n",
    "\n",
    "                            if C==0:\n",
    "                                #This Case works when description is in one row\n",
    "                                if \"Unnamed: 5\" in DF_13:\n",
    "                                    df.columns=df.iloc[0]\n",
    "                                    FINAL=df.drop([C])\n",
    "                                    FINAL['id']=k[1]\n",
    "                                    FINAL \n",
    "\n",
    "                                else:\n",
    "                                    #This Case works when description is not found\n",
    "                                    FINAL=df\n",
    "                                    FINAL['id']=k[1]\n",
    "                                    FINAL\n",
    "                            elif C>=1:\n",
    "                                #This Case works when description is more than 1 row\n",
    "                                #Dropping 'c' rows\n",
    "                                DF_14=df.iloc[C:]\n",
    "                                #row values as column names\n",
    "                                DF_14.columns=DF_14.iloc[0]\n",
    "                                #Dropping the row\n",
    "                                FINAL=DF_14.drop([C])\n",
    "                                FINAL['id']=k[1] \n",
    "                                FINAL \n",
    "                            else:\n",
    "                                None\n",
    "                        else:\n",
    "                            df['Shoppable Services'].fillna(method='ffill', inplace=True)\n",
    "                            df=df.rename(columns = {'Shoppable Services': 'ROWS'})\n",
    "                            df\n",
    "                            df=df[df['Primary Service and Ancillary Services']!='Primary Service and Ancillary Services']\n",
    "\n",
    "                            List_ids=[]\n",
    "                            for i in df['ROWS']:\n",
    "                                List_ids.append(i)\n",
    "\n",
    "                                List_ids=list(set(List_ids))\n",
    "\n",
    "                            combined_df = []\n",
    "                            for i in List_ids:\n",
    "                                #select one part of the data\n",
    "                                df1 = df[df['ROWS']==i] \n",
    "                                #Drop the last row\n",
    "                                #df1 = df1.iloc[:-1]\n",
    "\n",
    "                                try:\n",
    "\n",
    "                                    ds=df1.iloc[:1,:]\n",
    "\n",
    "                                    #ds.drop([\"Unnamed: 0\", \"Unnamed: 1\",\"CPT / HCPCS / ICD-10 Code\",\"Average Unit Count\",\"Rev Code\",\"Charge\"], axis = 1, inplace = True) \n",
    "                                    ds=ds[['Primary Service and Ancillary Services']] \n",
    "                                    ds=ds.reset_index(drop=True)\n",
    "                                    ds_T=ds.transpose()\n",
    "                                    DS1=ds_T.rename(columns = {0: \"CPT_Description\"}) \n",
    "                                    DS1=DS1.reset_index(drop=True)\n",
    "                                    DS1\n",
    "                                    #inpatient-outpatient\n",
    "                                    di = df1.iloc[:2,:]\n",
    "                                    #print(m)\n",
    "                                    di = di.drop([di.index[0]],axis=0)\n",
    "                                    di=di[['Primary Service and Ancillary Services']] \n",
    "                                    di=di.reset_index(drop=True)\n",
    "                                    di_T=di.transpose()\n",
    "                                    di3=di_T.rename(columns = {0: \"inpatient-outpatient1\"}) \n",
    "                                    DS4=di3.reset_index(drop=True)\n",
    "                                    DS4\n",
    "                                    #Total of Charges -PART -2\n",
    "                                    ds=df1[df1['Unnamed: 1'].notnull()]\n",
    "                                    ds.drop([\"ROWS\", \"Unnamed: 1\"], axis = 1, inplace = True) \n",
    "                                    ds=ds.reset_index(drop=True)\n",
    "                                    ds\n",
    "\n",
    "                                    #Total Charges\n",
    "                                    ds1=df1[df1['Average Unit Count']=='Total of Charges:']\n",
    "                                    ds1=ds1[['Charge']] \n",
    "                                    ds1=ds1.reset_index(drop=True)\n",
    "                                    ds1.rename(columns = {'Charge': \"Total Charges\"},inplace = True)\n",
    "                                    ds1\n",
    "\n",
    "                                    DS2=pd.concat([ds,ds1], axis=1)\n",
    "                                    DS2['LineItem_cnt']=DS2.shape[0]\n",
    "                                    C=DS2.shape[0]\n",
    "\n",
    "                                    #Payers\n",
    "                                    ds= df1.iloc[C+2:,:]\n",
    "                                    ds=ds[['Primary Service and Ancillary Services','Charge']]\n",
    "                                    ds=ds[ds['Primary Service and Ancillary Services'].notnull()]\n",
    "                                    #ds1=ds.dropna() \n",
    "\n",
    "                                    #ds['Primary Service and Ancillary Services'] = ds['Primary Service and Ancillary Services'].str.replace('Charge for', '')\n",
    "                                    ds2=ds.transpose()\n",
    "                                    ds2.columns = ds2.iloc[0] \n",
    "\n",
    "                                    #ds2=ds2.drop([\"Primary Service and Ancillary Services\"])\n",
    "                                    ds2=ds2.iloc[1:]\n",
    "                                    DS3=ds2.reset_index(drop=True)\n",
    "\n",
    "                                    DS_F=pd.concat([DS1,DS2,DS3,DS4], axis=1)\n",
    "                                    DS_F = DS_F.dropna(axis='columns', how='all')\n",
    "                                    DS_F['id']=k[1]\n",
    "\n",
    "\n",
    "                                except:\n",
    "                                    pass\n",
    "\n",
    "                                combined_df.append(DS_F)\n",
    "                                #combined_df['id']=k[1]\n",
    "                            combined_df = pd.concat(combined_df)\n",
    "                            combined_df.drop([\"Rev Code\",\"Charge\"], axis = 1, inplace = True)\n",
    "                            FINAL=combined_df[combined_df['CPT_Description'].notnull()]\n",
    "                            FINAL['CPT_Description1'] = FINAL.CPT_Description.str.split('-',1)\n",
    "                            FINAL[['CPT/HCPCS/ICD-10 Code','Cpt_description2']] = pd.DataFrame(FINAL.CPT_Description1.tolist(), index= FINAL.index)\n",
    "                            FINAL.drop([\"CPT_Description\",\"CPT_Description1\", \"Primary Service and Ancillary Services\",\"CPT / HCPCS / ICD-10 Code\"], axis = 1, inplace = True)\n",
    "                            FINAL=FINAL.rename(columns = {'Cpt_description2': \"CPT_Description\"})\n",
    "                            FINAL=FINAL[FINAL['CPT/HCPCS/ICD-10 Code'].str.len().le(8)]\n",
    "                            FINAL                  \n",
    "\n",
    "                    else:\n",
    "                        try:\n",
    "                            try:\n",
    "                                df=pd.read_csv(f)\n",
    "                            except:\n",
    "                                df=pd.read_csv(f,encoding='latin1')\n",
    "                        except:\n",
    "                            df = pd.read_excel(f, header = 1 )\n",
    "\n",
    "                        if 'Shoppable Services' in df.iloc[:, [0]]:\n",
    "                            if 'Primary Service and Ancillary Services' not in df.iloc[:, [2]]:\n",
    "\n",
    "                                DF_13=df.iloc[:, [s]]\n",
    "                                M=0\n",
    "                                C=0\n",
    "\n",
    "                                for index, row in DF_13.iterrows():\n",
    "                                    if(pd.notnull(row[0])):\n",
    "                                        M=M+1\n",
    "                                        break\n",
    "                                    else:\n",
    "                                        C=C+1\n",
    "                                if C==0:\n",
    "                                    if \"Unnamed: 5\" in DF_13:\n",
    "                                        df.columns=df.iloc[0]\n",
    "                                        FINAL=df.drop([C])\n",
    "                                        FINAL['id']=k[1]\n",
    "                                        FINAL \n",
    "                                    else:\n",
    "                                    #This Case works when description is not found\n",
    "                                        FINAL=df\n",
    "                                        FINAL['id']=k[1]\n",
    "                                        FINAL\n",
    "                                elif C>=1:\n",
    "                                    DF_14=df.iloc[C:]\n",
    "                                        #row values as column names\n",
    "                                    DF_14.columns=DF_14.iloc[0]\n",
    "                                        #Dropping the row\n",
    "                                    FINAL=DF_14.drop([C])\n",
    "                                    FINAL['id']=k[1] \n",
    "                                    FINAL\n",
    "                                    if np.nan in FINAL:\n",
    "                                        FINAL=FINAL.rename(columns={np.nan: 'inpatient'})\n",
    "                                        FINAL\n",
    "                                        FINAL['inpatient'] = FINAL.Inpatient.str.replace('*','')\n",
    "                                        FINAL['inpatient']=FINAL['inpatient'].mask(FINAL['inpatient'].eq('')|FINAL['inpatient'].isnull()).ffill()\n",
    "                                        FINAL=FINAL.rename(columns = {'inpatient': \"inpatient-outpatient\"})\n",
    "                                        FINAL['id']=k[1] \n",
    "                                        FINAL\n",
    "                                    else:\n",
    "                                        None\n",
    "                                else:\n",
    "                                    None\n",
    "\n",
    "\n",
    "\n",
    "                            else:\n",
    "                                try:\n",
    "                                    df=pd.read_csv(f)\n",
    "                                except:\n",
    "                                    df = pd.read_excel(f, header = 1 )\n",
    "\n",
    "                                df['Shoppable Services'].fillna(method='ffill', inplace=True)\n",
    "                                df=df.rename(columns = {'Shoppable Services': 'ROWS'})\n",
    "                                df\n",
    "                                df=df[df['Primary Service and Ancillary Services']!='Primary Service and Ancillary Services']\n",
    "\n",
    "\n",
    "                                List_ids=[]\n",
    "                                for i in df['ROWS']:\n",
    "                                    List_ids.append(i)\n",
    "\n",
    "                                    List_ids=list(set(List_ids))\n",
    "\n",
    "                                combined_df = []\n",
    "                                for i in List_ids:\n",
    "                                    #select one part of the data\n",
    "                                    df1 = df[df['ROWS']==i] \n",
    "                                    #Drop the last row\n",
    "                                    #df1 = df1.iloc[:-1]\n",
    "\n",
    "                                    try:\n",
    "\n",
    "                                        ds=df1.iloc[:1,:]\n",
    "\n",
    "                                        #ds.drop([\"Unnamed: 0\", \"Unnamed: 1\",\"CPT / HCPCS / ICD-10 Code\",\"Average Unit Count\",\"Rev Code\",\"Charge\"], axis = 1, inplace = True) \n",
    "                                        ds=ds[['Primary Service and Ancillary Services']] \n",
    "                                        ds=ds.reset_index(drop=True)\n",
    "                                        ds_T=ds.transpose()\n",
    "                                        DS1=ds_T.rename(columns = {0: \"CPT_Description\"}) \n",
    "                                        DS1=DS1.reset_index(drop=True)\n",
    "                                        DS1\n",
    "                                        #inpatient-outpatient\n",
    "                                        di = df1.iloc[:2,:]\n",
    "                                        #print(m)\n",
    "                                        di = di.drop([di.index[0]],axis=0)\n",
    "                                        di=di[['Primary Service and Ancillary Services']] \n",
    "                                        di=di.reset_index(drop=True)\n",
    "                                        di_T=di.transpose()\n",
    "                                        di3=di_T.rename(columns = {0: \"inpatient-outpatient1\"}) \n",
    "                                        DS4=di3.reset_index(drop=True)\n",
    "                                        DS4\n",
    "                                        #Total of Charges -PART -2\n",
    "                                        ds=df1[df1['Unnamed: 1'].notnull()]\n",
    "                                        ds.drop([\"ROWS\", \"Unnamed: 1\"], axis = 1, inplace = True) \n",
    "                                        ds=ds.reset_index(drop=True)\n",
    "                                        ds\n",
    "\n",
    "                                        #Total Charges\n",
    "                                        ds1=df1[df1['Average Unit Count']=='Total of Charges:']\n",
    "                                        ds1=ds1[['Charge']] \n",
    "                                        ds1=ds1.reset_index(drop=True)\n",
    "                                        ds1.rename(columns = {'Charge': \"Total Charges\"},inplace = True)\n",
    "                                        ds1\n",
    "\n",
    "                                        DS2=pd.concat([ds,ds1], axis=1)\n",
    "                                        DS2['LineItem_cnt']=DS2.shape[0]\n",
    "                                        C=DS2.shape[0]\n",
    "\n",
    "                                        #Payers\n",
    "                                        ds= df1.iloc[C+2:,:]\n",
    "                                        ds=ds[['Primary Service and Ancillary Services','Charge']]\n",
    "                                        ds=ds[ds['Primary Service and Ancillary Services'].notnull()]\n",
    "                                        #ds1=ds.dropna() \n",
    "\n",
    "                                        #ds['Primary Service and Ancillary Services'] = ds['Primary Service and Ancillary Services'].str.replace('Charge for', '')\n",
    "                                        ds2=ds.transpose()\n",
    "                                        ds2.columns = ds2.iloc[0] \n",
    "\n",
    "                                        #ds2=ds2.drop([\"Primary Service and Ancillary Services\"])\n",
    "                                        ds2=ds2.iloc[1:]\n",
    "                                        DS3=ds2.reset_index(drop=True)\n",
    "\n",
    "                                        DS_F=pd.concat([DS1,DS2,DS3,DS4], axis=1)\n",
    "                                        #DS_F = DS_F.dropna(axis='columns', how='all')\n",
    "                                        DS_F['id']=k[1]\n",
    "\n",
    "\n",
    "                                    except:\n",
    "                                        pass\n",
    "\n",
    "                                    combined_df.append(DS_F)\n",
    "                                    #combined_df['ID']=k[1]\n",
    "                                combined_df = pd.concat(combined_df)\n",
    "                                combined_df.drop([\"Rev Code\",\"Charge\"], axis = 1, inplace = True)\n",
    "                                FINAL=combined_df[combined_df['CPT_Description'].notnull()]\n",
    "                                FINAL['CPT_Description1'] = FINAL.CPT_Description.str.split('-',1)\n",
    "                                FINAL[['CPT/HCPCS/ICD-10 Code','Cpt_description2']] = pd.DataFrame(FINAL.CPT_Description1.tolist(), index= FINAL.index)\n",
    "                                FINAL.drop([\"CPT_Description\",\"CPT_Description1\", \"Primary Service and Ancillary Services\",\"CPT / HCPCS / ICD-10 Code\"], axis = 1, inplace = True)\n",
    "                                FINAL=FINAL.rename(columns = {'Cpt_description2': \"CPT_Description\"}) \n",
    "                                FINAL=FINAL[FINAL['CPT/HCPCS/ICD-10 Code'].str.len().le(8)]\n",
    "                                FINAL\n",
    "\n",
    "                        else:\n",
    "                            None\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass\n",
    "\n",
    "\n",
    "        try:\n",
    "            FINAL[['service type','inpatient-outpatient']] = FINAL[\"inpatient-outpatient1\"].str.split(\":\", 1, expand=True)\n",
    "            FINAL.drop([\"inpatient-outpatient1\",\"service type\"], axis = 1, inplace = True)\n",
    "        except:\n",
    "            pass\n",
    "        for i in FINAL.columns:\n",
    "\n",
    "            x = str(i).lower().strip()\n",
    "            FINAL=FINAL.rename(columns= {i:x})\n",
    "\n",
    "\n",
    "        for k in CNames.itertuples(index=False):\n",
    "            for r in DF6.itertuples(index=False):\n",
    "                if str(k[1]) == str(r[2]):\n",
    "                    try:\n",
    "\n",
    "                        for i in FINAL.columns.tolist():\n",
    "                            if str(i) == str(r[0]):\n",
    "                                FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                    except:\n",
    "                        pass\n",
    "        for i in FINAL.columns.tolist():\n",
    "\n",
    "            for r in DF6.itertuples(index=False):\n",
    "\n",
    "                if str(r[2]) == \"nan\" :\n",
    "\n",
    "                    if str(i) == str(r[0]):\n",
    "                        FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "\n",
    "        Search_List = list(DF8[\"Dropping columns\"])\n",
    "            #dropping columns\n",
    "        FINAL= FINAL.drop(columns=[col for col in FINAL if col  in Search_List])\n",
    "\n",
    "\n",
    "\n",
    "        column_list = ['inpatient_outpatient']\n",
    "        for col in column_list:\n",
    "            if col not in FINAL.columns:\n",
    "                FINAL[col] = ' '\n",
    "\n",
    "\n",
    "        df2=FINAL\n",
    "        df2 = df_column_uniquify(df2)\n",
    "        #Required format - variable list\n",
    "        Col_list = list(DF5[\"Columns\"])\n",
    "        df3=df2.melt(id_vars=[col for col in df2 if col in Col_list],var_name=\"name\",value_name='cost')\n",
    "        #df3=df1.melt(id_vars=['ID','Description','Cpt Code','Rev_Cd','Units'],var_name=\"Name\",value_name='Cost')\n",
    "\n",
    "\n",
    "        df4=df3\n",
    "        df4=df4[df4['cost'].notnull()]\n",
    "        #Dropping_columns=['Not offered','Not Contracted','N/A','Not a covered service','Not Offered','Not contracted','Not a covered service','N/A']\n",
    "        #df4 = df4[~df4['Cost'].isin(Dropping_columns)]\n",
    "        df4\n",
    "        Combined_data.append(df4)\n",
    "    Combined_data = pd.concat(Combined_data)\n",
    "\n",
    "    Combined_data\n",
    "    #Combined_data[\"id\"]=Combined_data.id.astype('int64')\n",
    "    ##Combined_data.dtypes\n",
    "    Sample_output = Combined_data\n",
    "\n",
    "    output_path = r\"C:\\Users\\User\\Zigna AI Corp\\Zigna AI Corp - RightPx\\Hospital Application_2022-03-09\\Automation_task\\outputs\\Longformat2_{}.csv\"\n",
    "    Sample_output.to_csv(output_path.format((k[1])), index=False)\n",
    "    return Sample_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "97976253",
   "metadata": {},
   "outputs": [],
   "source": [
    "################### wideFormat106 ##################\n",
    "def wideFormat106(CNames):\n",
    "    global df7      \n",
    "    Combined_data = []\n",
    "    combined_final = []\n",
    "    non_prep_data = []\n",
    "    #Getting the details as list from files\n",
    "    for k in CNames.itertuples(index=False):\n",
    "        f=k[0] \n",
    "        #Checking the file type- xlsx   \n",
    "        if k[2]== 'csv':\n",
    "            try:\n",
    "                DF_FINAL=pd.read_csv(f)\n",
    "            except:\n",
    "                DF_FINAL=pd.read_csv(f,encoding='latin1')\n",
    "                \n",
    "            non_prep_data.append(DF_FINAL)\n",
    "        \n",
    "        elif k[2]== 'xlsx':\n",
    "            sheet_to = pd.read_excel(f,sheet_name=None,dtype=str,header=None)\n",
    "         \n",
    "            for sh in sheet_to.keys():\n",
    "               \n",
    "                DF_FINAL = pd.read_excel(f,sheet_name=sh,dtype=str)\n",
    "                print(sh)\n",
    "                non_prep_data.append(DF_FINAL)\n",
    "                \n",
    "        for j in df7.itertuples(index=False):\n",
    "            if str(k[1]) == str(j[0]):\n",
    "                s = j[1]\n",
    "                \n",
    "        for DF_FINAL in non_prep_data:\n",
    "            try:\n",
    "                if DF_FINAL.iloc[:, [s]].empty == False:\n",
    "                    DF_10=DF_FINAL.iloc[:, [s]]    \n",
    "                    m=0\n",
    "                    c=0\n",
    "                    \n",
    "                    #Getting the count of  empty rows\n",
    "                    for index, row in DF_10.iterrows():\n",
    "                        if(pd.notnull(row[0])): \n",
    "                            m=m+1\n",
    "                            break\n",
    "                        else:\n",
    "                            c=c+1\n",
    "                    \n",
    "                    if c==0:\n",
    "                    #This Case works when description is in one row\n",
    "                        if \"Unnamed: 2\" in DF_10:\n",
    "                            DF_FINAL.columns=DF_FINAL.iloc[0]\n",
    "                            FINAL=DF_FINAL.drop([c])\n",
    "                            FINAL['id']=k[1]\n",
    "                            FINAL\n",
    "                        else:\n",
    "                            #This Case works when description is not found\n",
    "                            FINAL=DF_FINAL\n",
    "                            FINAL['id']=k[1]\n",
    "                            FINAL\n",
    "                    \n",
    "                    elif c>=1:\n",
    "                        #This Case works when description is more than 1 row\n",
    "                        #Dropping 'c' rows\n",
    "                        DF_11=DF_FINAL.iloc[c:]\n",
    "                        #row values as column names\n",
    "                        DF_11.columns=DF_11.iloc[0]\n",
    "                        #Dropping the row\n",
    "                        FINAL=DF_11.drop([c])\n",
    "                        FINAL['id']=k[1]\n",
    "                    else:\n",
    "                        None \n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass\n",
    "    \n",
    "       \n",
    "    \n",
    "        for i in FINAL.columns:\n",
    "            x = str(i).lower().strip()\n",
    "            FINAL=FINAL.rename(columns= {i:x})\n",
    "        \n",
    "    \n",
    "        for i in FINAL.columns.tolist():\n",
    "    \n",
    "            for k in CNames.itertuples(index=False):\n",
    "    \n",
    "                for r in DF6.itertuples(index=False):\n",
    "    \n",
    "                    if str(k[1]) == str(r[2]):\n",
    "                        try:\n",
    "    \n",
    "                            for i in FINAL.columns.tolist():\n",
    "    \n",
    "                                if str(i) == str(r[0]):\n",
    "    \n",
    "                                    FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                        except:\n",
    "                                pass\n",
    "    \n",
    "        for i in FINAL.columns.tolist():\n",
    "            for r in DF6.itertuples(index=False):\n",
    "                if str(r[2]) == \"nan\" :\n",
    "                    if str(i) == str(r[0]):\n",
    "                        FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "    \n",
    "        Search_List = list(DF8[\"Dropping columns\"])\n",
    "        #dropping columns\n",
    "    \n",
    "        FINAL= FINAL.drop(columns=[col for col in FINAL if col in Search_List])\n",
    "    \n",
    "        FINAL.loc[:, FINAL.columns.notnull()]\n",
    "        \n",
    "        #Checking the  Inpatient/Outpatient column exists or not\n",
    "        column_list = ['inpatient-outpatient']\n",
    "        for col in column_list:\n",
    "            if col not in FINAL.columns:\n",
    "                FINAL[col] = ' '\n",
    "    \n",
    "       \n",
    "    \n",
    "        df2=FINAL\n",
    "        df2 = df_column_uniquify(df2)\n",
    "        #Required format - variable list\n",
    "        Col_list = list(DF5[\"Columns\"])\n",
    "        df3=df2.melt(id_vars=[col for col in df2 if col in Col_list],var_name=\"name\",value_name='cost')\n",
    "        #df3=df1.melt(id_vars=['ID','Description','Cpt Code','Rev_Cd','Units'],var_name=\"Name\",value_name='Cost')\n",
    "    \n",
    "        \n",
    "    \n",
    "        df4=df3\n",
    "        df4=df4[df4['cost'].notnull()]\n",
    "    \n",
    "        #Dropping_columns=['Not offered','Not Contracted','N/A','Not a covered service','Not Offered','Not contracted','Not a covered service','N/A']\n",
    "        #df4 = df4[~df4['Cost'].isin(Dropping_columns)]\n",
    "        df4\n",
    "        Combined_data.append(df4)\n",
    "    Combined_data = pd.concat(Combined_data)\n",
    "    \n",
    "    Combined_data\n",
    "    \n",
    "    output_path = r\"C:\\Users\\User\\Zigna AI Corp\\Zigna AI Corp - RightPx\\Hospital Application_2022-03-09\\Automation_task\\outputs\\Wideformat106_{}.csv\"\n",
    "    Combined_data.to_csv(output_path.format((k[1])), index=False)\n",
    "    return Combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf9b89fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "################## wideFormat107 #################\n",
    "def wideFormat107(CNames):\n",
    "    global df7      \n",
    "    Combined_data = []\n",
    "    combined_final = []\n",
    "    non_prep_data = []\n",
    "    def similar(x1, x2):\n",
    "        return SequenceMatcher(None, x1, x2).ratio()\n",
    "    #Getting the details as list from files\n",
    "    for k in CNames.itertuples(index=False):\n",
    "        f=k[0] \n",
    "        #Checking the file type- xlsx   \n",
    "        if k[2]== 'csv':\n",
    "            try:\n",
    "                DF_FINAL=pd.read_csv(f)\n",
    "            except:\n",
    "                DF_FINAL=pd.read_csv(f,encoding='latin1')\n",
    "                \n",
    "            non_prep_data.append(DF_FINAL)\n",
    "        \n",
    "        elif k[2]== 'xlsx':\n",
    "            sheet_to = pd.read_excel(f,sheet_name=None,dtype=str,header=None)\n",
    "         \n",
    "            for sh in sheet_to.keys():\n",
    "               \n",
    "                DF_FINAL = pd.read_excel(f,sheet_name=sh,dtype=str)\n",
    "                print(sh)\n",
    "                non_prep_data.append(DF_FINAL)\n",
    "                \n",
    "        for j in df7.itertuples(index=False):\n",
    "            if str(k[1]) == str(j[0]):\n",
    "                s = j[1]\n",
    "                \n",
    "        for DF_FINAL in non_prep_data:\n",
    "            try:\n",
    "                if DF_FINAL.iloc[:, [s]].empty == False:\n",
    "                 \n",
    "                    if len(set(sh.lower().split()) & set(f.lower().split())) != 0:\n",
    "    #                     DF_FINAL=pd.read_excel(f,sheet_name= sh)\n",
    "    #                     print(sh)\n",
    "                        s.append(sh)\n",
    "                    else: \n",
    "                        lis = []\n",
    "                        for i in set(f.lower().split()):\n",
    "                            for j in set(sh.lower().split()):\n",
    "                                lis.append(similar(i,j))\n",
    "                                for p in lis:\n",
    "                                    if p >= 0.9:\n",
    "    #                                     DF_FINAL=pd.read_excel(f,sheet_name= sh)\n",
    "                                        s.append(sh)\n",
    "                                        break\n",
    "                                    else:\n",
    "                                         pass\n",
    "                DF_1 = pd.read_excel(f, s[0],header=None)\n",
    "                DF_1[:1] = DF_1[:1].fillna(method='ffill', axis=1,limit=1)\n",
    "                DF_1[:1] = DF_1[:1].fillna('C')\n",
    "                DF_1[:2] = DF_1[:2].fillna('C')\n",
    "                DF_1.columns = (DF_1.iloc[0] + '_' + DF_1.iloc[1])\n",
    "                DF_2 = DF_1.iloc[2:].reset_index(drop=True)\n",
    "                DF_2['sheet_name'] = s[0]\n",
    "                for i in DF_2.columns:\n",
    "                    x = str(i).lower().strip()\n",
    "                    DF_2 = DF_2.rename(columns= {i:x}) \n",
    "            \n",
    "                for i in DF_2.columns.tolist():\n",
    "            \n",
    "                    for k in CNames.itertuples(index=False):\n",
    "            \n",
    "                        for r in DF6.itertuples(index=False):\n",
    "            \n",
    "                            if str(k[1]) == str(r[2]):\n",
    "                                try:\n",
    "            \n",
    "                                    for i in DF_2.columns.tolist():\n",
    "            \n",
    "                                        if str(i) == str(r[0]):\n",
    "            \n",
    "                                            DF_2.rename(columns={i:r[1]}, inplace=True)\n",
    "                                except:\n",
    "                                    pass\n",
    "            \n",
    "                for i in DF_2.columns.tolist():\n",
    "                    for r in DF6.itertuples(index=False):\n",
    "                        if str(r[2]) == \"nan\" :\n",
    "            \n",
    "                            if str(i) == str(r[0]):\n",
    "                                DF_2.rename(columns={i:r[1]}, inplace=True)\n",
    "            \n",
    "                #Second sheet\n",
    "                DF_3 = pd.read_excel(f, s[1],header=None)\n",
    "                DF_3[:1] = DF_3[:1].fillna(method='ffill', axis=1,limit=1)\n",
    "                DF_3[:1] = DF_3[:1].fillna('C')\n",
    "                DF_3[:2] = DF_3[:2].fillna('C')\n",
    "                DF_3.columns = (DF_3.iloc[0] + '_' + DF_3.iloc[1])\n",
    "                DF_4 = DF_3.iloc[2:].reset_index(drop=True)\n",
    "                DF_4['sheet_name'] = s[1]\n",
    "                for i in DF_4.columns:\n",
    "                    x = str(i).lower().strip()\n",
    "                    DF_4=DF_4.rename(columns= {i:x}) \n",
    "            \n",
    "                for i in DF_4.columns.tolist():\n",
    "            \n",
    "                    for k in CNames.itertuples(index=False):\n",
    "            \n",
    "                        for r in DF6.itertuples(index=False):\n",
    "            \n",
    "                            if str(k[1]) == str(r[2]):\n",
    "                                try:\n",
    "            \n",
    "                                    for i in DF_4.columns.tolist():\n",
    "            \n",
    "                                        if str(i) == str(r[0]):\n",
    "            \n",
    "                                            DF_4.rename(columns={i:r[1]}, inplace=True)\n",
    "                                except:\n",
    "                                    pass\n",
    "            \n",
    "                for i in DF_4.columns.tolist():\n",
    "                    for r in DF6.itertuples(index=False):\n",
    "                        if str(r[2]) == \"nan\" :\n",
    "            \n",
    "                            if str(i) == str(r[0]):\n",
    "                                DF_4.rename(columns={i:r[1]}, inplace=True)\n",
    "                #Concatenating two sheets    \n",
    "                frames=[DF_2,DF_4]\n",
    "                result=pd.concat(frames)\n",
    "                # try:\n",
    "                #     result = result.drop(\"c_cdm code - description\",axis = 1)\n",
    "                # except:\n",
    "                    # None\n",
    "                result['Description_1'] = result['Cde n dscrpn'].str.split('-',1)\n",
    "                \n",
    "                result.dropna(subset = [\"Description_1\"], inplace=True)\n",
    "            \n",
    "            \n",
    "                #result[['CPT/DRG', 'description']] = result['Description_1'].str.split('_\\s+', n=1, expand=True)\n",
    "                result[['CPT/DRG','description']] = pd.DataFrame(result['Description_1'].tolist(), index= result.index)\n",
    "                #result.drop([\"Description_1\",\"Cde n dscrpn\"], axis = 1, inplace = True)\n",
    "                Search_List = list(DF8[\"Dropping columns\"])\n",
    "                #dropping columns\n",
    "                result1= result.drop(columns=[col for col in result if col in Search_List])\n",
    "                result1 = result1.drop(['Description_1'],axis=1)\n",
    "                DF_FINAL=result1\n",
    "                #DF_FINAL\n",
    "            \n",
    "                #Selecting -6th column from every file\n",
    "                DF_10=DF_FINAL.iloc[:, [s]]    \n",
    "                m=0\n",
    "                c=0\n",
    "                \n",
    "                #Getting the count of  empty rows\n",
    "                for index, row in DF_10.iterrows():\n",
    "                    if(pd.notnull(row[0])): \n",
    "                        m=m+1\n",
    "                        break\n",
    "                    else:\n",
    "                        c=c+1\n",
    "                        \n",
    "                if c==0:\n",
    "                #This Case works when description is in one row\n",
    "                    if \"Unnamed: 3\" in DF_10:\n",
    "                        DF_FINAL.columns=DF_FINAL.iloc[0]\n",
    "                        FINAL=DF_FINAL.drop([c])\n",
    "                        FINAL['id']=k[1]\n",
    "                        FINAL\n",
    "                    else:\n",
    "                        #This Case works when description is not found\n",
    "                        FINAL=DF_FINAL\n",
    "                        FINAL['id']=k[1]\n",
    "                        FINAL\n",
    "                        \n",
    "                elif c>=1:\n",
    "                    #This Case works when description is more than 1 row\n",
    "                    #Dropping 'c' rows\n",
    "                    DF_11=DF_FINAL.iloc[c:]\n",
    "                    #row values as column names\n",
    "                    DF_11.columns=DF_11.iloc[0]\n",
    "                    #Dropping the row\n",
    "                    FINAL=DF_11.drop([c])\n",
    "                    FINAL['id']=k[1]\n",
    "                else:\n",
    "                    None \n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass\n",
    "     \n",
    "        column_list = ['inpatient-outpatient']\n",
    "        for col in column_list:\n",
    "            if col not in FINAL.columns:\n",
    "                FINAL[col] = ' '\n",
    "    \n",
    "        \n",
    "        df2=FINAL\n",
    "        df2 = df_column_uniquify(df2)\n",
    "        #Required format - variable list\n",
    "        Col_list = list(DF5[\"Columns\"])\n",
    "        df3=df2.melt(id_vars=[col for col in df2 if col in Col_list],var_name=\"name\",value_name='cost')\n",
    "    \n",
    "            \n",
    "        df4=df3\n",
    "        df4=df4[df4['cost'].notnull()]\n",
    "    \n",
    "        df4\n",
    "        Combined_data.append(df4)\n",
    "    Combined_data = pd.concat(Combined_data)\n",
    "            \n",
    "    Combined_data\n",
    "    output_path = r\"C:\\Users\\User\\Zigna AI Corp\\Zigna AI Corp - RightPx\\Hospital Application_2022-03-09\\Automation_task\\outputs\\Wideformat107_{}.csv\"\n",
    "    Combined_data.to_csv(output_path.format((k[1])), index=False)\n",
    "    return Combined_data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "439cd746",
   "metadata": {},
   "outputs": [],
   "source": [
    "################## wideFormat108 ###############\n",
    "def wideFormat108(CNames):\n",
    "    global df7\n",
    "    \n",
    "    Combined_data = []\n",
    "    combined_final = []\n",
    "    non_prep_data = []\n",
    "    #Getting the details as list from files\n",
    "    for k in CNames.itertuples(index=False):\n",
    "        f=k[0] \n",
    "        #Checking the file type- xlsx   \n",
    "        if k[2]== 'csv':\n",
    "            try:\n",
    "                DF_FINAL=pd.read_csv(f)\n",
    "            except:\n",
    "                DF_FINAL=pd.read_csv(f,encoding='latin1')\n",
    "\n",
    "            non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        elif k[2]== 'xlsx':\n",
    "            sheet_to = pd.read_excel(f,sheet_name=None,dtype=str,header=None)\n",
    "\n",
    "            for sh in sheet_to.keys():\n",
    "\n",
    "                DF_FINAL = pd.read_excel(f,sheet_name=sh,dtype=str, header = None)\n",
    "                print(sh)\n",
    "                non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        for j in df7.itertuples(index=False):\n",
    "            if str(k[1]) == str(j[0]):\n",
    "                s = j[1]\n",
    "\n",
    "        for DF_FINAL in non_prep_data:\n",
    "            try:\n",
    "                if DF_FINAL.iloc[:, [s]].empty == False:\n",
    "                    DF_10=DF_FINAL.iloc[:, [s]]    \n",
    "                    m=0\n",
    "                    c=0\n",
    "\n",
    "                    #Getting the count of  empty rows\n",
    "                    for index, row in DF_10.iterrows():\n",
    "                        if(pd.notnull(row[1])): \n",
    "                            m=m+1\n",
    "                            break\n",
    "                        else:\n",
    "                            c=c+1\n",
    "\n",
    "                    if c==0:\n",
    "                    #This Case works when description is in one row\n",
    "                        if \"Unnamed: 5\" in DF_10:\n",
    "\n",
    "\n",
    "                            DF_FINAL.iloc[:c, :c] = np.nan\n",
    "\n",
    "                            DF_FINAL[:c] = DF_FINAL[:c].fillna(method='ffill', axis=1)\n",
    "                            DF_FINAL = DF_FINAL.replace(np.nan,'',regex=True)\n",
    "                            idx = DF_FINAL.index.get_loc(c)\n",
    "                            DF_11 = DF_FINAL.iloc[idx - c :]\n",
    "                            j = c+1\n",
    "\n",
    "                            req_rows = np.where(DF_11.index == j)[0][0]\n",
    "                            start = max(0, req_rows - j )\n",
    "                            end = max(1, req_rows)\n",
    "                            DF_12 = DF_11.iloc[start:end]\n",
    "\n",
    "                            DF_12= DF_12.apply(lambda c: ' '.join(c), axis=0)\n",
    "                            DF_12 = DF_12.to_frame()\n",
    "                            DF_13 = DF_12.T\n",
    "\n",
    "                            DF_11.drop(DF_11.head(j).index, inplace = True)\n",
    "                            DF15 = DF_13.append(DF_11)\n",
    "                            DF16 = DF15.reset_index(drop = True)\n",
    "                            DF16.columns = DF16.iloc[0]\n",
    "                            FINAL = DF16[1:]\n",
    "                            FINAL['id']=k[1]\n",
    "\n",
    "                            for i in FINAL.columns:\n",
    "                                x = str(i).lower().strip()\n",
    "                                FINAL=FINAL.rename(columns= {i:x})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                            for k in CNames.itertuples(index=False):\n",
    "                                for r in DF6.itertuples(index=False):\n",
    "                                    if str(k[1]) == str(r[2]):\n",
    "                                        try:\n",
    "                                            for i in FINAL.columns.tolist():\n",
    "                                                if str(i) == str(r[0]):\n",
    "                                                    FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                                        except:\n",
    "                                            pass\n",
    "                            for i in FINAL.columns.tolist():\n",
    "\n",
    "                                for r in DF6.itertuples(index=False):\n",
    "\n",
    "\n",
    "\n",
    "                                    if str(r[2]) == \"nan\" :\n",
    "\n",
    "                                        if str(i) == str(r[0]):\n",
    "                                            FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                            combined_final.append(FINAL)\n",
    "                        else:\n",
    "                            #This Case works when description is not found\n",
    "                            DF_FINAL.iloc[:c, :2] = np.nan\n",
    "\n",
    "                            DF_FINAL[:c] = DF_FINAL[:c].fillna(method='ffill', axis=1)\n",
    "                            DF_FINAL = DF_FINAL.replace(np.nan,'',regex=True)\n",
    "                            idx = DF_FINAL.index.get_loc(c)\n",
    "                            DF_11 = DF_FINAL.iloc[idx - c :]\n",
    "                            j = c+1\n",
    "\n",
    "                            req_rows = np.where(DF_11.index == j)[0][0]\n",
    "                            start = max(0, req_rows - j )\n",
    "                            end = max(1, req_rows)\n",
    "                            DF_12 = DF_11.iloc[start:end]\n",
    "\n",
    "                            DF_12= DF_12.apply(lambda c: ' '.join(c), axis=0)\n",
    "                            DF_12 = DF_12.to_frame()\n",
    "                            DF_13 = DF_12.T\n",
    "\n",
    "                            DF_11.drop(DF_11.head(j).index, inplace = True)\n",
    "                            DF15 = DF_13.append(DF_11)\n",
    "                            DF16 = DF15.reset_index(drop = True)\n",
    "                            DF16.columns = DF16.iloc[0]\n",
    "                            FINAL = DF16[1:]\n",
    "\n",
    "                            FINAL['id']=k[1]\n",
    "\n",
    "                            for i in FINAL.columns:\n",
    "                                x = str(i).lower().strip()\n",
    "                                FINAL=FINAL.rename(columns= {i:x})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                            for k in CNames.itertuples(index=False):\n",
    "                                for r in DF6.itertuples(index=False):\n",
    "                                    if str(k[1]) == str(r[2]):\n",
    "                                        try:\n",
    "                                            for i in FINAL.columns.tolist():\n",
    "                                                if str(i) == str(r[0]):\n",
    "                                                    FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                                        except:\n",
    "                                            pass\n",
    "                            for i in FINAL.columns.tolist():\n",
    "\n",
    "                                for r in DF6.itertuples(index=False):\n",
    "\n",
    "\n",
    "\n",
    "                                    if str(r[2]) == \"nan\" :\n",
    "\n",
    "                                        if str(i) == str(r[0]):\n",
    "                                            FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                            combined_final.append(FINAL)\n",
    "\n",
    "                    elif c>=1:\n",
    "                        #This Case works when description is more than 1 row\n",
    "                        #Dropping 'c' rows\n",
    "                        DF_FINAL.iloc[:c, :2] = np.nan\n",
    "\n",
    "                        DF_FINAL[:c] = DF_FINAL[:c].fillna(method='ffill', axis=1)\n",
    "                        DF_FINAL = DF_FINAL.replace(np.nan,'',regex=True)\n",
    "                        idx = DF_FINAL.index.get_loc(c)\n",
    "                        DF_11 = DF_FINAL.iloc[idx - c :]\n",
    "                        j = c+1\n",
    "\n",
    "                        req_rows = np.where(DF_11.index == j)[0][0]\n",
    "                        start = max(0, req_rows - j )\n",
    "                        end = max(1, req_rows)\n",
    "                        DF_12 = DF_11.iloc[start:end]\n",
    "\n",
    "                        DF_12= DF_12.apply(lambda c: ' '.join(c), axis=0)\n",
    "                        DF_12 = DF_12.to_frame()\n",
    "                        DF_13 = DF_12.T\n",
    "\n",
    "                        DF_11.drop(DF_11.head(j).index, inplace = True)\n",
    "                        DF15 = DF_13.append(DF_11)\n",
    "                        DF16 = DF15.reset_index(drop = True)\n",
    "                        DF16.columns = DF16.iloc[0]\n",
    "                        FINAL = DF16[1:]\n",
    "                        FINAL['id']=k[1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                        for i in FINAL.columns:\n",
    "                            x = str(i).lower().strip()\n",
    "                            FINAL=FINAL.rename(columns= {i:x})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                        for k in CNames.itertuples(index=False):\n",
    "                            for r in DF6.itertuples(index=False):\n",
    "                                if str(k[1]) == str(r[2]):\n",
    "                                    try:\n",
    "                                        for i in FINAL.columns.tolist():\n",
    "                                            if str(i) == str(r[0]):\n",
    "                                                FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                                    except:\n",
    "                                        pass\n",
    "                        for i in FINAL.columns.tolist():\n",
    "\n",
    "                            for r in DF6.itertuples(index=False):\n",
    "\n",
    "\n",
    "\n",
    "                                if str(r[2]) == \"nan\" :\n",
    "\n",
    "                                    if str(i) == str(r[0]):\n",
    "                                        FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                        combined_final.append(FINAL)\n",
    "                    else:\n",
    "                        None\n",
    "\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass\n",
    "\n",
    "        try:\n",
    "            FINAL = pd.concat(combined_final)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        #for r in DF6.itertuples(index=False):\n",
    "            #FINAL.rename(columns={r[0]:r[1]}, inplace=True)\n",
    "            #Search_List = list(DF8[\"Dropping columns\"])\n",
    "            #dropping columns\n",
    "            #FINAL= FINAL.drop(columns=[col for col in FINAL if col in Search_List])\n",
    "        #Checking the  Inpatient/Outpatient column exists or not\n",
    "        column_list = ['inpatient-outpatient']\n",
    "        for col in column_list:\n",
    "            if col not in FINAL.columns:\n",
    "                FINAL[col] = ' '\n",
    "\n",
    "\n",
    "        df2=FINAL\n",
    "        df2 = df_column_uniquify(df2)\n",
    "        #Required format - variable list\n",
    "        Col_list = list(DF5[\"Columns\"])\n",
    "        df3=df2.melt(id_vars=[col for col in df2 if col in Col_list],var_name=\"name\",value_name='cost')\n",
    "        #df3=df1.melt(id_vars=['ID','Description','Cpt Code','Rev_Cd','Units'],var_name=\"Name\",value_name='Cost')\n",
    "\n",
    "\n",
    "        df4=df3\n",
    "        df4=df4[df4['cost'].notnull()]\n",
    "\n",
    "        #Dropping_columns=['Not offered','Not Contracted','N/A','Not a covered service','Not Offered','Not contracted','Not a covered service','N/A']\n",
    "        #df4 = df4[~df4['Cost'].isin(Dropping_columns)]\n",
    "        df4\n",
    "        Combined_data.append(df4)\n",
    "    Combined_data = pd.concat(Combined_data)\n",
    "    Combined_data = Combined_data.drop_duplicates()      \n",
    "    Combined_data\n",
    "\n",
    "    output_path = r\"C:\\Users\\User\\Zigna AI Corp\\Zigna AI Corp - RightPx\\Hospital Application_2022-03-09\\Automation_task\\outputs\\Wideformat108_{}.csv\"\n",
    "    Combined_data.to_csv(output_path.format((k[1])), index=False)\n",
    "    return Combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f8cabf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "################# wideFormat11 ###############\n",
    "def wideFormat11(CNames):\n",
    "    global df7\n",
    "    \n",
    "    Combined_data = []\n",
    "    combined_final = []\n",
    "    non_prep_data = []\n",
    "\n",
    "\n",
    "    #Getting the details as list from files\n",
    "    for k in CNames.itertuples(index=False):\n",
    "        f=k[0] \n",
    "        #Checking the file type- xlsx   \n",
    "        if k[2]== 'csv':\n",
    "            try:\n",
    "                DF_FINAL=pd.read_csv(f)\n",
    "            except:\n",
    "                DF_FINAL=pd.read_csv(f,encoding='latin1')\n",
    "\n",
    "            non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        elif k[2]== 'xlsx':\n",
    "            sheet_to = pd.read_excel(f,sheet_name=None,dtype=str,header=None)\n",
    "\n",
    "            for sh in sheet_to.keys():\n",
    "\n",
    "                DF_FINAL = pd.read_excel(f,sheet_name=sh,dtype=str)\n",
    "                print(sh)\n",
    "                non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        for j in df7.itertuples(index=False):\n",
    "            if str(k[1]) == str(j[0]):\n",
    "                s = j[1]\n",
    "\n",
    "        for DF_FINAL in non_prep_data:\n",
    "            try:\n",
    "                if DF_FINAL.iloc[:, [s]].empty == False:\n",
    "\n",
    "\n",
    "                    DF_10 = DF_FINAL.iloc[:,[s]]\n",
    "                    m=0\n",
    "                    c=0\n",
    "\n",
    "\n",
    "                    for index, row in DF_10.iterrows():\n",
    "\n",
    "\n",
    "                        if (pd.notnull(row[0])):                       \n",
    "\n",
    "                            m=m+1\n",
    "                            print(m)\n",
    "                            break\n",
    "                        else:\n",
    "                            c=c+1\n",
    "\n",
    "\n",
    "                    if c==0:\n",
    "\n",
    "                    #This Case works when description is in one row\n",
    "                        if \"Unnamed: 2\" in DF_10:\n",
    "                            DF_FINAL.columns=DF_FINAL.iloc[0]\n",
    "                            FINAL=DF_FINAL.drop([c])\n",
    "                            FINAL['id']=k[1]\n",
    "                            FINAL.dropna(how='all', axis=1, inplace=True)\n",
    "                            for i in FINAL.columns:\n",
    "                                x = str(i).lower().strip()\n",
    "                                FINAL=FINAL.rename(columns= {i:x})\n",
    "\n",
    "                            for i in FINAL.columns.tolist():\n",
    "\n",
    "                                for k in CNames.itertuples(index=False):\n",
    "\n",
    "                                    for r in DF6.itertuples(index=False):\n",
    "\n",
    "                                        if str(k[1]) == str(r[2]):\n",
    "                                            try:\n",
    "\n",
    "                                                for i in FINAL.columns.tolist():\n",
    "\n",
    "                                                    if str(i) == str(r[0]):\n",
    "\n",
    "                                                        FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                                            except:\n",
    "                                                    pass\n",
    "\n",
    "                            for i in FINAL.columns.tolist():\n",
    "                                for r in DF6.itertuples(index=False):\n",
    "                                    if str(r[2]) == \"nan\" :\n",
    "                                        if str(i) == str(r[0]):\n",
    "                                            FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                            combined_final.append(FINAL)\n",
    "\n",
    "                        else:\n",
    "\n",
    "                            #This Case works when description is not found\n",
    "                            FINAL=DF_FINAL\n",
    "                            FINAL['id']=k[1]\n",
    "                            FINAL.dropna(how='all', axis=1, inplace=True)\n",
    "                            for i in FINAL.columns:\n",
    "                                x = str(i).lower().strip()\n",
    "                                FINAL=FINAL.rename(columns= {i:x})\n",
    "\n",
    "                            for i in FINAL.columns.tolist():\n",
    "\n",
    "                                for k in CNames.itertuples(index=False):\n",
    "\n",
    "                                    for r in DF6.itertuples(index=False):\n",
    "\n",
    "                                        if str(k[1]) == str(r[2]):\n",
    "                                            try:\n",
    "\n",
    "                                                for i in FINAL.columns.tolist():\n",
    "\n",
    "                                                    if str(i) == str(r[0]):\n",
    "\n",
    "                                                        FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                                            except:\n",
    "                                                    pass\n",
    "\n",
    "                            for i in FINAL.columns.tolist():\n",
    "                                for r in DF6.itertuples(index=False):\n",
    "                                    if str(r[2]) == \"nan\" :\n",
    "                                        if str(i) == str(r[0]):\n",
    "                                            FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                            combined_final.append(FINAL)\n",
    "\n",
    "\n",
    "\n",
    "                    elif c>=1:\n",
    "\n",
    "                        #This Case works when description is more than 1 row\n",
    "                        #Dropping 'c' rows\n",
    "                        DF_11=DF_FINAL.iloc[c:]\n",
    "                        #row values as column names\n",
    "                        DF_11.columns=DF_11.iloc[0]\n",
    "                        #Dropping the row\n",
    "                        FINAL=DF_11.drop([c])\n",
    "                        FINAL['id']=k[1]\n",
    "                        FINAL.dropna(how='all', axis=1, inplace=True)\n",
    "                        for i in FINAL.columns:\n",
    "                            x = str(i).lower().strip()\n",
    "                            FINAL=FINAL.rename(columns= {i:x})\n",
    "\n",
    "                        for i in FINAL.columns.tolist():\n",
    "\n",
    "                            for k in CNames.itertuples(index=False):\n",
    "\n",
    "                                for r in DF6.itertuples(index=False):\n",
    "\n",
    "                                    if str(k[1]) == str(r[2]):\n",
    "                                        try:\n",
    "\n",
    "                                            for i in FINAL.columns.tolist():\n",
    "\n",
    "                                                if str(i) == str(r[0]):\n",
    "\n",
    "                                                    FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                                        except:\n",
    "                                                pass\n",
    "\n",
    "                        for i in FINAL.columns.tolist():\n",
    "                            for r in DF6.itertuples(index=False):\n",
    "                                if str(r[2]) == \"nan\" :\n",
    "                                    if str(i) == str(r[0]):\n",
    "                                        FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                        combined_final.append(FINAL)\n",
    "\n",
    "\n",
    "                    else:\n",
    "                        None\n",
    "\n",
    "\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass\n",
    "        try:\n",
    "\n",
    "            FINAL = FINAL.loc[:, ~FINAL.columns.str.contains('^Unnamed')]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        Search_List = list(DF8[\"Dropping columns\"])\n",
    "            #dropping columns\n",
    "        FINAL= FINAL.drop(columns=[col for col in FINAL if col in Search_List])\n",
    "\n",
    "        column_list = ['inpatient-outpatient']\n",
    "        for col in column_list:\n",
    "            if col not in FINAL.columns:\n",
    "                FINAL[col] = ' '\n",
    "\n",
    "        df2=FINAL\n",
    "        df2 = df_column_uniquify(df2)\n",
    "        Col_list = list(DF5[\"Columns\"])\n",
    "        df3=df2.melt(id_vars=[col for col in df2 if col in Col_list],var_name=\"name\",value_name='cost')\n",
    "\n",
    "        df4=df3\n",
    "        df4['cost'] = np.where((df4['cost'] ==' ') , np.nan, df4['cost'])\n",
    "        df5=df4[df4['cost'].notnull()]\n",
    "\n",
    "        df5\n",
    "        Combined_data.append(df5)\n",
    "    Combined_data = pd.concat(Combined_data)\n",
    "\n",
    "    Combined_data\n",
    "\n",
    "    Sample_output= Combined_data\n",
    "\n",
    "    output_path = r\"C:\\Users\\User\\Zigna AI Corp\\Zigna AI Corp - RightPx\\Hospital Application_2022-03-09\\Automation_task\\outputs\\Wideformat11_{}.csv\"\n",
    "    Sample_output.to_csv(output_path.format(k[1]), index=False)\n",
    "    return Sample_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b54447a",
   "metadata": {},
   "outputs": [],
   "source": [
    "################# wideFormat111 ##############\n",
    "def wideFormat111(CNames):\n",
    "    global df7\n",
    "    \n",
    "    combined_df = []\n",
    "    Combined_data = []\n",
    "    non_prep_data = []\n",
    "    #Getting the details as list from files\n",
    "    for k in CNames.itertuples(index=False):\n",
    "        f=k[0] \n",
    "        #Checking the file type- xlsx   \n",
    "        if k[2]== 'csv':\n",
    "            try:\n",
    "                DF_FINAL=pd.read_csv(f)\n",
    "            except:\n",
    "                DF_FINAL=pd.read_csv(f,encoding='latin1')\n",
    "\n",
    "            non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        elif k[2]== 'xlsx':\n",
    "            sheet_to = pd.read_excel(f,sheet_name=None,dtype=str,header=None)\n",
    "\n",
    "            for sh in sheet_to.keys():\n",
    "\n",
    "                DF_FINAL = pd.read_excel(f,sheet_name=sh,dtype=str)\n",
    "                print(sh)\n",
    "                non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        for j in df7.itertuples(index=False):\n",
    "            if str(k[1]) == str(j[0]):\n",
    "                s = j[1]\n",
    "\n",
    "        for DF_FINAL in non_prep_data:\n",
    "            try:\n",
    "                if DF_FINAL.iloc[:, [s]].empty == False:\n",
    "\n",
    "\n",
    "                    DF_10=DF_FINAL.iloc[:, [s]]    \n",
    "                    m=0\n",
    "                    c=0\n",
    "\n",
    "                    #Getting the count of  empty rows\n",
    "                    for index, row in DF_10.iterrows():\n",
    "                        if(pd.notnull(row[0])): \n",
    "                            m=m+1\n",
    "                            break\n",
    "                        else:\n",
    "                            c=c+1\n",
    "\n",
    "                    if c==0:\n",
    "                    #This Case works when description is in one row\n",
    "                        if \"Unnamed: 1\" in DF_10:\n",
    "                            DF_FINAL.columns=DF_FINAL.iloc[0]\n",
    "                            FINAL=DF_FINAL.drop([c])\n",
    "                            FINAL['id']=k[1]\n",
    "                            FINAL\n",
    "                        else:\n",
    "                            #This Case works when description is not found\n",
    "                            FINAL=DF_FINAL\n",
    "                            FINAL['id']=k[1]\n",
    "                            FINAL\n",
    "\n",
    "                    elif c>=1:\n",
    "                        #This Case works when description is more than 1 row\n",
    "                        DF_11=DF_FINAL.iloc[c:]\n",
    "                        #This Case works when description is more than 1 row\n",
    "                        #DF_11=DF_FINAL.iloc[C:]\n",
    "                        list1=['CDM']\n",
    "                        DF_11[\"ROW\"] = DF_11.iloc[:,0].isin(list1)\n",
    "                        n =0\n",
    "                        for index, row in DF_11['ROW'].iteritems():\n",
    "                            if row == True:\n",
    "                                n += 1\n",
    "                                DF_11['ROW'][index] = n\n",
    "                            else:   \n",
    "                                DF_11['ROW'][index] = np.nan\n",
    "                        DF_11['ROW'].fillna(method='bfill', inplace=True, limit = 1)\n",
    "                        DF_11['ROW'].fillna(method='ffill', inplace=True)\n",
    "                        List_ids=[]\n",
    "                        for i in DF_11['ROW']:\n",
    "                            List_ids.append(i)\n",
    "\n",
    "                            List_ids=list(set(List_ids))\n",
    "                        list2 = pd.DataFrame()\n",
    "                        for i in List_ids:\n",
    "                            list2 = DF_11[DF_11['ROW']==i]\n",
    "                            list2 = list2.drop(['ROW'],axis=1)\n",
    "                            list2 = list2.dropna(how='all',axis=1)\n",
    "                            list2.iloc[:2] = list2.iloc[:2].fillna(' ')\n",
    "                            list2.columns = list2.iloc[0] + ' ' + list2.iloc[1]\n",
    "                            list2 = list2.iloc[2:]\n",
    "                            list2 = list2.reset_index(drop=True)\n",
    "                            list2['id']=k[1]\n",
    "                            FINAL = list2\n",
    "                            for i in FINAL.columns:\n",
    "                                x = str(i).lower().strip()\n",
    "                                FINAL=FINAL.rename(columns= {i:x}) \n",
    "\n",
    "                            for i in FINAL.columns.tolist():\n",
    "\n",
    "                                for k in CNames.itertuples(index=False):\n",
    "\n",
    "                                    for r in DF6.itertuples(index=False):\n",
    "\n",
    "                                        if str(k[1]) == str(r[2]):\n",
    "                                            try:\n",
    "\n",
    "                                                for i in FINAL.columns.tolist():\n",
    "\n",
    "                                                    if str(i) == str(r[0]):\n",
    "\n",
    "                                                        FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                                            except:\n",
    "                                                pass\n",
    "\n",
    "                            for i in FINAL.columns.tolist():\n",
    "                                for r in DF6.itertuples(index=False):\n",
    "                                    if str(r[2]) == \"nan\" :\n",
    "\n",
    "                                        if str(i) == str(r[0]):\n",
    "                                            FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                            combined_df.append(FINAL)\n",
    "\n",
    "                    else:\n",
    "                        None \n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass\n",
    "\n",
    "        FINAL = pd.concat(combined_df) \n",
    "        # FINAL.to_csv('Wideformat4(825).csv',index=False)\n",
    "\n",
    "        FINAL['Charges1'] = FINAL['Charges']\n",
    "\n",
    "        Search_List = list(DF8[\"Dropping columns\"])\n",
    "            #dropping columns\n",
    "        FINAL= FINAL.drop(columns=[col for col in FINAL if col  in Search_List])\n",
    "        column_list = ['inpatient-outpatient']\n",
    "        for col in column_list:\n",
    "            if col not in FINAL.columns:\n",
    "                FINAL[col] = ' '    \n",
    "\n",
    "        df2 = FINAL\n",
    "        df2 = df_column_uniquify(df2)\n",
    "        Col_list = list(DF5[\"Columns\"])\n",
    "        df3=df2.melt(id_vars=[col for col in df2 if col in Col_list],var_name=\"name\",value_name='cost')\n",
    "        #df3=df1.melt(id_vars=['ID','Description','Cpt Code','Rev_Cd','Units'],var_name=\"Name\",value_name='Cost')\n",
    "        column_list = ['cost1']\n",
    "        for col in column_list:\n",
    "            if col not in df3.columns:\n",
    "                df3[col] = ''\n",
    "\n",
    "        df3=df3[df3['cost'].notnull()]\n",
    "\n",
    "        list1=['Average', 'Charge', 'Average charge', '0', 'Not offered']\n",
    "        df3=df3[~(df3[\"cost\"].isin(list1))]\n",
    "\n",
    "        try:    \n",
    "            df3[\"cost11\"] = df3['cost'].str.contains('\\d+%')\n",
    "            df3[\"cost1\"]= np.where((df3[\"cost11\"].apply(lambda x:x==True)), df3['cost'].apply(lambda x: x.split(\"%\", 1)[0]),df3[\"cost1\"])\n",
    "            df3 = df3.drop('cost11',axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "            df3[pd.to_numeric(df3.Charges1, errors='coerce').isnull()]\n",
    "\n",
    "            df3['cost1'] = pd.to_numeric(df3['cost1'])\n",
    "\n",
    "            df3[\"cost1\"]= np.where(pd.notnull(df3[\"cost1\"]), df3['cost1'].div(100).round(3),df3[\"cost1\"])\n",
    "\n",
    "            df3[\"Charges1\"]= np.where((df3[\"Charges1\"].str.contains(\",\")), df3[\"Charges1\"].str.replace(',',''),df3[\"Charges1\"])\n",
    "\n",
    "            cols=[i for i in df3.columns if i in ['cost1', 'Charges1']]\n",
    "\n",
    "            for col in cols:\n",
    "                df3[col] = pd.to_numeric(df3[col], errors='coerce')\n",
    "\n",
    "            df3[\"cost1\"]= np.where(pd.notnull(df3[\"cost1\"]), df3[\"Charges1\"] * df3[\"cost1\"],df3[\"cost1\"])\n",
    "\n",
    "            df3[\"cost1\"].fillna(df3[\"cost\"], inplace=True)\n",
    "            df3 = df3.drop(['cost','Charges1'],axis=1)\n",
    "            df4=df3.rename(columns = {'cost1': \"cost\"}) \n",
    "        except:\n",
    "            None\n",
    "\n",
    "\n",
    "        df4=df4[df4['name'].notnull()]\n",
    "\n",
    "        df4\n",
    "        Combined_data.append(df4)\n",
    "    Combined_data = pd.concat(Combined_data)\n",
    "\n",
    "    Combined_data\n",
    "\n",
    "    Sample_output = Combined_data\n",
    "    output_path = r\"C:\\Users\\User\\Zigna AI Corp\\Zigna AI Corp - RightPx\\Hospital Application_2022-03-09\\Automation_task\\outputs\\Wideformat111_{}.csv\"\n",
    "    Sample_output.to_csv(output_path.format(k[1]), index=False)\n",
    "    return Sample_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5587b6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "################### wideFormat117 #####################\n",
    "def wideFormat117(CNames):\n",
    "    global df7\n",
    "    \n",
    "    Combined_data = []\n",
    "    combined_final = []\n",
    "    non_prep_data = []\n",
    "\n",
    "    def similar(x1, x2):\n",
    "        return SequenceMatcher(None, x1, x2).ratio()\n",
    "    for k in CNames.itertuples(index=False):\n",
    "        f=k[0] \n",
    "\n",
    "        #Checking the file type- xlsx   \n",
    "        if k[2]== 'csv':\n",
    "            try:\n",
    "                DF_FINAL=pd.read_csv(f)\n",
    "            except:\n",
    "                DF_FINAL=pd.read_csv(f,encoding='latin1')\n",
    "\n",
    "            non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        elif k[2]== 'xlsx':\n",
    "            sheet_to = pd.read_excel(f, sheet_name = None,dtype=str)\n",
    "            for sh in sheet_to.keys():\n",
    "\n",
    "                    if len(set(sh.lower().split()) & set(f.lower().split())) != 0:\n",
    "                        DF_FINAL=pd.read_excel(f,sheet_name= sh)\n",
    "                        print(sh)\n",
    "                    else:\n",
    "                        lis = []\n",
    "                        for i in set(f.lower().split()):\n",
    "                            for j in set(sh.lower().split()):\n",
    "                                lis.append(similar(i,j))\n",
    "                                for p in lis:\n",
    "                                    if p >= 0.9:\n",
    "                                        DF_FINAL=pd.read_excel(f,sheet_name= sh)\n",
    "                                        print(DF_FINAL)\n",
    "                                        break\n",
    "                                    else:\n",
    "                                        pass\n",
    "            non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        for j in df7.itertuples(index=False):\n",
    "            if str(k[1]) == str(j[0]):\n",
    "                s = j[1]\n",
    "\n",
    "        count = 0\n",
    "        for DF_FINAL in non_prep_data:\n",
    "            try:\n",
    "                if DF_FINAL.iloc[:, [s]].empty == False:\n",
    "                    DF_10=DF_FINAL.iloc[:, [s]]    \n",
    "                    m=0\n",
    "                    c=0\n",
    "\n",
    "                    #Getting the count of  empty rows..3\n",
    "                    for index, row in DF_10.iterrows():\n",
    "                        if(pd.notnull(row[0])): \n",
    "                            m=m+1\n",
    "                            break\n",
    "                        else:\n",
    "                            c=c+1\n",
    "\n",
    "                if c==0:\n",
    "                #This Case works when description is in one row\n",
    "                    if \"Unnamed: 1\" in DF_10:\n",
    "                        DF_FINAL.columns=DF_FINAL.iloc[0]\n",
    "                        #print(sh)\n",
    "                        FINAL=DF_FINAL.drop([c])\n",
    "                        FINAL['id']=k[1]\n",
    "                        FINAL.dropna(how='all', axis=1, inplace=True)\n",
    "                        FINAL = FINAL.reset_index(drop=True)\n",
    "                        # FINAL['sheet_name'] = sh\n",
    "                        for i in FINAL.columns:\n",
    "                            x = str(i).lower().strip()\n",
    "                            FINAL=FINAL.rename(columns= {i:x})    \n",
    "\n",
    "\n",
    "                        for i in FINAL.columns.tolist():\n",
    "\n",
    "                            for k in CNames.itertuples(index=False):\n",
    "\n",
    "                                for r in DF6.itertuples(index=False):\n",
    "\n",
    "                                    if str(k[1]) == str(r[2]):\n",
    "                                        try:\n",
    "\n",
    "                                            for i in FINAL.columns.tolist():\n",
    "\n",
    "                                                if str(i) == str(r[0]):\n",
    "\n",
    "                                                    FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                                        except:\n",
    "                                            pass\n",
    "\n",
    "                        for i in FINAL.columns.tolist():\n",
    "\n",
    "\n",
    "                            for r in DF6.itertuples(index=False):\n",
    "\n",
    "\n",
    "\n",
    "                                if str(r[2]) == \"nan\" :\n",
    "\n",
    "                                    if str(i) == str(r[0]):\n",
    "                                        FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                        combined_final.append(FINAL)\n",
    "\n",
    "                    else:\n",
    "                        #This Case works when description is not found\n",
    "                        FINAL=DF_FINAL\n",
    "                        FINAL['id']=k[1]\n",
    "                        FINAL.dropna(how='all', axis=1, inplace=True)\n",
    "                        FINAL = FINAL.reset_index(drop=True)\n",
    "                        for i in FINAL.columns:\n",
    "                            x = str(i).lower().strip()\n",
    "                            FINAL=FINAL.rename(columns= {i:x})    \n",
    "\n",
    "\n",
    "                        for i in FINAL.columns.tolist():\n",
    "\n",
    "                            for k in CNames.itertuples(index=False):\n",
    "\n",
    "                                for r in DF6.itertuples(index=False):\n",
    "\n",
    "                                    if str(k[1]) == str(r[2]):\n",
    "                                        try:\n",
    "\n",
    "                                            for i in FINAL.columns.tolist():\n",
    "\n",
    "                                                if str(i) == str(r[0]):\n",
    "\n",
    "                                                    FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                                        except:\n",
    "                                            pass\n",
    "\n",
    "                        for i in FINAL.columns.tolist():\n",
    "\n",
    "\n",
    "                            for r in DF6.itertuples(index=False):\n",
    "\n",
    "\n",
    "\n",
    "                                if str(r[2]) == \"nan\" :\n",
    "\n",
    "                                    if str(i) == str(r[0]):\n",
    "                                        FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                        combined_final.append(FINAL)\n",
    "\n",
    "\n",
    "\n",
    "                elif c>=1:\n",
    "                    #This Case works when description is more than 1 row\n",
    "                    #Dropping 'c' rows\n",
    "                    DF_11=DF_FINAL.iloc[c:]\n",
    "                    #print(sh)\n",
    "                    #row values as column names\n",
    "                    DF_11.columns=DF_11.iloc[0]\n",
    "                    #Dropping the row\n",
    "                    FINAL=DF_11.drop([c])\n",
    "                    FINAL['id']=k[1]\n",
    "                    FINAL.dropna(how='all', axis=1, inplace=True)\n",
    "                    FINAL = FINAL.reset_index(drop=True)\n",
    "\n",
    "                    # for FINAL in FINAL.columns:\n",
    "                    #     # FINAL['sheet_name'] = sh\n",
    "                    #     FINAL['sheet_name'] = sh      # this adds `sheet_name` into the column `Week`\n",
    "                    # combined_final = combined_final.append(FINAL)\n",
    "                    for i in FINAL.columns:\n",
    "                        x = str(i).lower().strip()\n",
    "                        FINAL=FINAL.rename(columns= {i:x})    \n",
    "\n",
    "\n",
    "                    for i in FINAL.columns.tolist():\n",
    "\n",
    "                        for k in CNames.itertuples(index=False):\n",
    "\n",
    "                            for r in DF6.itertuples(index=False):\n",
    "\n",
    "                                if str(k[1]) == str(r[2]):\n",
    "                                    try:\n",
    "\n",
    "                                        for i in FINAL.columns.tolist():\n",
    "\n",
    "                                            if str(i) == str(r[0]):\n",
    "\n",
    "                                                FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                                    except:\n",
    "                                        pass\n",
    "\n",
    "                    for i in FINAL.columns.tolist():\n",
    "\n",
    "\n",
    "                        for r in DF6.itertuples(index=False):\n",
    "\n",
    "\n",
    "\n",
    "                            if str(r[2]) == \"nan\" :\n",
    "\n",
    "                                if str(i) == str(r[0]):\n",
    "                                    FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                    combined_final.append(FINAL)\n",
    "\n",
    "                    count += 1\n",
    "                else:\n",
    "                    count += 1\n",
    "                    None\n",
    "\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass\n",
    "\n",
    "        Search_List = list(DF8[\"Dropping columns\"])\n",
    "        #dropping columns\n",
    "        FINAL= FINAL.drop(columns=[col for col in FINAL if col  in Search_List])\n",
    "\n",
    "\n",
    "        column_list = ['inpatient_outpatient']\n",
    "        for col in column_list:\n",
    "            if col not in FINAL.columns:\n",
    "                FINAL[col] = ' '\n",
    "\n",
    "\n",
    "        df2=FINAL\n",
    "        df2 = df_column_uniquify(df2)\n",
    "        #Required format - variable list\n",
    "        Col_list = list(DF5[\"Columns\"])\n",
    "        df3=df2.melt(id_vars=[col for col in df2 if col in Col_list],var_name=\"name\",value_name='cost')\n",
    "\n",
    "\n",
    "        df4=df3\n",
    "        df4=df4[df4['cost'].notnull()]\n",
    "        #Dropping_columns=['Not offered','Not Contracted','N/A','Not a covered service','Not Offered','Not contracted','Not a covered service','N/A']\n",
    "        #df4 = df4[~df4['Cost'].isin(Dropping_columns)]\n",
    "        df4\n",
    "        Combined_data.append(df4)\n",
    "    Combined_data = pd.concat(Combined_data)\n",
    "\n",
    "    Combined_data\n",
    "\n",
    "    Combined_data = Combined_data.drop_duplicates()\n",
    "    #Combined_data[\"id\"]=Combined_data.id.astype('int64')\n",
    "    #Combined_data.dtypes\n",
    "    Sample_output = Combined_data       \n",
    "\n",
    "    output_path = r\"C:\\Users\\User\\Zigna AI Corp\\Zigna AI Corp - RightPx\\Hospital Application_2022-03-09\\Automation_task\\outputs\\Wideformat117_{}.csv\"\n",
    "    Sample_output.to_csv(output_path.format(k[1]), index=False)\n",
    "    return Sample_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c3a905b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "################# wideFormat118 ##################\n",
    "def wideFormat118(CNames):\n",
    "    global df7\n",
    "    \n",
    "    Combined_data = []\n",
    "    combined_final = []\n",
    "    non_prep_data = []\n",
    "    #Getting the details as list from files\n",
    "    for k in CNames.itertuples(index=False):\n",
    "        f=k[0] \n",
    "        #Checking the file type- xlsx   \n",
    "        if k[2]== 'csv':\n",
    "            try:\n",
    "                DF_FINAL=pd.read_csv(f)\n",
    "            except:\n",
    "                DF_FINAL=pd.read_csv(f,encoding='latin1')\n",
    "\n",
    "            non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        elif k[2]== 'xlsx':\n",
    "            sheet_to = pd.read_excel(f,sheet_name=None,dtype=str,header=None)\n",
    "\n",
    "            for sh in sheet_to.keys():\n",
    "\n",
    "                DF_FINAL = pd.read_excel(f,sheet_name=sh,dtype=str,header=None)\n",
    "                print(sh)\n",
    "                non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        for j in df7.itertuples(index=False):\n",
    "            if str(k[1]) == str(j[0]):\n",
    "                s = j[1]\n",
    "\n",
    "        for DF_FINAL in non_prep_data:\n",
    "            try:\n",
    "                if DF_FINAL.iloc[:, [s]].empty == False:\n",
    "                    DF_10=DF_FINAL.iloc[:, [s]]    \n",
    "                    m=0\n",
    "                    c=0\n",
    "\n",
    "                    #Getting the count of  empty rows\n",
    "                    for index, row in DF_10.iterrows():\n",
    "                        if(pd.notnull(row[5])): \n",
    "                            m=m+1\n",
    "                            break\n",
    "                        else:\n",
    "                            c=c+1\n",
    "\n",
    "                    if c==0:\n",
    "                    #This Case works when description is in one row\n",
    "                        if \"Unnamed: 5\" in DF_10:\n",
    "                            FINAL = DF_FINAL\n",
    "                            FINAL['id']=k[1]\n",
    "                            for i in FINAL.columns:\n",
    "                                x = str(i).lower().strip()\n",
    "                                FINAL=FINAL.rename(columns= {i:x})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                            for k in CNames.itertuples(index=False):\n",
    "                                for r in DF6.itertuples(index=False):\n",
    "                                    if str(k[1]) == str(r[2]):\n",
    "                                        try:\n",
    "                                            for i in FINAL.columns.tolist():\n",
    "                                                if str(i) == str(r[0]):\n",
    "                                                    FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                                        except:\n",
    "                                            pass\n",
    "                            for i in FINAL.columns.tolist():\n",
    "\n",
    "                                for r in DF6.itertuples(index=False):\n",
    "\n",
    "\n",
    "\n",
    "                                    if str(r[2]) == \"nan\" :\n",
    "\n",
    "                                        if str(i) == str(r[0]):\n",
    "                                            FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                            combined_final.append(FINAL)\n",
    "                        else:\n",
    "                            #This Case works when description is not found\n",
    "                            DF_FINAL.iloc[:c, :c] = np.nan\n",
    "\n",
    "                            DF_FINAL[:c] = DF_FINAL[:c].fillna(method='ffill', axis=1)\n",
    "                            DF_FINAL = DF_FINAL.replace(np.nan,'',regex=True)\n",
    "                            idx = DF_FINAL.index.get_loc(c)\n",
    "                            DF_11 = DF_FINAL.iloc[idx - c :]\n",
    "                            j = c+1\n",
    "\n",
    "                            req_rows = np.where(DF_11.index == j)[0][0]\n",
    "                            start = max(0, req_rows - j )\n",
    "                            end = max(1, req_rows)\n",
    "                            DF_12 = DF_11.iloc[start:end]\n",
    "\n",
    "                            DF_12= DF_12.apply(lambda c: ' '.join(c), axis=0)\n",
    "                            DF_12 = DF_12.to_frame()\n",
    "                            DF_13 = DF_12.T\n",
    "\n",
    "                            DF_11.drop(DF_11.head(j).index, inplace = True)\n",
    "                            DF15 = DF_13.append(DF_11)\n",
    "                            DF16 = DF15.reset_index(drop = True)\n",
    "                            DF16.columns = DF16.iloc[0]\n",
    "                            FINAL = DF16[1:]\n",
    "                            FINAL['id']=k[1]\n",
    "                            for i in FINAL.columns:\n",
    "                                x = str(i).lower().strip()\n",
    "                                FINAL=FINAL.rename(columns= {i:x})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                            for k in CNames.itertuples(index=False):\n",
    "                                for r in DF6.itertuples(index=False):\n",
    "                                    if str(k[1]) == str(r[2]):\n",
    "                                        try:\n",
    "                                            for i in FINAL.columns.tolist():\n",
    "                                                if str(i) == str(r[0]):\n",
    "                                                    FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                                        except:\n",
    "                                            pass\n",
    "                            for i in FINAL.columns.tolist():\n",
    "\n",
    "                                for r in DF6.itertuples(index=False):\n",
    "\n",
    "\n",
    "\n",
    "                                    if str(r[2]) == \"nan\" :\n",
    "\n",
    "                                        if str(i) == str(r[0]):\n",
    "                                            FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                            combined_final.append(FINAL)\n",
    "\n",
    "                    elif c>=1:\n",
    "                        #This Case works when description is more than 1 row\n",
    "                        #Dropping 'c' rows\n",
    "                        DF_FINAL.iloc[:c, :c] = np.nan\n",
    "\n",
    "                        DF_FINAL[:c] = DF_FINAL[:c].fillna(method='ffill', axis=1)\n",
    "                        DF_FINAL = DF_FINAL.replace(np.nan,'',regex=True)\n",
    "                        idx = DF_FINAL.index.get_loc(c)\n",
    "                        DF_11 = DF_FINAL.iloc[idx - c :]\n",
    "                        j = c+1\n",
    "\n",
    "                        req_rows = np.where(DF_11.index == j)[0][0]\n",
    "                        start = max(0, req_rows - j )\n",
    "                        end = max(1, req_rows)\n",
    "                        DF_12 = DF_11.iloc[start:end]\n",
    "\n",
    "                        DF_12= DF_12.apply(lambda c: ' '.join(c), axis=0)\n",
    "                        DF_12 = DF_12.to_frame()\n",
    "                        DF_13 = DF_12.T\n",
    "\n",
    "                        DF_11.drop(DF_11.head(j).index, inplace = True)\n",
    "                        DF15 = DF_13.append(DF_11)\n",
    "                        DF16 = DF15.reset_index(drop = True)\n",
    "                        DF16.columns = DF16.iloc[0]\n",
    "                        FINAL = DF16[1:]\n",
    "                        FINAL['id']=k[1]\n",
    "\n",
    "\n",
    "\n",
    "                        for i in FINAL.columns:\n",
    "                            x = str(i).lower().strip()\n",
    "                            FINAL=FINAL.rename(columns= {i:x})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                        for k in CNames.itertuples(index=False):\n",
    "                            for r in DF6.itertuples(index=False):\n",
    "                                if str(k[1]) == str(r[2]):\n",
    "                                    try:\n",
    "                                        for i in FINAL.columns.tolist():\n",
    "                                            if str(i) == str(r[0]):\n",
    "                                                FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                                    except:\n",
    "                                        pass\n",
    "                        for i in FINAL.columns.tolist():\n",
    "\n",
    "                            for r in DF6.itertuples(index=False):\n",
    "\n",
    "\n",
    "\n",
    "                                if str(r[2]) == \"nan\" :\n",
    "\n",
    "                                    if str(i) == str(r[0]):\n",
    "                                        FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                        combined_final.append(FINAL)\n",
    "                    else:\n",
    "                        None\n",
    "\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass\n",
    "\n",
    "        try:\n",
    "            FINAL = pd.concat(combined_final)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            FINAL = FINAL.loc[:, FINAL.columns.notnull()]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            for col in FINAL.columns:\n",
    "                if col =='unnamed: 0':\n",
    "                    FINAL=FINAL.drop([\"unnamed: 0\"],axis=1)\n",
    "                else:\n",
    "                       None\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        Search_List = list(DF8[\"Dropping columns\"])\n",
    "        #dropping columns\n",
    "        FINAL= FINAL.drop(columns=[col for col in FINAL if col  in Search_List])\n",
    "\n",
    "        column_list = ['inpatient_outpatient']\n",
    "        for col in column_list:\n",
    "            if col not in FINAL.columns:\n",
    "                FINAL[col] = ' ' \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        df2=FINAL\n",
    "        df2 = df_column_uniquify(df2)\n",
    "        #Required format - variable list\n",
    "        Col_list = list(DF5[\"Columns\"])\n",
    "        df3=df2.melt(id_vars=[col for col in df2 if col in Col_list],var_name=\"name\",value_name='cost')\n",
    "        #df3=df1.melt(id_vars=['ID','Description','Cpt Code','Rev_Cd','Units'],var_name=\"Name\",value_name='Cost')\n",
    "\n",
    "\n",
    "\n",
    "        df4=df3\n",
    "        df4=df4[df4['cost'].notnull()]\n",
    "        df4=df4[df4['name'].notnull()]\n",
    "\n",
    "        #Dropping_columns=['Not offered','Not Contracted','N/A','Not a covered service','Not Offered','Not contracted','Not a covered service','N/A']\n",
    "        #df4 = df4[~df4['Cost'].isin(Dropping_columns)]\n",
    "        df4\n",
    "        Combined_data.append(df4)\n",
    "    Combined_data = pd.concat(Combined_data)\n",
    "\n",
    "    Combined_data\n",
    "    Combined_data.drop_duplicates()\n",
    "    #Combined_data[\"id\"]=Combined_data.id.astype('int64')\n",
    "    #Combined_data.dtypes\n",
    "\n",
    "    #Joining both hospital data with shoppable data by ID\n",
    "    #Sample_output=pd.merge(left=DHC_Hosp_data1, right=Combined_data,how='inner',left_on=['Hospital_Id'],right_on=['id'])\n",
    "    Sample_output = Combined_data\n",
    "    #Dropping the columns\n",
    "    #Sample_output.drop([\"id\"], axis = 1, inplace = True)\n",
    "    #Sample_output['inpatient-outpatient'] = np.where((Sample_output['inpatient-outpatient'] ==' ') & (Sample_output['name'].str.contains('inpatient/outpatient/drug')) , 'IP/OP', Sample_output['inpatient-outpatient'])\n",
    "    #Sample_output['inpatient-outpatient'] = np.where((Sample_output['inpatient-outpatient'] ==' ') & (Sample_output['name'].str.contains('inpatient/outpatient/drug')) , 'IP/OP', Sample_output['inpatient-outpatient'])\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains('ip & op')) , 'IP & OP', Sample_output['inpatient_outpatient'])\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains('ip & op')) , 'IP & OP', Sample_output['inpatient_outpatient'])\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains('ip/op')) , 'Inpatient', Sample_output['inpatient_outpatient'])\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains('ip/op')) , 'Outpatient', Sample_output['inpatient_outpatient'])\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains('inpatient')) , 'Inpatient', Sample_output['inpatient_outpatient'])\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains('outpatient')) , 'Outpatient', Sample_output['inpatient_outpatient'])\n",
    "    #Sample_output['inpatient-outpatient'] = np.where((Sample_output['inpatient-outpatient'] ==' ') & (Sample_output['name'].str.contains('ip')) , 'Inpatient', Sampl\n",
    "\n",
    "\n",
    "    output_path = r\"C:\\Users\\User\\Zigna AI Corp\\Zigna AI Corp - RightPx\\Hospital Application_2022-03-09\\Automation_task\\outputs\\Wideformat118_{}.csv\"\n",
    "    Sample_output.to_csv(output_path.format((k[1])), index=False)\n",
    "    return Sample_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c66f4d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### wideFormat128 ####################\n",
    "def wideFormat128(CNames):\n",
    "    global df7\n",
    "    \n",
    "    Combined_data = []\n",
    "    combined_final = []\n",
    "    non_prep_data = []\n",
    "    #Getting the details as list from files\n",
    "    for k in CNames.itertuples(index=False):\n",
    "        f=k[0] \n",
    "        #Checking the file type- xlsx   \n",
    "        if k[2]== 'csv':\n",
    "            try:\n",
    "                DF_FINAL=pd.read_csv(f, header = None)\n",
    "            except:\n",
    "                DF_FINAL=pd.read_csv(f,encoding='latin1',  header = None)\n",
    "\n",
    "\n",
    "        elif k[2]== 'xlsx':\n",
    "            sheet_to = pd.read_excel(f,sheet_name=None,dtype=str,  header = None)\n",
    "\n",
    "            for sh in sheet_to.keys():\n",
    "\n",
    "                DF_FINAL = pd.read_excel(f,sheet_name=sh,dtype=str,  header = None)\n",
    "                print(sh)\n",
    "\n",
    "\n",
    "                non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        for j in df7.itertuples(index=False):\n",
    "            if str(k[1]) == str(j[0]):\n",
    "                s = j[1]\n",
    "\n",
    "        for DF_FINAL in non_prep_data:\n",
    "\n",
    "\n",
    "            try:\n",
    "                if DF_FINAL.iloc[:, [s]].empty == False:\n",
    "\n",
    "\n",
    "                    DF_10 = DF_FINAL.iloc[:,[s]]\n",
    "                    m=0\n",
    "                    c=0\n",
    "\n",
    "            #Getting the count of  empty rows\n",
    "                for index, row in DF_10.iterrows():\n",
    "                    if(pd.notnull(row[1])): \n",
    "                        m=m+1\n",
    "                        break\n",
    "                    else:\n",
    "                        c=c+1\n",
    "\n",
    "\n",
    "                    if c==0:\n",
    "                    #This Case works when description is in one row\n",
    "                        if \"Unnamed: 5\" in DF_10:\n",
    "                            DF_FINAL.columns=DF_FINAL.iloc[0]\n",
    "                            FINAL=DF_FINAL.drop([c])\n",
    "                            FINAL['id']=k[1]\n",
    "                            for i in FINAL.columns:\n",
    "                                x = str(i).lower().strip()\n",
    "                                FINAL=FINAL.rename(columns= {i:x})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                            for k in CNames.itertuples(index=False):\n",
    "                                for r in DF6.itertuples(index=False):\n",
    "                                    if str(k[1]) == str(r[2]):\n",
    "                                        try:\n",
    "                                            for i in FINAL.columns.tolist():\n",
    "                                                if str(i) == str(r[0]):\n",
    "                                                    FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                                        except:\n",
    "                                            pass\n",
    "                            for i in FINAL.columns.tolist():\n",
    "\n",
    "                                for r in DF6.itertuples(index=False):\n",
    "\n",
    "\n",
    "\n",
    "                                    if str(r[2]) == \"nan\" :\n",
    "\n",
    "                                        if str(i) == str(r[0]):\n",
    "                                            FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                            combined_final.append(FINAL)\n",
    "                        else:\n",
    "                            #This Case works when description is not found\n",
    "                            DF_FINAL.iloc[:c, :c] = np.nan\n",
    "\n",
    "                            DF_FINAL[:c] = DF_FINAL[:c].fillna(method='ffill', axis=1)\n",
    "                            DF_FINAL = DF_FINAL.replace(np.nan,'',regex=True)\n",
    "                            idx = DF_FINAL.index.get_loc(c)\n",
    "                            DF_11 = DF_FINAL.iloc[idx - c :]\n",
    "                            j = c+1\n",
    "\n",
    "                            req_rows = np.where(DF_11.index == j)[0][0]\n",
    "                            start = max(0, req_rows - j )\n",
    "                            end = max(1, req_rows)\n",
    "                            DF_12 = DF_11.iloc[start:end]\n",
    "\n",
    "                            DF_12= DF_12.apply(lambda c: ' '.join(c), axis=0)\n",
    "                            DF_12 = DF_12.to_frame()\n",
    "                            DF_13 = DF_12.T\n",
    "\n",
    "                            DF_11.drop(DF_11.head(j).index, inplace = True)\n",
    "                            DF15 = DF_13.append(DF_11)\n",
    "                            DF16 = DF15.reset_index(drop = True)\n",
    "                            DF16.columns = DF16.iloc[0]\n",
    "                            FINAL = DF16[1:]\n",
    "                            FINAL['id']=k[1]\n",
    "                            for i in FINAL.columns:\n",
    "                                x = str(i).lower().strip()\n",
    "                                FINAL=FINAL.rename(columns= {i:x})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                            for k in CNames.itertuples(index=False):\n",
    "                                for r in DF6.itertuples(index=False):\n",
    "                                    if str(k[1]) == str(r[2]):\n",
    "                                        try:\n",
    "                                            for i in FINAL.columns.tolist():\n",
    "                                                if str(i) == str(r[0]):\n",
    "                                                    FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                                        except:\n",
    "                                            pass\n",
    "                            for i in FINAL.columns.tolist():\n",
    "\n",
    "                                for r in DF6.itertuples(index=False):\n",
    "\n",
    "\n",
    "\n",
    "                                    if str(r[2]) == \"nan\" :\n",
    "\n",
    "                                        if str(i) == str(r[0]):\n",
    "                                            FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                            combined_final.append(FINAL)\n",
    "\n",
    "                    elif c>=1:\n",
    "                        #This Case works when description is more than 1 row\n",
    "                        #Dropping 'c' rows\n",
    "                        DF_FINAL.iloc[:c, :c] = np.nan\n",
    "\n",
    "                        DF_FINAL[:c] = DF_FINAL[:c].fillna(method='ffill', axis=1)\n",
    "                        DF_FINAL = DF_FINAL.replace(np.nan,'',regex=True)\n",
    "                        idx = DF_FINAL.index.get_loc(c)\n",
    "                        DF_11 = DF_FINAL.iloc[idx - c :]\n",
    "                        j = c+1\n",
    "\n",
    "                        req_rows = np.where(DF_11.index == j)[0][0]\n",
    "                        start = max(0, req_rows - j )\n",
    "                        end = max(1, req_rows)\n",
    "                        DF_12 = DF_11.iloc[start:end]\n",
    "\n",
    "                        DF_12= DF_12.apply(lambda c: ' '.join(c), axis=0)\n",
    "                        DF_12 = DF_12.to_frame()\n",
    "                        DF_13 = DF_12.T\n",
    "\n",
    "                        DF_11.drop(DF_11.head(j).index, inplace = True)\n",
    "                        DF15 = DF_13.append(DF_11)\n",
    "                        DF16 = DF15.reset_index(drop = True)\n",
    "                        DF16.columns = DF16.iloc[0]\n",
    "                        FINAL = DF16[1:]\n",
    "\n",
    "\n",
    "\n",
    "                        for i in FINAL.columns:\n",
    "                            x = str(i).lower().strip()\n",
    "                            FINAL=FINAL.rename(columns= {i:x})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                        for k in CNames.itertuples(index=False):\n",
    "                            for r in DF6.itertuples(index=False):\n",
    "                                if str(k[1]) == str(r[2]):\n",
    "                                    try:\n",
    "                                        for i in FINAL.columns.tolist():\n",
    "                                            if str(i) == str(r[0]):\n",
    "                                                FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                                    except:\n",
    "                                        pass\n",
    "                        for i in FINAL.columns.tolist():\n",
    "\n",
    "                            for r in DF6.itertuples(index=False):\n",
    "\n",
    "\n",
    "\n",
    "                                if str(r[2]) == \"nan\" :\n",
    "\n",
    "                                    if str(i) == str(r[0]):\n",
    "                                        FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                        combined_final.append(FINAL)\n",
    "                    else:\n",
    "                        None\n",
    "\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass\n",
    "\n",
    "        try:\n",
    "            FINAL = pd.concat(combined_final)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            FINAL = FINAL.loc[:, FINAL.columns.notnull()]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            for col in FINAL.columns:\n",
    "                if col =='unnamed: 0':\n",
    "                    FINAL=FINAL.drop([\"unnamed: 0\"],axis=1)\n",
    "                else:\n",
    "                       None\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        Search_List = list(DF8[\"Dropping columns\"])\n",
    "        #dropping columns\n",
    "        FINAL= FINAL.drop(columns=[col for col in FINAL if col  in Search_List])\n",
    "\n",
    "        column_list = ['inpatient_outpatient']\n",
    "        for col in column_list:\n",
    "            if col not in FINAL.columns:\n",
    "                FINAL[col] = ' ' \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        df2=FINAL\n",
    "        df2 = df_column_uniquify(df2)\n",
    "        #Required format - variable list\n",
    "        Col_list = list(DF5[\"Columns\"])\n",
    "        df3=df2.melt(id_vars=[col for col in df2 if col in Col_list],var_name=\"name\",value_name='cost')\n",
    "        #df3=df1.melt(id_vars=['ID','Description','Cpt Code','Rev_Cd','Units'],var_name=\"Name\",value_name='Cost')\n",
    "\n",
    "\n",
    "\n",
    "        df4=df3\n",
    "        df4=df4[df4['cost'].notnull()]\n",
    "        df4=df4[df4['name'].notnull()]\n",
    "\n",
    "        #Dropping_columns=['Not offered','Not Contracted','N/A','Not a covered service','Not Offered','Not contracted','Not a covered service','N/A']\n",
    "        #df4 = df4[~df4['Cost'].isin(Dropping_columns)]\n",
    "        df4\n",
    "        Combined_data.append(df4)\n",
    "    Combined_data = pd.concat(Combined_data)\n",
    "\n",
    "    Combined_data\n",
    "    Combined_data.drop_duplicates()\n",
    "    #Combined_data[\"id\"]=Combined_data.id.astype('int64')\n",
    "    #Combined_data.dtypes\n",
    "\n",
    "    #Joining both hospital data with shoppable data by ID\n",
    "    #Sample_output=pd.merge(left=DHC_Hosp_data1, right=Combined_data,how='inner',left_on=['Hospital_Id'],right_on=['id'])\n",
    "    Sample_output = Combined_data\n",
    "    #Dropping the columns\n",
    "    #Sample_output.drop([\"id\"], axis = 1, inplace = True)\n",
    "    #Sample_output['inpatient-outpatient'] = np.where((Sample_output['inpatient-outpatient'] ==' ') & (Sample_output['name'].str.contains('inpatient/outpatient/drug')) , 'IP/OP', Sample_output['inpatient-outpatient'])\n",
    "    #Sample_output['inpatient-outpatient'] = np.where((Sample_output['inpatient-outpatient'] ==' ') & (Sample_output['name'].str.contains('inpatient/outpatient/drug')) , 'IP/OP', Sample_output['inpatient-outpatient'])\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains('ip & op')) , 'IP & OP', Sample_output['inpatient_outpatient'])\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains('ip & op')) , 'IP & OP', Sample_output['inpatient_outpatient'])\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains('ip/op')) , 'Inpatient', Sample_output['inpatient_outpatient'])\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains('ip/op')) , 'Outpatient', Sample_output['inpatient_outpatient'])\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains('inpatient')) , 'Inpatient', Sample_output['inpatient_outpatient'])\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains('outpatient')) , 'Outpatient', Sample_output['inpatient_outpatient'])\n",
    "    #Sample_output['inpatient-outpatient'] = np.where((Sample_output['inpatient-outpatient'] ==' ') & (Sample_output['name'].str.contains('ip')) , 'Inpatient', Sampl\n",
    "\n",
    "\n",
    "    output_path = r\"C:\\Users\\User\\Zigna AI Corp\\Zigna AI Corp - RightPx\\Hospital Application_2022-03-09\\Automation_task\\outputs\\Wideformat128_{}.csv\"\n",
    "    Sample_output.to_csv(output_path.format((k[1])), index=False)\n",
    "    return Sample_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "26ce4db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "################### wideFormat12 #####################\n",
    "def wideFormat12(CNames):\n",
    "    global df7\n",
    "    \n",
    "    Combined_data = []\n",
    "    combined_final = []\n",
    "    non_prep_data = []\n",
    "    #Getting the details as list from files\n",
    "    for k in CNames.itertuples(index=False):\n",
    "        f=k[0] \n",
    "        #Checking the file type- xlsx   \n",
    "        if k[2]== 'csv':\n",
    "            try:\n",
    "                DF_FINAL=pd.read_csv(f)\n",
    "            except:\n",
    "                DF_FINAL=pd.read_csv(f,encoding='latin1')\n",
    "\n",
    "            non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        elif k[2]== 'xlsx':\n",
    "            sheet_to = pd.read_excel(f,sheet_name=None,dtype=str,header=None)\n",
    "\n",
    "            for sh in sheet_to.keys():\n",
    "\n",
    "                DF_FINAL = pd.read_excel(f,sheet_name=sh,dtype=str)\n",
    "                print(sh)\n",
    "                non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        for j in df7.itertuples(index=False):\n",
    "            if str(k[1]) == str(j[0]):\n",
    "                s = j[1]\n",
    "\n",
    "        for DF_FINAL in non_prep_data:\n",
    "            try:\n",
    "                if DF_FINAL.iloc[:, [s]].empty == False:\n",
    "                    DF_10=DF_FINAL.iloc[:, [s]]    \n",
    "                    m=0\n",
    "                    c=0\n",
    "\n",
    "                    #Getting the count of  empty rows\n",
    "                    for index, row in DF_10.iterrows():\n",
    "                        if(pd.notnull(row[0])): \n",
    "                            m=m+1\n",
    "                            break\n",
    "                        else:\n",
    "                            c=c+1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                if c==0:\n",
    "                #This Case works when description is in one row\n",
    "                    if \"Unnamed: 3\" in DF_10:\n",
    "\n",
    "                        # DF_FINAL.columns = pd.Series([np.nan if 'Unnamed:' in x else x for x in DF_FINAL.columns.values]).ffill().values.flatten()\n",
    "                        DF_11=DF_FINAL.iloc[c+1:]\n",
    "                        DF_11[:c]=DF_11[:c].fillna(method='ffill', axis=1,limit=1)\n",
    "                        DF_11[:c-1] = DF_11[:c-1].fillna(' ')\n",
    "\n",
    "                        DF_FINAL.columns = (DF_FINAL.iloc[c+1] + ' ' + DF_FINAL.iloc[c+2])\n",
    "                        #DF_FINAL.columns = pd.Series([np.nan if 'Unnamed:' in x else x for x in DF_FINAL.columns.values]).ffill().values.flatten()\n",
    "                        DF_FINAL = DF_FINAL.iloc[c+3:]\n",
    "                        # DF_FINAL=DF_FINAL.dropna()\n",
    "                        #row values as column names\n",
    "                        #Dropping the row\n",
    "                        FINAL = DF_FINAL.reset_index(drop=True)\n",
    "                        FINAL['id']=k[1]\n",
    "                        FINAL\n",
    "\n",
    "                    else:\n",
    "                        #This Case works when description is not found\n",
    "                        FINAL=DF_FINAL\n",
    "                        FINAL['id']=k[1]\n",
    "                        FINAL\n",
    "\n",
    "\n",
    "\n",
    "                elif c>=1:\n",
    "                    #This Case works when description is more than 1 row\n",
    "                    #Dropping 'c' rows\n",
    "                    DF_11=DF_FINAL.iloc[c-1:]\n",
    "                    DF_11[:c-1]=DF_11[:c-1].fillna(method='ffill', axis=1)\n",
    "                    DF_11[:c-1] = DF_11[:c-1].fillna(' ')\n",
    "                    DF_FINAL.columns = (DF_FINAL.iloc[c-1] + ' ' + DF_FINAL.iloc[c])\n",
    "                    DF_FINAL = DF_FINAL.iloc[c+2:]\n",
    "                    #row values as column names\n",
    "                    #Dropping the row\n",
    "                    FINAL = DF_FINAL.reset_index(drop=True)\n",
    "                    FINAL['id']=k[1]\n",
    "                    FINAL\n",
    "                else:\n",
    "                    None \n",
    "\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass\n",
    "\n",
    "        for i in FINAL.columns:\n",
    "                x = str(i).lower().strip()\n",
    "                FINAL=FINAL.rename(columns= {i:x})\n",
    "\n",
    "\n",
    "        for i in FINAL.columns.tolist():\n",
    "            for r in DF6.itertuples(index=False):\n",
    "                if str(i) == str(r[0]):\n",
    "                    FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "\n",
    "        Search_List = list(DF8[\"Dropping columns\"])\n",
    "        #dropping columns\n",
    "        FINAL= FINAL.drop(columns=[col for col in FINAL if col  in Search_List])\n",
    "    #Checking the  Inpatient/Outpatient column exists or not\n",
    "        column_list = ['inpatient_outpatient']\n",
    "        for col in column_list:\n",
    "            if col not in FINAL.columns:\n",
    "                FINAL[col] = ' '\n",
    "\n",
    "        #Search_List = list(DF3[\"Keeping columns\"])\n",
    "        #Keeping columns\n",
    "        #df1= FINAL.drop(columns=[col for col in FINAL if col not in Search_List])\n",
    "        #Removing the empty rows from'cpt code'\n",
    "        #df2 = df1.dropna(axis=0, subset=['Cpt Code'])\n",
    "\n",
    "        #df2=FINAL[FINAL['cpt code'].notnull()] \n",
    "\n",
    "        df2=FINAL\n",
    "        df2 = df_column_uniquify(df2)\n",
    "\n",
    "        try:\n",
    "            df2 = df2[df2[\"billing_code\"].str.contains(\"2020 CPT/HCPCS\")==False]\n",
    "            df2=df2[df2['billing_code'].notnull()]\n",
    "        except:\n",
    "            pass\n",
    "        df2[\"lineitem_cnt\"] = df2.groupby([\"billing_code\"])[\"billing_code\"].transform('count')\n",
    "        df2[\"lineitem_cnt\"]=df2[\"lineitem_cnt\"]-1\n",
    "        #Required format - variable list\n",
    "        Col_list = list(DF5[\"Columns\"])\n",
    "        df3=df2.melt(id_vars=[col for col in df2 if col in Col_list],var_name=\"name\",value_name='cost')\n",
    "        df3 = df3.replace(r'^\\s*$', np.NaN, regex=True)\n",
    "        df3=df3[df3['name'].notnull()]#df3=df1.melt(id_vars=['ID','Description','Cpt Code','Rev_Cd','Units'],var_name=\"Name\",value_name='Cost')\n",
    "\n",
    "        #df3['payer'] = None\n",
    "        #df3['insurance Type'] = None\n",
    "\n",
    "        #df3['Benefit Type']=None\n",
    "\n",
    "        #Name_List = list(DF1[\"Payers\"])\n",
    "\n",
    "        #Name_List1 = list(DF2[\"Insurance Type\"])\n",
    "\n",
    "        #Name_List2 = list(DF3[\"Benefit Type\"])\n",
    "\n",
    "        #Finding Payers from the list\n",
    "        #for i in Name_List:\n",
    "        #    df3['payer'][(df3['name'].str.contains(i,case=False,na=False))] = i\n",
    "        #Finding Insurancetype from the list    \n",
    "        #for j in Name_List1:\n",
    "        #    df3['insurance Type'][(df3['name'].str.contains(j,case=False,na=False))] = j\n",
    "\n",
    "        #Finding Benefit Type from the list  \n",
    "        #for k in Name_List2:\n",
    "        #    df3['Benefit Type'][(df3['name'].str.contains(k,case=False,na=False))] = k \n",
    "\n",
    "        df4=df3\n",
    "        df4=df4[df4['cost'].notnull()]\n",
    "\n",
    "\n",
    "        #Dropping_columns=['Not offered','Not Contracted','N/A','Not a covered service','Not Offered','Not contracted','Not a covered service','N/A']\n",
    "        #df4 = df4[~df4['Cost'].isin(Dropping_columns)]\n",
    "        df4\n",
    "        Combined_data.append(df4)\n",
    "    Combined_data = pd.concat(Combined_data)\n",
    "\n",
    "    Combined_data\n",
    "    #Combined_data[\"id\"]=Combined_data.id.astype('int64')\n",
    "    Combined_data.dtypes\n",
    "\n",
    "    #Joining both hospital data with shoppable data by ID\n",
    "    #Sample_output=pd.merge(left=DHC_Hosp_data1, right=Combined_data,how='inner',left_on=['Hospital_Id'],right_on=['id'])\n",
    "\n",
    "    #Dropping the columns\n",
    "    #Sample_output.drop([\"id\"], axis = 1, inplace = True)\n",
    "\n",
    "    # Combined_data['inpatient-outpatient'] = np.where((Combined_data['inpatient-outpatient'] ==' ') & (Combined_data['name'].str.contains('ip')) , 'Inpatient', Combined_data['inpatient-outpatient'])\n",
    "    # Combined_data['inpatient-outpatient'] = np.where((Combined_data['inpatient-outpatient'] ==' ') & (Combined_data['name'].str.contains(' op')) , 'Outpatient', Combined_data['inpatient-outpatient'])\n",
    "\n",
    "    Combined_data\n",
    "    output_path = r\"C:\\Users\\User\\Zigna AI Corp\\Zigna AI Corp - RightPx\\Hospital Application_2022-03-09\\Automation_task\\outputs\\Wideformat12_{}.csv\"\n",
    "    Combined_data.to_csv(output_path.format((k[1])), index=False)\n",
    "    return Combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0d9d2ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "################# wideFormat131 #################\n",
    "def wideFormat131(CNames):\n",
    "    global df7\n",
    "    \n",
    "    Combined_data = []\n",
    "    combined_final = []\n",
    "    non_prep_data = []\n",
    "    #Getting the details as list from files\n",
    "    for k in CNames.itertuples(index=False):\n",
    "        f=k[0] \n",
    "        #Checking the file type- xlsx   \n",
    "        if k[2]== 'csv':\n",
    "            try:\n",
    "                DF_FINAL=pd.read_csv(f)\n",
    "            except:\n",
    "                DF_FINAL=pd.read_csv(f,encoding='latin1')\n",
    "\n",
    "\n",
    "        elif k[2]== 'xlsx':\n",
    "            sheet_to = pd.read_excel(f,sheet_name=None,dtype=str)\n",
    "\n",
    "            for sh in sheet_to.keys():\n",
    "\n",
    "                DF_FINAL = pd.read_excel(f,sheet_name=sh,dtype=str)\n",
    "                print(sh)\n",
    "\n",
    "\n",
    "                non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        for j in df7.itertuples(index=False):\n",
    "            if str(k[1]) == str(j[0]):\n",
    "                s = j[1]\n",
    "\n",
    "        for DF_FINAL in non_prep_data:\n",
    "\n",
    "\n",
    "            try:\n",
    "                if DF_FINAL.iloc[:, [s]].empty == False:\n",
    "\n",
    "\n",
    "                    DF_10 = DF_FINAL.iloc[:,[s]] ###### it is  6\n",
    "                    m=0\n",
    "                    c=0\n",
    "\n",
    "\n",
    "\n",
    "                    #Getting the count of  empty rows\n",
    "                    for index, row in DF_10.iterrows():\n",
    "                        if(pd.notnull(row.iloc[0])): \n",
    "                            m=m+1\n",
    "                            break\n",
    "                        else:\n",
    "                            c=c+1\n",
    "                    print(c)\n",
    "                    if c==0:\n",
    "                    #This Case works when description is in one row\n",
    "                        if \"Unnamed: 5\" in DF_10:\n",
    "                            DF_FINAL.columns=DF_FINAL.iloc[0]\n",
    "                            FINAL=DF_FINAL.drop([c])\n",
    "                            FINAL['id']=k[1]\n",
    "                            combined_final.append(FINAL)\n",
    "                        else:\n",
    "                            #This Case works when description is not found\n",
    "                            FINAL=DF_FINAL\n",
    "                            FINAL['id']=k[1]\n",
    "                            combined_final.append(FINAL)\n",
    "\n",
    "\n",
    "                    elif c>=1:\n",
    "                        # From c-1 idex the rows are considered \n",
    "                        # c-1 row is ffilled and c-1 and c rows are combined to form the column names of DF_11 dataframe\n",
    "                        # Dropping 'c and c-1' rows\n",
    "                        # sheets are appended to combined final\n",
    "                        DF_FINAL = DF_FINAL.dropna(axis=1, how='all')\n",
    "                        DF_11=DF_FINAL.iloc[c-1:]\n",
    "                        DF_FINAL.iloc[c-1] = DF_FINAL.iloc[c-1].fillna(method='ffill')\n",
    "                        DF_11.columns = DF_FINAL.iloc[c-1].astype('str')+'_'+DF_FINAL.iloc[c].astype('str')\n",
    "                        DF_11 = DF_11.iloc[2:]\n",
    "                        DF_11 = DF_11.dropna(axis=1, how='all')\n",
    "                        #Dropping the row\n",
    "                        FINAL=DF_11\n",
    "                        FINAL['id']=k[1]\n",
    "                        combined_final.append(FINAL)\n",
    "\n",
    "                    else:\n",
    "                        pass\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass\n",
    "        FINAL = pd.concat(combined_final)\n",
    "\n",
    "        for i in FINAL.columns:\n",
    "            x = str(i).lower().strip()\n",
    "            FINAL=FINAL.rename(columns= {i:x})\n",
    "        #FINAL.drop(['hospital data_chargedept'], axis = 1, inplace = True)\n",
    "\n",
    "        for i in FINAL.columns.tolist():\n",
    "\n",
    "            for k in CNames.itertuples(index=False):\n",
    "\n",
    "                for r in DF6.itertuples(index=False):\n",
    "\n",
    "                    if str(k[1]) == str(r[2]):\n",
    "                        try:\n",
    "\n",
    "                            for i in FINAL.columns.tolist():\n",
    "\n",
    "                                if str(i) == str(r[0]):\n",
    "\n",
    "                                    FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                        except:\n",
    "                                pass\n",
    "\n",
    "        for i in FINAL.columns.tolist():\n",
    "            for r in DF6.itertuples(index=False):\n",
    "                if str(r[2]) == \"nan\" :\n",
    "\n",
    "\n",
    "                    if str(i) == str(r[0]):\n",
    "                        FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        Search_List = list(DF8[\"Dropping columns\"])\n",
    "\n",
    "        FINAL= FINAL.drop(columns=[col for col in FINAL if col in Search_List])\n",
    "        df2=FINAL\n",
    "        df2 = df_column_uniquify(df2)\n",
    "\n",
    "        column_list = ['inpatient_outpatient']\n",
    "        for col in column_list:\n",
    "            if col not in FINAL.columns:\n",
    "                FINAL[col] = ' '\n",
    "\n",
    "        #Required format - variable list\n",
    "\n",
    "        Col_list = list(DF5[\"Columns\"])\n",
    "        df3=df2.melt(id_vars=[col for col in df2 if col in Col_list],var_name=\"name\",value_name='cost')   \n",
    "        df4=df3\n",
    "        df4=df4[df4['cost'].notnull()]\n",
    "        df4=df4[df4['cpt_hcpcs_drg_aprdrg_icdx10'].notnull()]\n",
    "        Combined_data.append(df4)\n",
    "    Combined_data = pd.concat(Combined_data)\n",
    "    Combined_data\n",
    "\n",
    "    Sample_output = Combined_data\n",
    "    output_path = r\"C:\\Users\\User\\Zigna AI Corp\\Zigna AI Corp - RightPx\\Hospital Application_2022-03-09\\Automation_task\\outputs\\Wideformat131_{}.csv\"\n",
    "    Sample_output.to_csv(output_path.format((k[1])), index=False)\n",
    "    return Sample_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d8a3d163",
   "metadata": {},
   "outputs": [],
   "source": [
    "################## wideFormat132 ##################\n",
    "def wideFormat132(CNames):\n",
    "    global df7\n",
    "    \n",
    "    Combined_data = []\n",
    "    combined_final = []\n",
    "    non_prep_data = []\n",
    "    #Getting the details as list from files\n",
    "    for k in CNames.itertuples(index=False):\n",
    "        f=k[0] \n",
    "        #Checking the file type- xlsx   \n",
    "        if k[2]== 'csv':\n",
    "            try:\n",
    "                DF_FINAL=pd.read_csv(f)\n",
    "            except:\n",
    "                DF_FINAL=pd.read_csv(f,encoding='latin1')\n",
    "\n",
    "            non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        elif k[2]== 'xlsx':\n",
    "            sheet_to = pd.read_excel(f,sheet_name=None,dtype=str,header=None)\n",
    "\n",
    "            for sh in sheet_to.keys():\n",
    "\n",
    "                DF_FINAL = pd.read_excel(f,sheet_name=sh,dtype=str)\n",
    "                print(sh)\n",
    "                non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        for j in df7.itertuples(index=False):\n",
    "            if str(k[1]) == str(j[0]):\n",
    "                s = j[1]\n",
    "\n",
    "        for DF_FINAL in non_prep_data:\n",
    "            try:\n",
    "                if DF_FINAL.iloc[:, [s]].empty == False:\n",
    "\n",
    "                    dummy = \"\"\n",
    "                    try:\n",
    "                        count = 0\n",
    "                        for i in range(len(DF_FINAL)):\n",
    "                            if DF_FINAL[\"Hospital Name\"][i] == \"Payer\":\n",
    "                                #print(sh)\n",
    "                                count += 1\n",
    "                                dummy = pd.DataFrame(DF_FINAL.iloc[count+1,:2])\n",
    "\n",
    "                    except:\n",
    "                        # dummy = \"\"\n",
    "                        None\n",
    "                    print(dummy)\n",
    "\n",
    "\n",
    "\n",
    "                    DF_10=DF_FINAL.iloc[:, [s]]    \n",
    "                    m=0\n",
    "                    c=0\n",
    "\n",
    "                    #Getting the count of  empty rows\n",
    "                    for index, row in DF_10.iterrows():\n",
    "                        if(pd.notnull(row[0])): \n",
    "                            m=m+1\n",
    "                            break\n",
    "                        else:\n",
    "                            c=c+1\n",
    "\n",
    "                    if c==0:\n",
    "                    #This Case works when description is in one row\n",
    "                        if \"Unnamed: 2\" in DF_10:\n",
    "                            DF_FINAL.columns=DF_FINAL.iloc[0]                                  \n",
    "                            FINAL=DF_FINAL.drop([c])\n",
    "                            FINAL['id']=k[1]\n",
    "                            try:\n",
    "                                FINAL['sheet_name'] = sh\n",
    "                            except:\n",
    "                                pass\n",
    "\n",
    "\n",
    "                            FINAL.dropna(how='all', axis=1, inplace=True)\n",
    "                            FINAL = FINAL.reset_index(drop=True)\n",
    "\n",
    "                            for i in FINAL.columns:\n",
    "                                x = str(i).lower().strip()\n",
    "                                FINAL=FINAL.rename(columns= {i:x})\n",
    "                            # FINAL=FINAL.rename(columns = {'drug mnemonic': \"CPT/HCPCS\"}) \n",
    "\n",
    "                            for i in FINAL.columns:\n",
    "                               x = str(i).lower().strip()\n",
    "                               FINAL=FINAL.rename(columns= {i:x}) \n",
    "\n",
    "                            for i in FINAL.columns.tolist():\n",
    "\n",
    "                                for k in CNames.itertuples(index=False):\n",
    "\n",
    "                                    for r in DF6.itertuples(index=False):\n",
    "\n",
    "                                        if str(k[1]) == str(r[2]):\n",
    "                                            try:\n",
    "\n",
    "                                                for i in FINAL.columns.tolist():\n",
    "\n",
    "                                                    if str(i) == str(r[0]):\n",
    "\n",
    "                                                        FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                                            except:\n",
    "                                                pass\n",
    "\n",
    "                            for i in FINAL.columns.tolist():\n",
    "                                for r in DF6.itertuples(index=False):\n",
    "                                    if str(r[2]) == \"nan\" :\n",
    "\n",
    "                                        if str(i) == str(r[0]):\n",
    "                                            FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                            combined_final.append(FINAL)\n",
    "\n",
    "                        else:\n",
    "                            #This Case works when description is not found\n",
    "                            FINAL=DF_FINAL\n",
    "                            FINAL['id']=k[1]\n",
    "                            try:\n",
    "                                FINAL['sheet_name'] = sh\n",
    "                            except:\n",
    "                                pass\n",
    "\n",
    "\n",
    "                            FINAL.dropna(how='all', axis=1, inplace=True)\n",
    "                            FINAL = FINAL.reset_index(drop=True)\n",
    "                            try:\n",
    "                                DF_FINAL[\" \".join(dummy.values[0])] = \" \".join(dummy.values[1])\n",
    "                            except:\n",
    "                                None\n",
    "                            for i in FINAL.columns:\n",
    "                                x = str(i).lower().strip()\n",
    "                                FINAL=FINAL.rename(columns= {i:x})\n",
    "\n",
    "\n",
    "\n",
    "                            for i in FINAL.columns.tolist():\n",
    "\n",
    "                                for k in CNames.itertuples(index=False):\n",
    "\n",
    "                                    for r in DF6.itertuples(index=False):\n",
    "\n",
    "                                        if str(k[1]) == str(r[2]):\n",
    "                                            try:\n",
    "\n",
    "                                                for i in FINAL.columns.tolist():\n",
    "\n",
    "                                                    if str(i) == str(r[0]):\n",
    "\n",
    "                                                        FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                                            except:\n",
    "                                                pass\n",
    "\n",
    "                            for i in FINAL.columns.tolist():\n",
    "                                for r in DF6.itertuples(index=False):\n",
    "                                    if str(r[2]) == \"nan\" :\n",
    "\n",
    "                                        if str(i) == str(r[0]):\n",
    "                                            FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                            combined_final.append(FINAL)\n",
    "\n",
    "\n",
    "\n",
    "                    elif c>=1:\n",
    "                        #This Case works when description is more than 1 row\n",
    "                        #Dropping 'c' rows\n",
    "                        DF_11=DF_FINAL.iloc[c:]\n",
    "                        #row values as column names\n",
    "                        DF_11.columns=DF_11.iloc[0]\n",
    "                        FINAL=DF_11.drop([c])\n",
    "                        FINAL['id']=k[1]\n",
    "                        FINAL['sheet_name'] = sh\n",
    "                        try:\n",
    "                            FINAL['Payer'] = \" \".join(dummy.values[1])\n",
    "                        except:\n",
    "                            None\n",
    "                        FINAL.dropna(how='all', axis=1, inplace=True)\n",
    "                        FINAL = FINAL.reset_index(drop=True)\n",
    "                        for i in FINAL.columns:\n",
    "                                x = str(i).lower().strip()\n",
    "                                FINAL=FINAL.rename(columns= {i:x})\n",
    "\n",
    "\n",
    "\n",
    "                        for i in FINAL.columns.tolist():\n",
    "\n",
    "                            for k in CNames.itertuples(index=False):\n",
    "\n",
    "                                for r in DF6.itertuples(index=False):\n",
    "\n",
    "                                    if str(k[1]) == str(r[2]):\n",
    "                                        try:\n",
    "\n",
    "                                            for i in FINAL.columns.tolist():\n",
    "\n",
    "                                                if str(i) == str(r[0]):\n",
    "\n",
    "                                                    FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                                        except:\n",
    "                                            pass\n",
    "\n",
    "                        for i in FINAL.columns.tolist():\n",
    "                            for r in DF6.itertuples(index=False):\n",
    "                                if str(r[2]) == \"nan\" :\n",
    "\n",
    "                                    if str(i) == str(r[0]):\n",
    "                                        FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                        combined_final.append(FINAL)\n",
    "                    else:\n",
    "                        None \n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass\n",
    "\n",
    "\n",
    "\n",
    "        FINAL = pd.concat(combined_final) \n",
    "        Search_List = list(DF8[\"Dropping columns\"])\n",
    "            #dropping columns\n",
    "        FINAL= FINAL.drop(columns=[col for col in FINAL if col in Search_List])   \n",
    "\n",
    "        column_list = ['inpatient-outpatient']\n",
    "        for col in column_list:\n",
    "            if col not in FINAL.columns:\n",
    "                FINAL[col] = ' '\n",
    "\n",
    "\n",
    "        try:\n",
    "            FINAL['payer_name']= FINAL['payer_name'].fillna('') ##filling empty spaces with na values\n",
    "            FINAL[\"payer_name\"]=FINAL[\"payer_name\"].astype(str)\n",
    "        except:\n",
    "            pass\n",
    "        df2=FINAL\n",
    "        df2 = df_column_uniquify(df2)\n",
    "        #Required format - variable list\n",
    "        Col_list = list(DF5[\"Columns\"])\n",
    "        df3=df2.melt(id_vars=[col for col in df2 if col in Col_list],var_name=\"name\",value_name='cost')\n",
    "\n",
    "\n",
    "        df4=df3\n",
    "        df4=df4[df4['cost'].notnull()]\n",
    "        try:\n",
    "            df4['name'] = df4[['payer_name', 'name']].apply(lambda x: ' '.join(x), axis=1)\n",
    "            df4 = df4.drop('payer_name',axis =1)\n",
    "            df4['name'] = df4['name'].str.strip()\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "        #df4['name'] = df4['name'].str.strip()\n",
    "        #Dropping_columns=['Not offered','Not Contracted','N/A','Not a covered service','Not Offered','Not contracted','Not a covered service','N/A']\n",
    "        #df4 = df4[~df4['Cost'].isin(Dropping_columns)]\n",
    "        df4\n",
    "        Combined_data.append(df4)\n",
    "    Combined_data = pd.concat(Combined_data)\n",
    "\n",
    "    Combined_data2\n",
    "\n",
    "    Sample_output= Combined_data\n",
    "\n",
    "    Sample_output = Sample_output.drop_duplicates()\n",
    "\n",
    "    Sample_output['inpatient-outpatient'] = np.where((Sample_output['inpatient-outpatient'] ==' ') & (Sample_output['name'].str.contains('IP ')) , 'Inpatient', Sample_output['inpatient-outpatient'])\n",
    "    Sample_output['inpatient-outpatient'] = np.where((Sample_output['inpatient-outpatient'] ==' ') & (Sample_output['name'].str.contains('OP')) , 'Outpatient', Sample_output['inpatient-outpatient'])\n",
    "    Sample_output['inpatient-outpatient'] = np.where((Sample_output['inpatient-outpatient'] ==' ') & (Sample_output['name'].str.contains('Inpatient ')) , 'Inpatient', Sample_output['inpatient-outpatient'])\n",
    "    Sample_output['inpatient-outpatient'] = np.where((Sample_output['inpatient-outpatient'] ==' ') & (Sample_output['name'].str.contains('Outpatient ')) , 'Outpatient', Sample_output['inpatient-outpatient'])\n",
    "    Sample_output['inpatient-outpatient'] = np.where((Sample_output['inpatient-outpatient'] ==' ') & (Sample_output['name'].str.contains('IP/OP')) , 'Inpatient/Outpatient', Sample_output['inpatient-outpatient'])\n",
    "    Sample_output['inpatient-outpatient'] = np.where((Sample_output['inpatient-outpatient'] ==' ') & (Sample_output['name'].str.contains('inpatient')) , 'inpatient', Sample_output['inpatient-outpatient'])\n",
    "    Sample_output['inpatient-outpatient'] = np.where((Sample_output['inpatient-outpatient'] ==' ') & (Sample_output['name'].str.contains('outpatient')) , 'outpatient', Sample_output['inpatient-outpatient'])\n",
    "    \n",
    "    output_path = r\"C:\\Users\\User\\Zigna AI Corp\\Zigna AI Corp - RightPx\\Hospital Application_2022-03-09\\Automation_task\\outputs\\Wideformat132_{}.csv\"\n",
    "    Sample_output.to_csv(output_path.format((k[1])), index=False)\n",
    "    return Sample_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8a290875",
   "metadata": {},
   "outputs": [],
   "source": [
    "################# wideFormat15 ######################\n",
    "def wideFormat15(CNames):\n",
    "    global df7\n",
    "    \n",
    "    Combined_data = []\n",
    "    combined_final = []\n",
    "    non_prep_data = []\n",
    "    #Getting the details as list from files\n",
    "    for k in CNames.itertuples(index=False):\n",
    "        f=k[0] \n",
    "        #Checking the file type- xlsx   \n",
    "        if k[2]== 'csv':\n",
    "            try:\n",
    "                DF_FINAL=pd.read_csv(f)\n",
    "            except:\n",
    "                DF_FINAL=pd.read_csv(f,encoding='latin1')\n",
    "\n",
    "\n",
    "        elif k[2]== 'xlsx':\n",
    "            sheet_to = pd.read_excel(f,sheet_name=None,dtype=str)\n",
    "\n",
    "            for sh in sheet_to.keys():\n",
    "\n",
    "                DF_FINAL = pd.read_excel(f,sheet_name=sh,dtype=str)\n",
    "                print(sh)\n",
    "\n",
    "\n",
    "                non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        for j in df7.itertuples(index=False):\n",
    "            if str(k[1]) == str(j[0]):\n",
    "                s = j[1]\n",
    "\n",
    "\n",
    "\n",
    "        for DF_FINAL in non_prep_data:\n",
    "\n",
    "\n",
    "            try:\n",
    "                if DF_FINAL.iloc[:, [s]].empty == False:\n",
    "\n",
    "\n",
    "                    DF_10 = DF_FINAL.iloc[:,[s]]\n",
    "                    m=0\n",
    "                    c=0\n",
    "\n",
    "                #Getting the count of  empty rows\n",
    "                    for index, row in DF_10.iterrows():\n",
    "                        if(pd.notnull(row[0])): \n",
    "                            m=m+1\n",
    "                            break\n",
    "                        else:\n",
    "                            c=c+1\n",
    "\n",
    "                    if c==0:\n",
    "                    #This Case works when description is in one row\n",
    "                        if \"Unnamed: 5\" in DF_10:\n",
    "                            DF_FINAL.columns=DF_FINAL.iloc[0]\n",
    "                            FINAL=DF_FINAL.drop([c])\n",
    "                            FINAL['id']=k[1]\n",
    "                            FINAL\n",
    "                        else:\n",
    "                            #This Case works when description is not found\n",
    "                            FINAL=DF_FINAL\n",
    "                            FINAL['id']=k[1]\n",
    "                            FINAL\n",
    "\n",
    "                    elif c>=1:\n",
    "                        #This Case works when description is more than 1 row\n",
    "                        #Dropping 'c' rows\n",
    "                        DF_11=DF_FINAL.iloc[c:]\n",
    "                        #row values as column names\n",
    "                        DF_11.columns=DF_11.iloc[0]\n",
    "                        #Dropping the row\n",
    "                        FINAL=DF_11.drop([c])\n",
    "                        FINAL['id']=k[1]\n",
    "                    else:\n",
    "                        None \n",
    "\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass\n",
    "\n",
    "        #Checking the file type- csv\n",
    "\n",
    "\n",
    "\n",
    "        for i in FINAL.columns:\n",
    "            x = str(i).lower().strip()\n",
    "            FINAL=FINAL.rename(columns= {i:x})\n",
    "\n",
    "        for i in FINAL.columns.tolist():\n",
    "\n",
    "            for k in CNames.itertuples(index=False):\n",
    "\n",
    "                for r in DF6.itertuples(index=False):\n",
    "\n",
    "                    if str(k[1]) == str(r[2]):\n",
    "                        try:\n",
    "\n",
    "                            for i in FINAL.columns.tolist():\n",
    "\n",
    "                                if str(i) == str(r[0]):\n",
    "\n",
    "                                    FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                        except:\n",
    "                                pass\n",
    "\n",
    "        for i in FINAL.columns.tolist():\n",
    "            for r in DF6.itertuples(index=False):\n",
    "                if str(r[2]) == \"nan\" :\n",
    "                    if str(i) == str(r[0]):\n",
    "                        FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "\n",
    "        # FINAL.drop([\"CPT/HCPCS\",\"DESCRIPTION\"], axis = 1, inplace = True)\n",
    "        #FINAL\n",
    "        Search_List = list(DF8[\"Dropping columns\"])\n",
    "            #dropping columns\n",
    "\n",
    "        FINAL= FINAL.drop(columns=[col for col in FINAL if col in Search_List])\n",
    "\n",
    "\n",
    "        # for r in DF6.itertuples(index=False):\n",
    "        #     FINAL.rename(columns={r[0]:r[1]}, inplace=True)\n",
    "        #Checking the  Inpatient/Outpatient column exists or not\n",
    "        column_list = ['inpatient-outpatient']\n",
    "        for col in column_list:\n",
    "            if col not in FINAL.columns:\n",
    "                FINAL[col] = ' '\n",
    "\n",
    "        FINAL[\"LineItem_cnt\"] = FINAL.groupby(\"cpt_hcpcs_drg_aprdrg_icdx10\")[\"cpt_hcpcs_drg_aprdrg_icdx10\"].transform('count')\n",
    "        FINAL[\"LineItem_cnt\"]=FINAL[\"LineItem_cnt\"]-1\n",
    "        #FINAL['inpatient-outpatient'] = (FINAL['inpatient-outpatient'].str.strip().replace('',np.nan).groupby(FINAL['CODE LOOKUP']).transform(lambda x: x.bfill().ffill()))\n",
    "\n",
    "        FINAL['inpatient-outpatient'] = (FINAL.groupby('cpt_hcpcs_drg_aprdrg_icdx10')['inpatient-outpatient'].transform(lambda x: x[x != ''].iat[0]))\n",
    "\n",
    "        FINAL['gross charge'] = pd.to_numeric(FINAL['gross charge'], errors='coerce')\n",
    "        FINAL['self_pay'] = pd.to_numeric(FINAL['self_pay'], errors='coerce')\n",
    "\n",
    "        #FINAL=FINAL.groupby(['CPT/HCPCS','LineItem_cnt','description','inpatient-outpatient','id']).aggregate(['sum']).reset_index()\n",
    "        FINAL=FINAL.groupby(['cpt_hcpcs_drg_aprdrg_icdx10','LineItem_cnt','description','inpatient-outpatient','hospital_Id']).aggregate(['sum']).reset_index()\n",
    "\n",
    "\n",
    "        FINAL.columns = FINAL.columns.get_level_values(0)\n",
    "        #FINAL\n",
    "\n",
    "\n",
    "\n",
    "        #Search_List = list(DF3[\"Keeping columns\"])\n",
    "        #Keeping columns\n",
    "        #df1= FINAL.drop(columns=[col for col in FINAL if col not in Search_List])\n",
    "        #Removing the empty rows from'cpt code'\n",
    "        #df2 = df1.dropna(axis=0, subset=['Cpt Code'])\n",
    "\n",
    "        #df2=FINAL[FINAL['cpt code'].notnull()] \n",
    "\n",
    "        df2=FINAL\n",
    "        df2 = df_column_uniquify(df2)\n",
    "        #Required format - variable list\n",
    "        Col_list = list(DF5[\"Columns\"])\n",
    "        df3=df2.melt(id_vars=[col for col in df2 if col in Col_list],var_name=\"name\",value_name='cost')\n",
    "        #df3=df1.melt(id_vars=['ID','Description','Cpt Code','Rev_Cd','Units'],var_name=\"Name\",value_name='Cost')\n",
    "\n",
    "        #df3['payer'] = None\n",
    "        #df3['insurance Type'] = None\n",
    "        #df3['Benefit Type']=None\n",
    "\n",
    "        #Name_List = list(DF1[\"Payers\"])\n",
    "\n",
    "        #Name_List1 = list(DF2[\"Insurance Type\"])\n",
    "\n",
    "        #Name_List2 = list(DF3[\"Benefit Type\"])\n",
    "\n",
    "        #Finding Payers from the list\n",
    "        #for i in Name_List:\n",
    "        #    df3['payer'][(df3['name'].str.contains(i,case=False,na=False))] = i\n",
    "        #Finding Insurancetype from the list    \n",
    "        #for j in Name_List1:\n",
    "        #    df3['insurance Type'][(df3['name'].str.contains(j,case=False,na=False))] = j\n",
    "\n",
    "        #Finding Benefit Type from the list  \n",
    "        #for k in Name_List2:\n",
    "        #    df3['Benefit Type'][(df3['name'].str.contains(k,case=False,na=False))] = k \n",
    "\n",
    "        df4=df3\n",
    "        df4=df4[df4['cost'].notnull()]\n",
    "        #Dropping_columns=['Not offered','Not Contracted','N/A','Not a covered service','Not Offered','Not contracted','Not a covered service','N/A']\n",
    "        #df4 = df4[~df4['Cost'].isin(Dropping_columns)]\n",
    "        df4\n",
    "        Combined_data.append(df4)\n",
    "    Combined_data = pd.concat(Combined_data)\n",
    "\n",
    "    Combined_data\n",
    "    output_path = r\"C:\\Users\\User\\Zigna AI Corp\\Zigna AI Corp - RightPx\\Hospital Application_2022-03-09\\Automation_task\\outputs\\Wideformat15_{}.csv\"\n",
    "    Combined_data.to_csv(output_path.format((k[1])), index=False)\n",
    "    return Combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fce52d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## wideFormat15_1 #####################\n",
    "def wideFormat15_1(CNames):\n",
    "    global df7\n",
    "    \n",
    "    Combined_data = []\n",
    "    combined_final = []\n",
    "    non_prep_data = []\n",
    "    #Getting the details as list from files\n",
    "    for k in CNames.itertuples(index=False):\n",
    "        f=k[0] \n",
    "        #Checking the file type- xlsx   \n",
    "        if k[2]== 'csv':\n",
    "            try:\n",
    "                DF_FINAL=pd.read_csv(f)\n",
    "            except:\n",
    "                DF_FINAL=pd.read_csv(f,encoding='latin1')\n",
    "\n",
    "\n",
    "        elif k[2]== 'xlsx':\n",
    "            sheet_to = pd.read_excel(f,sheet_name=None,dtype=str)\n",
    "\n",
    "            for sh in sheet_to.keys():\n",
    "\n",
    "                DF_FINAL = pd.read_excel(f,sheet_name=sh,dtype=str)\n",
    "                print(sh)\n",
    "\n",
    "\n",
    "                non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        for j in df7.itertuples(index=False):\n",
    "            if str(k[1]) == str(j[0]):\n",
    "                s = j[1]\n",
    "\n",
    "\n",
    "\n",
    "        for DF_FINAL in non_prep_data:\n",
    "\n",
    "\n",
    "            try:\n",
    "                if DF_FINAL.iloc[:, [s]].empty == False:\n",
    "\n",
    "\n",
    "                    DF_10 = DF_FINAL.iloc[:,[s]]\n",
    "                    m=0\n",
    "                    c=0\n",
    "\n",
    "                #Getting the count of  empty rows\n",
    "                    for index, row in DF_10.iterrows():\n",
    "                        if(pd.notnull(row[0])): \n",
    "                            m=m+1\n",
    "                            break\n",
    "                        else:\n",
    "                            c=c+1\n",
    "\n",
    "                    if c==0:\n",
    "                    #This Case works when description is in one row\n",
    "                        if \"Unnamed: 5\" in DF_10:\n",
    "                            DF_FINAL.columns=DF_FINAL.iloc[0]\n",
    "                            FINAL=DF_FINAL.drop([c])\n",
    "                            FINAL['id']=k[1]\n",
    "                            FINAL\n",
    "                        else:\n",
    "                            #This Case works when description is not found\n",
    "                            FINAL=DF_FINAL\n",
    "                            FINAL['id']=k[1]\n",
    "                            FINAL\n",
    "\n",
    "                    elif c>=1:\n",
    "                        #This Case works when description is more than 1 row\n",
    "                        #Dropping 'c' rows\n",
    "                        DF_11=DF_FINAL.iloc[c:]\n",
    "                        #row values as column names\n",
    "                        DF_11.columns=DF_11.iloc[0]\n",
    "                        #Dropping the row\n",
    "                        FINAL=DF_11.drop([c])\n",
    "                        FINAL['id']=k[1]\n",
    "                    else:\n",
    "                        None \n",
    "\n",
    "\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass\n",
    "\n",
    "\n",
    "           # \"CPT/HCPCS\"\n",
    "            # FINAL.drop([\"#\",\"Ancillary codes (CPT/Revenue)\",\"Category/Location\",], axis = 1, inplace = True)\n",
    "            # FINAL\n",
    "\n",
    "\n",
    "\n",
    "            # for r in DF6.itertuples(index=False):\n",
    "            #     FINAL.rename(columns={r[0]:r[1]}, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            for i in FINAL.columns:\n",
    "                x = str(i).lower().strip()\n",
    "                FINAL=FINAL.rename(columns= {i:x})\n",
    "\n",
    "            for i in FINAL.columns.tolist():\n",
    "\n",
    "                for k in CNames.itertuples(index=False):\n",
    "\n",
    "                    for r in DF6.itertuples(index=False):\n",
    "\n",
    "                        if str(k[1]) == str(r[2]):\n",
    "                            try:\n",
    "\n",
    "                                for i in FINAL.columns.tolist():\n",
    "\n",
    "                                    if str(i) == str(r[0]):\n",
    "\n",
    "                                        FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                            except:\n",
    "                                    pass\n",
    "\n",
    "            for i in FINAL.columns.tolist():\n",
    "                for r in DF6.itertuples(index=False):\n",
    "                    if str(r[2]) == \"nan\" :\n",
    "                        if str(i) == str(r[0]):\n",
    "                            FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "\n",
    "            Search_List = list(DF8[\"Dropping columns\"])\n",
    "                #dropping columns\n",
    "\n",
    "            FINAL= FINAL.drop(columns=[col for col in FINAL if col in Search_List])\n",
    "            #Checking the  Inpatient/Outpatient column exists or not\n",
    "\n",
    "\n",
    "            column_list = ['inpatient_outpatient']\n",
    "            for col in column_list:\n",
    "                if col not in FINAL.columns:\n",
    "                    FINAL[col] = ' '\n",
    "\n",
    "            FINAL['description'].fillna(method='ffill', inplace=True)\n",
    "            FINAL['cpt_drg'].fillna(method='ffill', inplace=True)\n",
    "            FINAL['cms_requried'].fillna(method='ffill', inplace=True)\n",
    "\n",
    "            all_columns = list(FINAL)\n",
    "            #FINAL[all_columns] = FINAL[all_columns].replace('\\$|,', '', regex=True)\n",
    "            cols=[i for i in FINAL.columns if i not in [\"cpt_drg\",\"description\",'inpatient_outpatient','hospital_Id','cms_requried']]\n",
    "\n",
    "            for col in cols:\n",
    "                FINAL[col] = pd.to_numeric(FINAL[col], errors='coerce')\n",
    "\n",
    "            FINAL[\"LineItem_cnt\"] = FINAL.groupby([\"description\",\"cpt_drg\"])[\"cpt_drg\"].transform('count')\n",
    "            FINAL[\"LineItem_cnt\"]=FINAL[\"LineItem_cnt\"]-1\n",
    "\n",
    "\n",
    "            #FINAL['Gross Charge'] = pd.to_numeric(FINAL['Gross Charge'], errors='coerce')\n",
    "\n",
    "            FINAL=FINAL.groupby(['cpt_drg','LineItem_cnt','description','inpatient_outpatient','hospital_Id','cms_requried']).aggregate(['sum']).reset_index()\n",
    "            FINAL.columns = FINAL.columns.get_level_values(0)\n",
    "            FINAL\n",
    "\n",
    "\n",
    "\n",
    "            #Search_List = list(DF3[\"Keeping columns\"])\n",
    "            #Keeping columns\n",
    "            #df1= FINAL.drop(columns=[col for col in FINAL if col not in Search_List])\n",
    "            #Removing the empty rows from'cpt code'\n",
    "            #df2 = df1.dropna(axis=0, subset=['Cpt Code'])\n",
    "\n",
    "            #df2=FINAL[FINAL['cpt code'].notnull()] \n",
    "\n",
    "            df2=FINAL\n",
    "            df2 = df_column_uniquify(df2)\n",
    "            #Required format - variable list\n",
    "            Col_list = list(DF5[\"Columns\"])\n",
    "            df3=df2.melt(id_vars=[col for col in df2 if col in Col_list],var_name=\"name\",value_name='cost')\n",
    "            #df3=df1.melt(id_vars=['ID','Description','Cpt Code','Rev_Cd','Units'],var_name=\"Name\",value_name='Cost')\n",
    "\n",
    "            #df3['payer'] = None\n",
    "            #df3['insurance Type'] = None\n",
    "            #df3['Benefit Type']=None\n",
    "\n",
    "            #Name_List = list(DF1[\"Payers\"])\n",
    "\n",
    "            #Name_List1 = list(DF2[\"Insurance Type\"])\n",
    "\n",
    "            #Name_List2 = list(DF3[\"Benefit Type\"])\n",
    "\n",
    "            #Finding Payers from the list\n",
    "            #for i in Name_List:\n",
    "            #    df3['payer'][(df3['name'].str.contains(i,case=False,na=False))] = i\n",
    "            #Finding Insurancetype from the list    \n",
    "            #for j in Name_List1:\n",
    "            #    df3['insurance Type'][(df3['name'].str.contains(j,case=False,na=False))] = j\n",
    "\n",
    "            #Finding Benefit Type from the list  \n",
    "            #for k in Name_List2:\n",
    "            #    df3['Benefit Type'][(df3['name'].str.contains(k,case=False,na=False))] = k \n",
    "\n",
    "            df4=df3\n",
    "            df4=df4[df4['cost'].notnull()]\n",
    "            #Dropping_columns=['Not offered','Not Contracted','N/A','Not a covered service','Not Offered','Not contracted','Not a covered service','N/A']\n",
    "            #df4 = df4[~df4['Cost'].isin(Dropping_columns)]\n",
    "            df4\n",
    "            Combined_data.append(df4)\n",
    "        Combined_data = pd.concat(Combined_data)\n",
    "\n",
    "        Combined_data\n",
    "        output_path = r\"C:\\Users\\User\\Zigna AI Corp\\Zigna AI Corp - RightPx\\Hospital Application_2022-03-09\\Automation_task\\outputs\\Wideformat15_1_{}.csv\"\n",
    "        Combined_data.to_csv(output_path.format((k[1])), index=False)\n",
    "        return Combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9c134399",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################## wideFormat15_2 ############################\n",
    "def wideFormat15_2(CNames):      \n",
    "    global df7\n",
    "    Combined_data = []\n",
    "    combined_final = []\n",
    "    non_prep_data = []\n",
    "    #Getting the details as list from files\n",
    "    for k in CNames.itertuples(index=False):\n",
    "        f=k[0] \n",
    "        #Checking the file type- xlsx   \n",
    "        if k[2]== 'csv':\n",
    "            try:\n",
    "                DF_FINAL=pd.read_csv(f)\n",
    "            except:\n",
    "                DF_FINAL=pd.read_csv(f,encoding='latin1')\n",
    "                \n",
    "            non_prep_data.append(DF_FINAL)\n",
    "        \n",
    "        elif k[2]== 'xlsx':\n",
    "            sheet_to = pd.read_excel(f,sheet_name=None,dtype=str,header=None)\n",
    "         \n",
    "            for sh in sheet_to.keys():\n",
    "               \n",
    "                DF_FINAL = pd.read_excel(f,sheet_name=sh,dtype=str)\n",
    "                print(sh)\n",
    "                non_prep_data.append(DF_FINAL)\n",
    "                \n",
    "        for j in df7.itertuples(index=False):\n",
    "            if str(k[1]) == str(j[0]):\n",
    "                s = j[1]\n",
    "                \n",
    "        for DF_FINAL in non_prep_data:\n",
    "            try:\n",
    "                if DF_FINAL.iloc[:, [s]].empty == False:\n",
    "                    \n",
    "                    DF_FINAL=pd.read_excel(f,sheet_name=sh,header=None,skiprows=3)\n",
    "                    DF_FINAL[:2] = DF_FINAL[:2].fillna(method='ffill', axis=1)\n",
    "                    DF_FINAL[:2] = DF_FINAL[:2].fillna(' ')\n",
    "                    DF_FINAL.columns = (DF_FINAL.iloc[0] + ' ' + DF_FINAL.iloc[1]+' '+DF_FINAL.iloc[2])\n",
    "                    DF_FINAL = DF_FINAL.iloc[3:]\n",
    "                    FINAL = DF_FINAL.reset_index(drop=True)\n",
    "                    FINAL['id']=k[1]\n",
    "    \n",
    "                    DF_10=DF_FINAL.iloc[:, [s]]    \n",
    "                    m=0\n",
    "                    c=0\n",
    "                    \n",
    "                    #Getting the count of  empty rows\n",
    "                    for index, row in DF_10.iterrows():\n",
    "                        if(pd.notnull(row[0])): \n",
    "                            m=m+1\n",
    "                            break\n",
    "                        else:\n",
    "                            c=c+1\n",
    "                            \n",
    "                    if c==0:\n",
    "                    #This Case works when description is in one row\n",
    "                        if \"Unnamed: 5\" in DF_10:\n",
    "                            DF_FINAL.columns=DF_FINAL.iloc[0]\n",
    "                            FINAL=DF_FINAL.drop([c])\n",
    "                            FINAL['id']=k[1]\n",
    "                            FINAL\n",
    "                        else:\n",
    "                            #This Case works when description is not found\n",
    "                            FINAL=DF_FINAL\n",
    "                            FINAL['id']=k[1]\n",
    "                            FINAL\n",
    "                            \n",
    "                    elif c>=1:\n",
    "                        #This Case works when description is more than 1 row\n",
    "                        #Dropping 'c' rows\n",
    "                        DF_11=DF_FINAL.iloc[c:]\n",
    "                        #row values as column names\n",
    "                        DF_11.columns=DF_11.iloc[0]\n",
    "                        #Dropping the row\n",
    "                        FINAL=DF_11.drop([c])\n",
    "                        FINAL['id']=k[1]\n",
    "                    else:\n",
    "                        None \n",
    "            \n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass\n",
    "    \n",
    "        for i in FINAL.columns:\n",
    "            x = str(i).lower().strip()\n",
    "            FINAL=FINAL.rename(columns= {i:x})    \n",
    "        \n",
    "       \n",
    "        \n",
    "        for i in FINAL.columns.tolist():\n",
    "        \n",
    "            for k in CNames.itertuples(index=False):\n",
    "        \n",
    "                for r in DF6.itertuples(index=False):\n",
    "        \n",
    "                    if str(k[1]) == str(r[2]):\n",
    "                        try:\n",
    "        \n",
    "                            for i in FINAL.columns.tolist():\n",
    "        \n",
    "                                if str(i) == str(r[0]):\n",
    "        \n",
    "                                    FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                        except:\n",
    "                                pass\n",
    "        \n",
    "        for i in FINAL.columns.tolist():\n",
    "            for r in DF6.itertuples(index=False):\n",
    "                if str(r[2]) == \"nan\" :\n",
    "                    if str(i) == str(r[0]):\n",
    "                        FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                       \n",
    "        column_list = ['inpatient-outpatient']\n",
    "        for col in column_list:\n",
    "            if col not in FINAL.columns:\n",
    "                FINAL[col] = ' '\n",
    "             \n",
    "    \n",
    "    \n",
    "        FINAL['CPT/HCPCS/DRG'].fillna(method='ffill', inplace=True)\n",
    "        FINAL['Shoppable Service Category'].fillna(method='ffill', inplace=True)\n",
    "    \n",
    "        if CNames['id'].isin(['2902']).any():\n",
    "            try:\n",
    "                FINAL = FINAL.replace(('May be billed separately'), ' ', regex=True)\n",
    "                FINAL['inpatient-outpatient'] = FINAL['inpatient-outpatient'].replace(' ', np.nan, regex=True)\n",
    "                FINAL['inpatient-outpatient'].fillna(method='ffill', inplace=True)\n",
    "            except:\n",
    "                   None\n",
    "        FINAL['inpatient-outpatient'].fillna(method='ffill', inplace=True)\n",
    "    \n",
    "        all_columns = list(FINAL)\n",
    "        #FINAL[all_columns] = FINAL[all_columns].replace('\\$|,', '', regex=True)\n",
    "        cols=[i for i in FINAL.columns if i not in [\"CPT/HCPCS/DRG\",\"Primary Service and Ancillary Service\",'Hospital_Id','Shoppable Service Category', 'inpatient-outpatient']]\n",
    "        \n",
    "        for col in cols:\n",
    "            FINAL[col] = pd.to_numeric(FINAL[col], errors='coerce')\n",
    "        \n",
    "        FINAL = FINAL.drop_duplicates(keep='first', inplace=False)\n",
    "    \n",
    "        \n",
    "        FINAL[\"LineItem_cnt\"] = FINAL.groupby([\"CPT/HCPCS/DRG\",\"inpatient-outpatient\"])[\"CPT/HCPCS/DRG\"].transform('count')\n",
    "        FINAL[\"LineItem_cnt\"]=FINAL[\"LineItem_cnt\"]-1\n",
    "        \n",
    "        if CNames['id'].isin(['2902']).any():\n",
    "            try:\n",
    "                FINAL.drop(['Primary Service and Ancillary Service'],axis=1,inplace=True)\n",
    "            except:\n",
    "                None\n",
    "                    \n",
    "    \n",
    "        #FINAL['Gross Charge'] = pd.to_numeric(FINAL['Gross Charge'], errors='coerce')\n",
    "    \n",
    "        FINAL=FINAL.groupby(['CPT/HCPCS/DRG','LineItem_cnt','Shoppable Service Category','inpatient-outpatient','Hospital_Id']).aggregate(['sum']).reset_index()\n",
    "        FINAL.columns = FINAL.columns.get_level_values(0)\n",
    "        FINAL\n",
    "        \n",
    "    \n",
    "        df2=FINAL\n",
    "        df2 = df_column_uniquify(df2)\n",
    "        #Required format - variable list\n",
    "        Col_list = list(DF5[\"Columns\"])\n",
    "        df3=df2.melt(id_vars=[col for col in df2 if col in Col_list],var_name=\"name\",value_name='cost')\n",
    "        \n",
    "            \n",
    "        df4=df3\n",
    "        df4=df4[df4['cost'].notnull()]\n",
    "        #Dropping_columns=['Not offered','Not Contracted','N/A','Not a covered service','Not Offered','Not contracted','Not a covered service','N/A']\n",
    "        #df4 = df4[~df4['Cost'].isin(Dropping_columns)]\n",
    "        df4\n",
    "        Combined_data.append(df4)\n",
    "    Combined_data = pd.concat(Combined_data)\n",
    "    \n",
    "    \n",
    "    output_path = r\"C:\\Users\\User\\Zigna AI Corp\\Zigna AI Corp - RightPx\\Hospital Application_2022-03-09\\Automation_task\\outputs\\Wideformat15_2{}.csv\"\n",
    "    Combined_data.to_csv(output_path.format((k[1])), index=False)\n",
    "    return Combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f3d7a8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################# wideFormat21 ######################\n",
    "def wideFormat21(CNames):\n",
    "    global df7\n",
    "    \n",
    "    Combined_data = []\n",
    "    combined_final = []\n",
    "    non_prep_data = []\n",
    "    #Getting the details as list from files\n",
    "    for k in CNames.itertuples(index=False):\n",
    "        f=k[0] \n",
    "        #Checking the file type- xlsx   \n",
    "        if k[2]== 'csv':\n",
    "            try:\n",
    "                DF_FINAL=pd.read_csv(f)\n",
    "            except:\n",
    "                DF_FINAL=pd.read_csv(f,encoding='latin1')\n",
    "\n",
    "\n",
    "        elif k[2]== 'xlsx':\n",
    "            sheet_to = pd.read_excel(f,sheet_name=None,dtype=str)\n",
    "\n",
    "            for sh in sheet_to.keys():\n",
    "\n",
    "                DF_FINAL = pd.read_excel(f,sheet_name=sh,dtype=str)\n",
    "                print(sh)\n",
    "\n",
    "\n",
    "                non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        for j in df7.itertuples(index=False):\n",
    "            if str(k[1]) == str(j[0]):\n",
    "                s = j[1]\n",
    "\n",
    "        for DF_FINAL in non_prep_data:\n",
    "\n",
    "\n",
    "            try:\n",
    "                if DF_FINAL.iloc[:, [s]].empty == False:\n",
    "\n",
    "\n",
    "                    DF_10 = DF_FINAL.iloc[:,[s]]\n",
    "                    m=0\n",
    "                    c=0\n",
    "\n",
    "            #Getting the count of  empty rows\n",
    "                for index, row in DF_10.iterrows():\n",
    "                    if(pd.notnull(row[0])): \n",
    "                        m=m+1\n",
    "                        break\n",
    "                    else:\n",
    "                        c=c+1\n",
    "                if c==0:\n",
    "\n",
    "                      #This Case works when description is in one row\n",
    "                    if \"Unnamed: 5\" in DF_10:\n",
    "                        DF_FINAL.columns=DF_FINAL.iloc[0]\n",
    "                        FINAL=DF_FINAL.drop([c])\n",
    "                        FINAL['id']=k[1]\n",
    "                        FINAL\n",
    "                    else:\n",
    "                        #This Case works when description is not found\n",
    "                        FINAL=DF_FINAL\n",
    "                        FINAL['id']=k[1]\n",
    "                        FINAL\n",
    "\n",
    "                elif c>=1:\n",
    "                    #This Case works when description is more than 1 row\n",
    "                    #Dropping 'c' rows\n",
    "                    DF_11=DF_FINAL.iloc[c:]\n",
    "                    #row values as column names\n",
    "                    DF_11.columns=DF_11.iloc[0]\n",
    "                    #Dropping the row\n",
    "                    FINAL=DF_11.drop([c])\n",
    "                    FINAL['id']=k[1]\n",
    "                else:\n",
    "                    None \n",
    "\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        for i in FINAL.columns:\n",
    "            x = str(i).lower().strip()\n",
    "            FINAL=FINAL.rename(columns= {i:x})\n",
    "\n",
    "        for i in FINAL.columns.tolist():\n",
    "\n",
    "            for k in CNames.itertuples(index=False):\n",
    "\n",
    "                for r in DF6.itertuples(index=False):\n",
    "\n",
    "                    if str(k[1]) == str(r[2]):\n",
    "                        try:\n",
    "\n",
    "                            for i in FINAL.columns.tolist():\n",
    "\n",
    "                                if str(i) == str(r[0]):\n",
    "\n",
    "                                    FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                        except:\n",
    "                                pass\n",
    "\n",
    "        for i in FINAL.columns.tolist():\n",
    "            for r in DF6.itertuples(index=False):\n",
    "                if str(r[2]) == \"nan\" :\n",
    "                    if str(i) == str(r[0]):\n",
    "                        FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "        FINAL['cpt'] = np.where((FINAL['description_1'].notnull()) & (FINAL['description'].notnull()) &(FINAL['cpt_hcpcs'].notnull()), FINAL['cpt_hcpcs'], \"\")\n",
    "        FINAL= FINAL.replace(r'^\\s*$', np.NaN, regex=True)\n",
    "        FINAL['description_1'].fillna(method='ffill', inplace=True)\n",
    "        FINAL['cpt'].fillna(method='ffill', inplace=True)\n",
    "        FINAL['LineItem_cnt'] = None \n",
    "        FINAL['LineItem_cnt'] = FINAL.groupby(['description_1','cpt'])[\"cpt\"].transform(\"count\")\n",
    "        FINAL[\"LineItem_cnt\"]=FINAL[\"LineItem_cnt\"]-1\n",
    "\n",
    "        all_columns = list(FINAL)\n",
    "        FINAL[all_columns] = FINAL[all_columns].replace(r'^\\s*$', '', regex=True)\n",
    "\n",
    "\n",
    "        cols=[i for i in FINAL.columns if i not in [\"description_1\",'cpt','inpatient-outpatient','hospital_Id']]\n",
    "        for col in cols:\n",
    "            FINAL[col] = pd.to_numeric(FINAL[col], errors='coerce')\n",
    "        # FINAL.drop([\"Description\",'Code'], axis = 1, inplace = True)\n",
    "        FINAL=FINAL.groupby(['description_1','LineItem_cnt','cpt','hospital_Id']).aggregate(['sum']).reset_index()\n",
    "        FINAL.columns = FINAL.columns.get_level_values(0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        Search_List = list(DF8[\"Dropping columns\"])\n",
    "            #dropping columns\n",
    "        FINAL= FINAL.drop(columns=[col for col in FINAL if col in Search_List])\n",
    "\n",
    "\n",
    "        #Checking the  Inpatient/Outpatient column exists or not\n",
    "        column_list = ['inpatient-outpatient']\n",
    "        for col in column_list:\n",
    "            if col not in FINAL.columns:\n",
    "                FINAL[col] = ' '\n",
    "\n",
    "\n",
    "\n",
    "        df2=FINAL\n",
    "        df2 = df_column_uniquify(df2)\n",
    "        #Required format - variable list\n",
    "        Col_list = list(DF5[\"Columns\"])\n",
    "        df3=df2.melt(id_vars=[col for col in df2 if col in Col_list],var_name=\"name\",value_name='cost')\n",
    "        #df3=df1.melt(id_vars=['ID','Description','Cpt Code','Rev_Cd','Units'],var_name=\"Name\",value_name='Cost')\n",
    "\n",
    "\n",
    "        df4=df3\n",
    "        df4=df4[df4['cost'].notnull()]\n",
    "        #Dropping_columns=['Not offered','Not Contracted','N/A','Not a covered service','Not Offered','Not contracted','Not a covered service','N/A']\n",
    "        #df4 = df4[~df4['Cost'].isin(Dropping_columns)]\n",
    "        df4\n",
    "        Combined_data.append(df4)\n",
    "    Combined_data = pd.concat(Combined_data)\n",
    "\n",
    "    Combined_data\n",
    "    # output_path = \"D:\" + os.path.sep + \"Zigna AI Corp\" + os.path.sep + \"Zigna AI Corp - Hospital Application_2022-03-09\" + os.path.sep + \"Automation_task\"  + os.path.sep + \"outputs\" + os.path.sep + \"Wideformat21_{}.csv\"\n",
    "    # Combined_data.to_csv(output_path.format((k[1])), index=False)\n",
    "    # return Combined_data\n",
    "    output_path = r\"C:\\Users\\User\\Zigna AI Corp\\Zigna AI Corp - RightPx\\Hospital Application_2022-03-09\\Automation_task\\outputs\\Wideformat21_{}.csv\"\n",
    "    Combined_data.to_csv(output_path.format((k[1])), index=False)\n",
    "    return Combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "508ebb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### wideFormat23 ###########################\n",
    "def wideFormat23(CNames):\n",
    "    global df7      \n",
    "    Combined_data = []\n",
    "    combined_final = []\n",
    "    non_prep_data = []\n",
    "    #Getting the details as list from files\n",
    "    for k in CNames.itertuples(index=False):\n",
    "        f=k[0] \n",
    "        #Checking the file type- xlsx   \n",
    "        if k[2]== 'csv':\n",
    "            try:\n",
    "                DF_FINAL=pd.read_csv(f)\n",
    "            except:\n",
    "                DF_FINAL=pd.read_csv(f,encoding='latin1')\n",
    "                \n",
    "            non_prep_data.append(DF_FINAL)\n",
    "        \n",
    "        elif k[2]== 'xlsx':\n",
    "            sheet_to = pd.read_excel(f,sheet_name=None,dtype=str,header=None)\n",
    "         \n",
    "            for sh in sheet_to.keys():\n",
    "               \n",
    "                DF_FINAL = pd.read_excel(f,sheet_name=sh,dtype=str)\n",
    "                print(sh)\n",
    "                non_prep_data.append(DF_FINAL)\n",
    "                \n",
    "        for j in df7.itertuples(index=False):\n",
    "            if str(k[1]) == str(j[0]):\n",
    "                s = j[1]\n",
    "                \n",
    "        for DF_FINAL in non_prep_data:\n",
    "            try:\n",
    "                if DF_FINAL.iloc[:, [s]].empty == False:\n",
    "                    DF_FINAL1= pd.concat(pd.read_excel(f,sheet_name=None))\n",
    "                    DF_FINAL1.reset_index(level=0, inplace=True)\n",
    "                    DF_FINAL2 = DF_FINAL1.loc[:, ~DF_FINAL1.columns.str.contains('^Unnamed')]\n",
    "                    DF_FINAL=DF_FINAL2[~(DF_FINAL2[\"level_0\"]=='Discounted Cash Price')]\n",
    "                    DF_FINAL.drop([\"level_0\"], axis = 1, inplace = True)\n",
    "                    DF_FINAL\n",
    "                    \n",
    "                    DF_10=DF_FINAL.iloc[:, [s]]    \n",
    "                    m=0\n",
    "                    c=0\n",
    "                \n",
    "                    #Getting the count of  empty rows\n",
    "                    for index, row in DF_10.iterrows():\n",
    "                        if(pd.notnull(row[0])): \n",
    "                            m=m+1\n",
    "                            break\n",
    "                        else:\n",
    "                            c=c+1\n",
    "                \n",
    "                    if c==0:\n",
    "                    #This Case works when description is in one row\n",
    "                        if \"Unnamed: 5\" in DF_10:\n",
    "                            DF_FINAL.columns=DF_FINAL.iloc[0]\n",
    "                            FINAL=DF_FINAL.drop([c])\n",
    "                            FINAL['id']=k[1]\n",
    "                            FINAL\n",
    "                        else:\n",
    "                            #This Case works when description is not found\n",
    "                            FINAL=DF_FINAL\n",
    "                            FINAL['id']=k[1]\n",
    "                            FINAL\n",
    "                \n",
    "                    elif c>=1:\n",
    "                        #This Case works when description is more than 1 row\n",
    "                        #Dropping 'c' rows\n",
    "                        DF_11=DF_FINAL.iloc[c:]\n",
    "                        #row values as column names\n",
    "                        DF_11.columns=DF_11.iloc[0]\n",
    "                        #Dropping the row\n",
    "                        FINAL=DF_11.drop([c])\n",
    "                        FINAL['id']=k[1]\n",
    "                    else:\n",
    "                        None \n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass\n",
    "        for i in FINAL.columns:\n",
    "                x = str(i).lower().strip()\n",
    "                FINAL=FINAL.rename(columns= {i:x})\n",
    "    \n",
    "        \n",
    "    \n",
    "        FINAL.loc[:, FINAL.columns.notnull()]\n",
    "        for i in FINAL.columns.tolist():\n",
    "            for r in DF6.itertuples(index=False):\n",
    "                if str(i) == str(r[0]):\n",
    "                    FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "        \n",
    "        Search_List = list(DF8[\"Dropping columns\"])\n",
    "            #dropping columns\n",
    "        FINAL= FINAL.drop(columns=[col for col in FINAL if col in Search_List])\n",
    "        #Checking the  Inpatient/Outpatient column exists or not\n",
    "        column_list = ['inpatient-outpatient']\n",
    "        for col in column_list:\n",
    "            if col not in FINAL.columns:\n",
    "                FINAL[col] = ' '\n",
    "    \n",
    "       \n",
    "    \n",
    "        df2=FINAL\n",
    "        df2 = df_column_uniquify(df2)\n",
    "        #Required format - variable list\n",
    "        Col_list = list(DF5[\"Columns\"])\n",
    "        df3=df2.melt(id_vars=[col for col in df2 if col in Col_list],var_name=\"name\",value_name='cost')\n",
    "        #df3=df1.melt(id_vars=['ID','Description','Cpt Code','Rev_Cd','Units'],var_name=\"Name\",value_name='Cost')\n",
    "    \n",
    "       \n",
    "        df4=df3\n",
    "        df4=df4[df4['cost'].notnull()]\n",
    "        #Dropping_columns=['Not offered','Not Contracted','N/A','Not a covered service','Not Offered','Not contracted','Not a covered service','N/A']\n",
    "        #df4 = df4[~df4['Cost'].isin(Dropping_columns)]\n",
    "        df4\n",
    "        Combined_data.append(df4)\n",
    "    Combined_data = pd.concat(Combined_data)\n",
    "    \n",
    "    Combined_data\n",
    "    #Combined_data[\"id\"]=Combined_data.id.astype('int64')\n",
    "    Combined_data.dtypes\n",
    "    \n",
    "    #Joining both hospital data with shoppable data by ID\n",
    "    #Sample_output=pd.merge(left=DHC_Hosp_data1, right=Combined_data,how='inner',left_on=['Hospital_Id'],right_on=['id'])\n",
    "    Combined_data['inpatient-outpatient'] = np.where((Combined_data['inpatient-outpatient'] ==' ') & (Combined_data['name'].str.contains('outpatient')) , 'Outpatient', Combined_data['inpatient-outpatient'])\n",
    "    Combined_data['inpatient-outpatient'] = np.where((Combined_data['inpatient-outpatient'] ==' ') & (Combined_data['name'].str.contains('inpatient')) , 'Inpatient', Combined_data['inpatient-outpatient'])\n",
    "    \n",
    "    #Dropping the columns\n",
    "    output_path = r\"C:\\Users\\User\\Zigna AI Corp\\Zigna AI Corp - RightPx\\Hospital Application_2022-03-09\\Automation_task\\outputs\\Wideformat23_{}.csv\"\n",
    "    Combined_data.to_csv(output_path.format((k[1])), index=False)\n",
    "    return Combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "15e97609",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################## wideFormat35 #######################\n",
    "def wideFormat35(CNames):\n",
    "    global df7\n",
    "    \n",
    "    Combined_data = []\n",
    "    combined_final = []\n",
    "    non_prep_data = []\n",
    "    #Getting the details as list from files\n",
    "    for k in CNames.itertuples(index=False):\n",
    "        f=k[0] \n",
    "        #Checking the file type- xlsx   \n",
    "        if k[2]== 'csv':\n",
    "            try:\n",
    "                DF_FINAL=pd.read_csv(f)\n",
    "            except:\n",
    "                DF_FINAL=pd.read_csv(f,encoding='latin1')\n",
    "\n",
    "\n",
    "        elif k[2]== 'xlsx':\n",
    "            sheet_to = pd.read_excel(f,sheet_name=None,dtype=str)\n",
    "\n",
    "            for sh in sheet_to.keys():\n",
    "\n",
    "                DF_FINAL = pd.read_excel(f,sheet_name=sh,dtype=str)\n",
    "                print(sh)\n",
    "\n",
    "\n",
    "                non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        for j in df7.itertuples(index=False):\n",
    "            if str(k[1]) == str(j[0]):\n",
    "                s = j[1]\n",
    "\n",
    "        for DF_FINAL in non_prep_data:\n",
    "\n",
    "\n",
    "            try:\n",
    "                if DF_FINAL.iloc[:, [s]].empty == False:\n",
    "\n",
    "\n",
    "                    DF_10 = DF_FINAL.iloc[:,[s]]\n",
    "                    m=0\n",
    "                    c=0\n",
    "\n",
    "            #Getting the count of  empty rows\n",
    "                for index, row in DF_10.iterrows():\n",
    "                    if(pd.notnull(row[0])): \n",
    "                        m=m+1\n",
    "                        break\n",
    "                    else:\n",
    "                        c=c+1\n",
    "\n",
    "                if c==0:\n",
    "                #This Case works when description is in one row\n",
    "                    if \"Unnamed: 2\" in DF_10:\n",
    "                        DF_FINAL.columns=DF_FINAL.iloc[0]\n",
    "                        FINAL=DF_FINAL.drop([c])\n",
    "                        FINAL['id']=k[1]\n",
    "                        FINAL\n",
    "                    else:\n",
    "                        #This Case works when description is not found\n",
    "                        FINAL=DF_FINAL\n",
    "                        FINAL['id']=k[1]\n",
    "                        FINAL\n",
    "\n",
    "                elif c>=1:\n",
    "                   #This Case works when description is more than 1 row\n",
    "                    #Dropping 'c' rows\n",
    "\n",
    "                    DF_11=DF_FINAL.iloc[c-1:]\n",
    "                    DF_11[:c-1]=DF_11[:c-1].fillna(method='ffill', axis=1)\n",
    "                    DF_11[:c-1] = DF_11[:c-1].fillna(' ')\n",
    "                    DF_FINAL.columns = (DF_FINAL.iloc[c-1] + ' ' + DF_FINAL.iloc[c])\n",
    "                    DF_FINAL = DF_FINAL.iloc[c+2:]\n",
    "                    #row values as column names\n",
    "                    #Dropping the row\n",
    "                    FINAL = DF_FINAL.reset_index(drop=True)\n",
    "                    FINAL['id']=k[1]\n",
    "                else:\n",
    "                    None \n",
    "\n",
    "        #Checking the file type- csv\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass\n",
    "        for i in FINAL.columns:\n",
    "\n",
    "            x = str(i).lower().strip()\n",
    "            FINAL=FINAL.rename(columns= {i:x})\n",
    "\n",
    "        for i in FINAL.columns.tolist():\n",
    "\n",
    "            for k in CNames.itertuples(index=False):\n",
    "\n",
    "                for r in DF6.itertuples(index=False):\n",
    "\n",
    "                    if str(k[1]) == str(r[2]):\n",
    "                        try:\n",
    "\n",
    "                            for i in FINAL.columns.tolist():\n",
    "\n",
    "                                if str(i) == str(r[0]):\n",
    "\n",
    "                                    FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                        except:\n",
    "                                pass\n",
    "\n",
    "        for i in FINAL.columns.tolist():\n",
    "            for r in DF6.itertuples(index=False):\n",
    "                if str(r[2]) == \"nan\" :\n",
    "                    if str(i) == str(r[0]):\n",
    "                        FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "\n",
    "        # if CNames['id'].isin(['3502']).any():\n",
    "        #         try:\n",
    "        #             FINAL.drop(['  COUNT','(see NOTES tab) CMS 70'],axis=1,inplace=True)\n",
    "        #         except:\n",
    "        #             None\n",
    "\n",
    "           #FINAL\n",
    "        Search_List = list(DF8[\"Dropping columns\"])\n",
    "            #dropping columns\n",
    "\n",
    "        FINAL= FINAL.drop(columns=[col for col in FINAL if col in Search_List])\n",
    "\n",
    "\n",
    "\n",
    "        #Checking the  Inpatient/Outpatient column exists or not\n",
    "        column_list = ['inpatient-outpatient']\n",
    "        for col in column_list:\n",
    "            if col not in FINAL.columns:\n",
    "                FINAL[col] = ' '        \n",
    "\n",
    "        #Search_List = list(DF3[\"Keeping columns\"])\n",
    "        #Keeping columns\n",
    "        #df1= FINAL.drop(columns=[col for col in FINAL if col not in Search_List])\n",
    "        #Removing the empty rows from'cpt code'\n",
    "        #df2 = df1.dropna(axis=0, subset=['Cpt Code'])\n",
    "\n",
    "        #df2=FINAL[FINAL['cpt code'].notnull()] \n",
    "\n",
    "        df2=FINAL\n",
    "        df2 = df_column_uniquify(df2)\n",
    "        #Required format - variable list\n",
    "        Col_list = list(DF5[\"Columns\"])\n",
    "        df3=df2.melt(id_vars=[col for col in df2 if col in Col_list],var_name=\"name\",value_name='cost')\n",
    "        #df3=df1.melt(id_vars=['ID','Description','Cpt Code','Rev_Cd','Units'],var_name=\"Name\",value_name='Cost')\n",
    "\n",
    "        #df3['payer'] = None\n",
    "        #df3['insurance Type'] = None\n",
    "        #df3['Benefit Type']=None\n",
    "\n",
    "        #Name_List = list(DF1[\"Payers\"])\n",
    "\n",
    "        #Name_List1 = list(DF2[\"Insurance Type\"])\n",
    "\n",
    "        #Name_List2 = list(DF3[\"Benefit Type\"])\n",
    "\n",
    "        #Finding Payers from the list\n",
    "        #for i in Name_List:\n",
    "        #    df3['payer'][(df3['name'].str.contains(i,case=False,na=False))] = i\n",
    "        #Finding Insurancetype from the list    \n",
    "        #for j in Name_List1:\n",
    "        #    df3['insurance Type'][(df3['name'].str.contains(j,case=False,na=False))] = j\n",
    "\n",
    "        #Finding Benefit Type from the list  \n",
    "        #for k in Name_List2:\n",
    "        #    df3['Benefit Type'][(df3['name'].str.contains(k,case=False,na=False))] = k \n",
    "\n",
    "        df4=df3\n",
    "        df4=df4[df4['cost'].notnull()]\n",
    "        #Dropping_columns=['Not offered','Not Contracted','N/A','Not a covered service','Not Offered','Not contracted','Not a covered service','N/A']\n",
    "        #df4 = df4[~df4['Cost'].isin(Dropping_columns)]\n",
    "        df4\n",
    "        Combined_data.append(df4)\n",
    "    Combined_data = pd.concat(Combined_data)\n",
    "    Combined_data = Combined_data.drop_duplicates()\n",
    "\n",
    "    Combined_data\n",
    "    #Combined_data[\"id\"]=Combined_data.id.astype('int64')\n",
    "    #Combined_data.dtypes\n",
    "\n",
    "    #Joining both hospital data with shoppable data by ID\n",
    "    #Sample_output=pd.merge(left=DHC_Hosp_data1, right=Combined_data,how='inner',left_on=['Hospital_Id'],right_on=['id'])\n",
    "    Sample_output = Combined_data\n",
    "    output_path = r\"C:\\Users\\User\\Zigna AI Corp\\Zigna AI Corp - RightPx\\Hospital Application_2022-03-09\\Automation_task\\outputs\\Wideformat35_{}.csv\"\n",
    "    Sample_output.to_csv(output_path.format((k[1])), index=False)\n",
    "    return Sample_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9567f7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################### wideFormat41 #######################\n",
    "def wideFormat41(CNames):\n",
    "    global df7\n",
    "    \n",
    "    Combined_data = []\n",
    "    combined_final = []\n",
    "    non_prep_data = []\n",
    "\n",
    "    def similar(x1, x2):\n",
    "        return SequenceMatcher(None, x1, x2).ratio()\n",
    "    for k in CNames.itertuples(index=False):\n",
    "        f=k[0] \n",
    "\n",
    "        #Checking the file type- xlsx   \n",
    "        if k[2]== 'csv':\n",
    "            try:\n",
    "                DF_FINAL=pd.read_csv(f)\n",
    "            except:\n",
    "                DF_FINAL=pd.read_csv(f,encoding='latin1')\n",
    "\n",
    "            non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        elif k[2]== 'xlsx':\n",
    "            sheet_to = pd.read_excel(f, sheet_name = None,dtype=str)\n",
    "            for sh in sheet_to.keys():\n",
    "                #print(sh)\n",
    "                a = sh.strip()\n",
    "                a = a.replace('.','')\n",
    "                #print(sh)\n",
    "                if CNames.FILE_NAMES.str.contains(a).any():\n",
    "                    #sh = sh.replace('.','')\n",
    "                    print(sh)\n",
    "                    DF_FINAL = pd.read_excel(f,sheet_name=sh)\n",
    "            non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        for j in df7.itertuples(index=False):\n",
    "            if str(k[1]) == str(j[0]):\n",
    "                s = j[1]\n",
    "\n",
    "        for DF_FINAL in non_prep_data:\n",
    "            try:\n",
    "                if DF_FINAL.iloc[:, [s]].empty == False:\n",
    "                    DF_10=DF_FINAL.iloc[:, [s]]    \n",
    "                    m=0\n",
    "                    c=0\n",
    "\n",
    "                    #Getting the count of  empty rows..3\n",
    "                    for index, row in DF_10.iterrows():\n",
    "                        if(pd.notnull(row[0])): \n",
    "                            m=m+1\n",
    "                            break\n",
    "                        else:\n",
    "                            c=c+1\n",
    "\n",
    "                    if c==0:\n",
    "                    #This Case works when description is in one row\n",
    "                        if \"Unnamed: 0\" in DF_10:\n",
    "                            DF_FINAL.columns=DF_FINAL.iloc[0]\n",
    "                            FINAL=DF_FINAL.drop([c])\n",
    "                            FINAL['id']=k[1]\n",
    "                            FINAL\n",
    "                        else:\n",
    "                            #This Case works when description is not found\n",
    "                            FINAL=DF_FINAL\n",
    "                            FINAL['id']=k[1]\n",
    "                            FINAL\n",
    "\n",
    "                    elif c>=1:\n",
    "                        #This Case works when description is more than 1 row\n",
    "                        #Dropping 'c' rows\n",
    "                        DF_11=DF_FINAL.iloc[c:]\n",
    "                        #row values as column names\n",
    "                        DF_11.columns=DF_11.iloc[0]\n",
    "                        #Dropping the row\n",
    "                        FINAL=DF_11.drop([c])\n",
    "                        FINAL['id']=k[1]\n",
    "\n",
    "                    else:\n",
    "                        None \n",
    "\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass\n",
    "        FINAL = FINAL.loc[:, FINAL.columns.notnull()]    \n",
    "        FINAL['sheet_name'] = sh\n",
    "        for i in FINAL.columns:\n",
    "            x = str(i).lower().strip()\n",
    "            FINAL=FINAL.rename(columns= {i:x})    \n",
    "\n",
    "\n",
    "        for i in FINAL.columns.tolist():\n",
    "\n",
    "            for k in CNames.itertuples(index=False):\n",
    "\n",
    "                for r in DF6.itertuples(index=False):\n",
    "\n",
    "                    if str(k[1]) == str(r[2]):\n",
    "                        try:\n",
    "\n",
    "                            for i in FINAL.columns.tolist():\n",
    "\n",
    "                                if str(i) == str(r[0]):\n",
    "\n",
    "                                    FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                        except:\n",
    "                            pass\n",
    "\n",
    "        for i in FINAL.columns.tolist():\n",
    "\n",
    "\n",
    "            for r in DF6.itertuples(index=False):\n",
    "\n",
    "\n",
    "\n",
    "                if str(r[2]) == \"nan\" :\n",
    "\n",
    "                    if str(i) == str(r[0]):\n",
    "                        FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "        Search_List = list(DF8[\"Dropping columns\"])\n",
    "        #dropping columns\n",
    "        FINAL= FINAL.drop(columns=[col for col in FINAL if col  in Search_List])\n",
    "\n",
    "\n",
    "        column_list = ['inpatient-outpatient']\n",
    "        for col in column_list:\n",
    "            if col not in FINAL.columns:\n",
    "                FINAL[col] = ' '\n",
    "\n",
    "\n",
    "        df2=FINAL\n",
    "        df2 = df_column_uniquify(df2)\n",
    "        #Required format - variable list\n",
    "        Col_list = list(DF5[\"Columns\"])\n",
    "        df3=df2.melt(id_vars=[col for col in df2 if col in Col_list],var_name=\"name\",value_name='cost')\n",
    "\n",
    "\n",
    "        df4=df3\n",
    "        df4=df4[df4['cost'].notnull()]\n",
    "        #Dropping_columns=['Not offered','Not Contracted','N/A','Not a covered service','Not Offered','Not contracted','Not a covered service','N/A']\n",
    "        #df4 = df4[~df4['Cost'].isin(Dropping_columns)]\n",
    "        df4\n",
    "        Combined_data.append(df4)\n",
    "    Combined_data = pd.concat(Combined_data)\n",
    "\n",
    "    Combined_data\n",
    "    #Combined_data[\"id\"]=Combined_data.id.astype('int64')\n",
    "    #Combined_data.dtypes\n",
    "    Sample_output = Combined_data\n",
    "\n",
    "    output_path = r\"C:\\Users\\User\\Zigna AI Corp\\Zigna AI Corp - RightPx\\Hospital Application_2022-03-09\\Automation_task\\outputs\\Wideformat41_{}.csv\"\n",
    "    Sample_output.to_csv(output_path.format(k[1]), index=False)\n",
    "    Sample_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bae54e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### wideFormat43 ###########################\n",
    "def wideFormat43(CNames):\n",
    "    global df7\n",
    "    \n",
    "    Combined_data = []\n",
    "    combined_final = []\n",
    "    non_prep_data = []\n",
    "    #Getting the details as list from files\n",
    "    for k in CNames.itertuples(index=False):\n",
    "        f=k[0] \n",
    "        #Checking the file type- xlsx   \n",
    "        if k[2]== 'csv':\n",
    "            try:\n",
    "                DF_FINAL=pd.read_csv(f)\n",
    "            except:\n",
    "                DF_FINAL=pd.read_csv(f,encoding='latin1')\n",
    "\n",
    "\n",
    "        elif k[2]== 'xlsx':\n",
    "            sheet_to = pd.read_excel(f,sheet_name=None,dtype=str)\n",
    "\n",
    "            for sh in sheet_to.keys():\n",
    "\n",
    "                DF_FINAL = pd.read_excel(f,sheet_name=sh,dtype=str)\n",
    "                print(sh)\n",
    "\n",
    "\n",
    "                non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        for j in df7.itertuples(index=False):\n",
    "            if str(k[1]) == str(j[0]):\n",
    "                s = j[1]\n",
    "\n",
    "        for DF_FINAL in non_prep_data:\n",
    "\n",
    "\n",
    "            try:\n",
    "                if DF_FINAL.iloc[:, [s]].empty == False:\n",
    "\n",
    "\n",
    "                    DF_10 = DF_FINAL.iloc[:,[s]]\n",
    "                    m=0\n",
    "                    c=0\n",
    "\n",
    "\n",
    "                #Getting the count of  empty rows\n",
    "                for index, row in DF_10.iterrows():\n",
    "                    if(pd.notnull(row[0])): \n",
    "                        m=m+1\n",
    "                        break\n",
    "                    else:\n",
    "                        c=c+1\n",
    "\n",
    "                if c==0:\n",
    "                #This Case works when description is in one row\n",
    "                    if \"Unnamed: 5\" in DF_10:\n",
    "                        DF_FINAL.columns=DF_FINAL.iloc[0]\n",
    "                        FINAL=DF_FINAL.drop([c])\n",
    "                        FINAL['id']=k[1]\n",
    "                        FINAL\n",
    "                    else:\n",
    "                        #This Case works when description is not found\n",
    "                        FINAL=DF_FINAL\n",
    "                        FINAL['id']=k[1]\n",
    "                        FINAL\n",
    "\n",
    "                elif c>=1:\n",
    "                    #This Case works when description is more than 1 row\n",
    "                    #Dropping 'c' rows\n",
    "                    DF_11=DF_FINAL.iloc[c:]\n",
    "                    #row values as column names\n",
    "                    DF_11.columns=DF_11.iloc[0]\n",
    "                    #Dropping the row\n",
    "                    FINAL=DF_11.drop([c])\n",
    "                    FINAL['id']=k[1]\n",
    "                else:\n",
    "                    None \n",
    "        #Checking the file type- csv\n",
    "\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass\n",
    "\n",
    "        FINAL1=FINAL.loc[:, FINAL.columns.notnull()]\n",
    "        FINAL1.dropna()\n",
    "        # FINAL1=FINAL1[FINAL1['description'].notnull()]\n",
    "\n",
    "        for i in FINAL1.columns:\n",
    "\n",
    "            x = str(i).lower().strip()\n",
    "            FINAL1=FINAL1.rename(columns= {i:x})\n",
    "\n",
    "        for i in FINAL1.columns.tolist():\n",
    "\n",
    "            for k in CNames.itertuples(index=False):\n",
    "\n",
    "                for r in DF6.itertuples(index=False):\n",
    "\n",
    "                    if str(k[1]) == str(r[2]):\n",
    "                        try:\n",
    "\n",
    "                            for i in FINAL1.columns.tolist():\n",
    "\n",
    "                                if str(i) == str(r[0]):\n",
    "\n",
    "                                    FINAL1.rename(columns={i:r[1]}, inplace=True)\n",
    "                        except:\n",
    "                                pass\n",
    "\n",
    "        for i in FINAL1.columns.tolist():\n",
    "            for r in DF6.itertuples(index=False):\n",
    "                if str(r[2]) == \"nan\" :\n",
    "                    if str(i) == str(r[0]):\n",
    "                        FINAL1.rename(columns={i:r[1]}, inplace=True)\n",
    "\n",
    "         # FINAL.drop([\"CPT/HCPCS\",\"DESCRIPTION\"], axis = 1, inplace = True)\n",
    "         #FINAL\n",
    "        Search_List = list(DF8[\"Dropping columns\"])\n",
    "            #dropping columns\n",
    "\n",
    "        FINAL1= FINAL1.drop(columns=[col for col in FINAL1 if col in Search_List])\n",
    "        column_list = ['inpatient_outpatient']\n",
    "        for col in column_list:\n",
    "            if col not in FINAL1.columns:\n",
    "                FINAL1[col] = ' '\n",
    "\n",
    "        #Search_List = list(DF3[\"Keeping columns\"])\n",
    "        #Keeping columns\n",
    "        #df1= FINAL.drop(columns=[col for col in FINAL if col not in Search_List])\n",
    "        #Removing the empty rows from'cpt code'\n",
    "        #df2 = df1.dropna(axis=0, subset=['Cpt Code'])\n",
    "\n",
    "        #df2=FINAL[FINAL['cpt code'].notnull()] \n",
    "\n",
    "        df2=FINAL1\n",
    "        df2 = df_column_uniquify(df2)\n",
    "        #Required format - variable list\n",
    "        Col_list = list(DF5[\"Columns\"])\n",
    "        df3=df2.melt(id_vars=[col for col in df2 if col in Col_list],var_name=\"name\",value_name='cost')\n",
    "        #df3=df1.melt(id_vars=['ID','Description','Cpt Code','Rev_Cd','Units'],var_name=\"Name\",value_name='Cost')\n",
    "\n",
    "        #df3['payer'] = None\n",
    "        #df3['insurance Type'] = None\n",
    "        #df3['Benefit Type']=None\n",
    "\n",
    "        #Name_List = list(DF1[\"Payers\"])\n",
    "\n",
    "        #Name_List1 = list(DF2[\"Insurance Type\"])\n",
    "\n",
    "        #Name_List2 = list(DF3[\"Benefit Type\"])\n",
    "\n",
    "        #Finding Payers from the list\n",
    "        #for i in Name_List:\n",
    "        #    df3['payer'][(df3['name'].str.contains(i,case=False,na=False))] = i\n",
    "        #Finding Insurancetype from the list    \n",
    "        #for j in Name_List1:\n",
    "        #    df3['insurance Type'][(df3['name'].str.contains(j,case=False,na=False))] = j\n",
    "\n",
    "        #Finding Benefit Type from the list  \n",
    "        #for k in Name_List2:\n",
    "        #    df3['Benefit Type'][(df3['name'].str.contains(k,case=False,na=False))] = k \n",
    "\n",
    "        df4=df3\n",
    "        df4=df4[df4['cost'].notnull()]\n",
    "        #Dropping_columns=['Not offered','Not Contracted','N/A','Not a covered service','Not Offered','Not contracted','Not a covered service','N/A']\n",
    "        #df4 = df4[~df4['Cost'].isin(Dropping_columns)]\n",
    "        df4\n",
    "        Combined_data.append(df4)\n",
    "    try:\n",
    "\n",
    "\n",
    "        Combined_data = pd.concat(Combined_data)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    Combined_data\n",
    "\n",
    "    Sample_output = Combined_data\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains('ip rate')) , 'Inpatient', Sample_output['inpatient_outpatient'])\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains('op rate')) , 'Outpatient', Sample_output['inpatient_outpatient'])\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains('inpatient')) , 'Inpatient', Sample_output['inpatient_outpatient'])\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains('outpatient')) , 'Outpatient', Sample_output['inpatient_outpatient'])\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains(' ip')) , 'Inpatient', Sample_output['inpatient_outpatient'])\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains(' op')) , 'Outpatient', Sample_output['inpatient_outpatient'])\n",
    "    \n",
    "    output_path = r\"C:\\Users\\User\\Zigna AI Corp\\Zigna AI Corp - RightPx\\Hospital Application_2022-03-09\\Automation_task\\outputs\\Wideformat43_{}.csv\"\n",
    "    Sample_output.to_csv(output_path.format(k[1]), index=False)\n",
    "    Sample_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7bc31b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "############### wideFormat61 ############################\n",
    "def wideFormat61(CNames):\n",
    "    global df7\n",
    "    \n",
    "    Combined_data = []\n",
    "    combined_final = []\n",
    "    non_prep_data = []\n",
    "    #Getting the details as list from files\n",
    "    for k in CNames.itertuples(index=False):\n",
    "        f=k[0] \n",
    "        #Checking the file type- xlsx   \n",
    "        if k[2]== 'csv':\n",
    "            try:\n",
    "                DF_FINAL=pd.read_csv(f)\n",
    "            except:\n",
    "                DF_FINAL=pd.read_csv(f,encoding='latin1')\n",
    "\n",
    "\n",
    "        elif k[2]== 'xlsx':\n",
    "            sheet_to = pd.read_excel(f,sheet_name=None,dtype=str)\n",
    "\n",
    "            for sh in sheet_to.keys():\n",
    "\n",
    "                DF_FINAL = pd.read_excel(f,sheet_name=sh,dtype=str)\n",
    "                print(sh)\n",
    "\n",
    "\n",
    "                non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        for j in df7.itertuples(index=False):\n",
    "            if str(k[1]) == str(j[0]):\n",
    "                s = j[1]\n",
    "\n",
    "        for DF_FINAL in non_prep_data:\n",
    "\n",
    "\n",
    "            try:\n",
    "                if DF_FINAL.iloc[:, [s]].empty == False:\n",
    "\n",
    "\n",
    "                    DF_10 = DF_FINAL.iloc[:,[s]]\n",
    "                    m=0\n",
    "                    c=0\n",
    "\n",
    "            #Getting the count of  empty rows\n",
    "                for index, row in DF_10.iterrows():\n",
    "                    if(pd.notnull(row[0])): \n",
    "                        m=m+1\n",
    "                        break\n",
    "                    else:\n",
    "                        c=c+1\n",
    "\n",
    "                if c==0:\n",
    "                #This Case works when description is in one row\n",
    "                    if \"Unnamed: 0\" in DF_10:\n",
    "                        DF_FINAL.columns=DF_FINAL.iloc[0]\n",
    "                        FINAL=DF_FINAL.drop([c])\n",
    "                        FINAL['id']=k[1]\n",
    "                        FINAL\n",
    "                    else:\n",
    "                        #This Case works when description is not found\n",
    "                        FINAL=DF_FINAL\n",
    "                        FINAL['id']=k[1]\n",
    "                        FINAL\n",
    "\n",
    "                elif c>=1:\n",
    "                    #This Case works when description is more than 1 row\n",
    "                    #Dropping 'c' rows\n",
    "                    DF_11=DF_FINAL.iloc[c:]\n",
    "                    #row values as column names\n",
    "                    DF_11.columns=DF_11.iloc[0]\n",
    "                    #Dropping the row\n",
    "                    FINAL=DF_11.drop([c])\n",
    "                    FINAL['id']=k[1]\n",
    "                else:\n",
    "                    None \n",
    "\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass\n",
    "        for i in FINAL.columns:\n",
    "            x = str(i).lower().strip()\n",
    "            FINAL=FINAL.rename(columns= {i:x})\n",
    "        FINAL=FINAL.T.drop_duplicates().T \n",
    "\n",
    "\n",
    "        try:    \n",
    "            FINAL = FINAL.loc[:, ~FINAL.columns.str.contains('^unnamed')]\n",
    "        except:\n",
    "            None\n",
    "\n",
    "        try:\n",
    "            FINAL = FINAL.loc[:, ~FINAL.columns.str.contains(' rate type')]\n",
    "        except:\n",
    "            None\n",
    "        try:\n",
    "            FINAL['gross charge1'] = FINAL['gross charges']\n",
    "        except:\n",
    "            None\n",
    "        try:\n",
    "            FINAL['charge1'] = FINAL['charge']\n",
    "        except:\n",
    "            None\n",
    "        for i in FINAL.columns.tolist():\n",
    "\n",
    "            for k in CNames.itertuples(index=False):\n",
    "\n",
    "                for r in DF6.itertuples(index=False):\n",
    "\n",
    "                    if str(k[1]) == str(r[2]):\n",
    "                        try:\n",
    "\n",
    "                            for i in FINAL.columns.tolist():\n",
    "\n",
    "                                if str(i) == str(r[0]):\n",
    "\n",
    "                                    FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                        except:\n",
    "                                pass\n",
    "\n",
    "        for i in FINAL.columns.tolist():\n",
    "            for r in DF6.itertuples(index=False):\n",
    "                if str(r[2]) == \"nan\" :\n",
    "                    if str(i) == str(r[0]):\n",
    "                        FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "\n",
    "\n",
    "        Search_List = list(DF8[\"Dropping columns\"])\n",
    "        #dropping columns\n",
    "        FINAL= FINAL.drop(columns=[col for col in FINAL if col  in Search_List])\n",
    "\n",
    "        column_list = ['inpatient_outpatient']\n",
    "        for col in column_list:\n",
    "            if col not in FINAL.columns:\n",
    "                FINAL[col] = ' '\n",
    "        df2=FINAL  \n",
    "        df2 = df_column_uniquify(df2)\n",
    "        #Required format - variable list\n",
    "        Col_list = list(DF5[\"Columns\"])\n",
    "        df3=df2.melt(id_vars=[col for col in df2 if col in Col_list],var_name=\"name\",value_name='cost')\n",
    "        #df3=df1.melt(id_vars=['ID','Description','Cpt Code','Rev_Cd','Units'],var_name=\"Name\",value_name='Cost')\n",
    "        df3=df3[df3['cost'].notnull()]\n",
    "        #df3['cost1'] = df3['cost'].str.contains('% of medicare opps',case = False)\n",
    "        column_list = ['cost1']\n",
    "        for col in column_list:\n",
    "            if col not in df3.columns:\n",
    "                df3[col] = ' '\n",
    "\n",
    "\n",
    "        df3[\"cost11\"] = df3['cost'].str.contains('\\d+%')\n",
    "        df3[\"cost1\"]= np.where((df3[\"cost11\"].apply(lambda x:x==True)), df3['cost'].apply(lambda x: x.split(\"%\", 1)[0]),df3[\"cost1\"])\n",
    "        df3 = df3.drop('cost11',axis = 1)\n",
    "\n",
    "        df3['cost1'] = df3['cost1'].str.extract('(\\d+)')\n",
    "        df3['cost1'] = pd.to_numeric(df3['cost1'])\n",
    "        try:\n",
    "            df3[\"gross charge1\"]= np.where((df3[\"gross charge1\"].str.contains(\",\")), df3[\"gross charge1\"].str.replace(',',''),df3[\"charge1\"])\n",
    "        except:\n",
    "            None\n",
    "        try:\n",
    "            df3[\"gross charge1\"]= np.where((df3[\"gross charge1\"].str.contains(\"$\")), df3[\"gross charge1\"].str.replace(',',''),df3[\"charge1\"])\n",
    "        except:\n",
    "            None        \n",
    "\n",
    "\n",
    "        try:\n",
    "            df3['gross charge1'] = pd.to_numeric(df3['gross charge1'])\n",
    "        except:\n",
    "            None\n",
    "        try: \n",
    "            df3[\"charge1\"]= np.where((df3[\"charge1\"].str.contains(\"$\")), df3[\"charge1\"].str.replace(',',''),df3[\"charge1\"])\n",
    "        except:\n",
    "            None\n",
    "\n",
    "        try: \n",
    "            df3[\"charge1\"]= np.where((df3[\"charge1\"].str.contains(\",\")), df3[\"charge1\"].str.replace(',',''),df3[\"charge1\"])\n",
    "        except:\n",
    "            None\n",
    "        try:    \n",
    "            df3['charge1'] = pd.to_numeric(df3['charge1'])\n",
    "        except:\n",
    "            None\n",
    "        df3['cost1'] = df3['cost1'].div(100).round(3)\n",
    "\n",
    "        df3['cost1'] = pd.to_numeric(df3['cost1'])\n",
    "\n",
    "        try:\n",
    "            df3[\"cost1\"] = df3[\"gross charge1\"] * df3[\"cost1\"]\n",
    "        except:\n",
    "            None\n",
    "        try:\n",
    "            df3[\"cost1\"] = df3[\"gross charges\"] * df3[\"cost1\"]\n",
    "        except:\n",
    "            None\n",
    "\n",
    "        try:     \n",
    "            df3[\"cost1\"] = df3[\"charge1\"] * df3[\"cost1\"]\n",
    "        except:\n",
    "            None\n",
    "\n",
    "\n",
    "        df3[\"cost1\"].fillna(df3[\"cost\"], inplace=True)\n",
    "\n",
    "        try:\n",
    "            df3 = df3.drop(['cost'],axis=1)\n",
    "        except:\n",
    "            None\n",
    "\n",
    "\n",
    "        try :\n",
    "            df3 = df3.drop([\"gross charge1\"], axis = 1)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        df4=df3.rename(columns = {'cost1': \"cost\"}) \n",
    "\n",
    "\n",
    "        df4=df4[df4['name'].notnull()]\n",
    "\n",
    "        df4\n",
    "\n",
    "        Combined_data.append(df4)\n",
    "    Combined_data = pd.concat(Combined_data)\n",
    "    Combined_data\n",
    "    Sample_output = Combined_data\n",
    "\n",
    "\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient-outpatient'] ==' ') & (Sample_output['name'].str.contains('inpatient/outpatient/drug')) , 'IP/OP', Sample_output['inpatient-outpatient'])\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient-outpatient'] ==' ') & (Sample_output['name'].str.contains('inpatient/outpatient/drug')) , 'IP/OP', Sample_output['inpatient-outpatient'])\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains('ip & op')) , 'IP & OP', Sample_output['inpatient_outpatient'])\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains('ip & op')) , 'IP & OP', Sample_output['inpatient_outpatient'])\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains('ip/op')) , 'Inpatient', Sample_output['inpatient_outpatient'])\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains('ip/op')) , 'Outpatient', Sample_output['inpatient_outpatient'])\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains('inpatient')) , 'Inpatient', Sample_output['inpatient_outpatient'])\n",
    "    Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains('outpatient')) , 'Outpatient', Sample_output['inpatient_outpatient'])\n",
    "    Sample_output['inpatient-outpatient'] = np.where((Sample_output['inpatient-outpatient'] ==' ') & (Sample_output['name'].str.contains('ip')) , 'Inpatient', Sample_output['inpatient_outpatient'])\n",
    "    Sample_output['inpatient-outpatient'] = np.where((Sample_output['inpatient-outpatient'] ==' ') & (Sample_output['name'].str.contains('op')) , 'Outpatient', Sample_output['inpatient_outpatient'])\n",
    "    \n",
    "    output_path = r\"C:\\Users\\User\\Zigna AI Corp\\Zigna AI Corp - RightPx\\Hospital Application_2022-03-09\\Automation_task\\outputs\\Wideformat61_{}.csv\"\n",
    "    Sample_output.to_csv(output_path.format(k[1]), index=False)\n",
    "    return Sample_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1d6d2d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### wideFormat76 #######################\n",
    "def wideFormat76(CNames):\n",
    "    global df7\n",
    "    \n",
    "        \n",
    "    Combined_data = []\n",
    "    combined_final = []\n",
    "    non_prep_data = []\n",
    "    #Getting the details as list from files\n",
    "    for k in CNames.itertuples(index=False):\n",
    "        f=k[0] \n",
    "        #Checking the file type- xlsx   \n",
    "        if k[2]== 'csv':\n",
    "            try:\n",
    "                DF_FINAL=pd.read_csv(f)\n",
    "            except:\n",
    "                DF_FINAL=pd.read_csv(f,encoding='latin1')\n",
    "                \n",
    "            non_prep_data.append(DF_FINAL)\n",
    "        \n",
    "        elif k[2]== 'xlsx':\n",
    "            sheet_to = pd.read_excel(f,sheet_name=None,dtype=str,header=None)\n",
    "         \n",
    "            for sh in sheet_to.keys():\n",
    "               \n",
    "                DF_FINAL = pd.read_excel(f,sheet_name=sh,dtype=str)\n",
    "                print(sh)\n",
    "                non_prep_data.append(DF_FINAL)\n",
    "                \n",
    "        for j in df7.itertuples(index=False):\n",
    "            if str(k[1]) == str(j[0]):\n",
    "                s = j[1]\n",
    "                \n",
    "        for DF_FINAL in non_prep_data:\n",
    "            try:\n",
    "                if DF_FINAL.iloc[:, [s]].empty == False:\n",
    "                    DF_10=DF_FINAL.iloc[:, [s]]    \n",
    "                    m=0\n",
    "                    c=0\n",
    "                    \n",
    "                    #Getting the count of  empty rows\n",
    "                    for index, row in DF_10.iterrows():\n",
    "                        if(pd.notnull(row[0])): \n",
    "                            m=m+1\n",
    "                            break\n",
    "                        else:\n",
    "                            c=c+1\n",
    "                            \n",
    "                    if c==0:\n",
    "                    #This Case works when description is in one row\n",
    "                        if \"Unnamed: 5\" in DF_10:\n",
    "                            DF_FINAL.columns=DF_FINAL.iloc[0]\n",
    "                            FINAL=DF_FINAL.drop([c])\n",
    "                            FINAL['id']=k[1]\n",
    "                            FINAL\n",
    "                        else:\n",
    "                            #This Case works when description is not found\n",
    "                            FINAL=DF_FINAL\n",
    "                            FINAL['id']=k[1]\n",
    "                            FINAL\n",
    "                            \n",
    "                    elif c>=1:\n",
    "                        #This Case works when description is more than 1 row\n",
    "                        #Dropping 'c' rows\n",
    "                        DF_11=DF_FINAL.iloc[c:]\n",
    "                        #row values as column names\n",
    "                        DF_11.columns=DF_11.iloc[0]\n",
    "                        #Dropping the row\n",
    "                        FINAL=DF_11.drop([c])\n",
    "                        FINAL['id']=k[1]\n",
    "                    else:\n",
    "                        None \n",
    "                        \n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass\n",
    "    \n",
    "            \n",
    "       \n",
    "        \n",
    "        try:\n",
    "            FINAL = FINAL.drop([\"Location\", \"Per\"], axis = 1)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        FINAL[\"LineItem_cnt\"] = FINAL.groupby([\"CPT\",\"ProcedureDescription\"])[\"CPT\"].transform('count')\n",
    "        FINAL[\"LineItem_cnt\"]=FINAL[\"LineItem_cnt\"]-1\n",
    "    \n",
    "    \n",
    "        \n",
    "        for i in FINAL.columns:\n",
    "           x = str(i).lower().strip()\n",
    "           FINAL=FINAL.rename(columns= {i:x}) \n",
    "    \n",
    "        for i in FINAL.columns.tolist():\n",
    "     \n",
    "            for k in CNames.itertuples(index=False):\n",
    "     \n",
    "                for r in DF6.itertuples(index=False):\n",
    "     \n",
    "                    if str(k[1]) == str(r[2]):\n",
    "                        try:\n",
    "     \n",
    "                            for i in FINAL.columns.tolist():\n",
    "     \n",
    "                                if str(i) == str(r[0]):\n",
    "     \n",
    "                                    FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                        except:\n",
    "                            pass\n",
    "     \n",
    "        for i in FINAL.columns.tolist():\n",
    "            for r in DF6.itertuples(index=False):\n",
    "                if str(r[2]) == \"nan\" :\n",
    "    \n",
    "                   if str(i) == str(r[0]):\n",
    "                       FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                       \n",
    "        Search_List = list(DF8[\"Dropping columns\"])\n",
    "            #dropping columns\n",
    "    \n",
    "        FINAL= FINAL.drop(columns=[col for col in FINAL if col in Search_List])\n",
    "          \n",
    "        #Checking the  Inpatient/Outpatient column exists or not\n",
    "        column_list = ['inpatient-outpatient']\n",
    "        for col in column_list:\n",
    "            if col not in FINAL.columns:\n",
    "                FINAL[col] = ' '\n",
    "                \n",
    "    \n",
    "        \n",
    "        df2=FINAL\n",
    "        df2 = df_column_uniquify(df2)\n",
    "        #Required format - variable list\n",
    "        Col_list = list(DF5[\"Columns\"])\n",
    "        df3=df2.melt(id_vars=[col for col in df2 if col in Col_list],var_name=\"name\",value_name='cost')\n",
    "        #df3=df1.melt(id_vars=['ID','Description','Cpt Code','Rev_Cd','Units'],var_name=\"Name\",value_name='Cost')\n",
    "        df3=df3[df3['name'].notnull()] \n",
    "        \n",
    "        \n",
    "        df4=df3\n",
    "        df4=df4[df4['cost'].notnull()]\n",
    "        \n",
    "        df4\n",
    "        Combined_data.append(df4)\n",
    "    Combined_data = pd.concat(Combined_data)\n",
    "    output_path = r\"C:\\Users\\User\\Zigna AI Corp\\Zigna AI Corp - RightPx\\Hospital Application_2022-03-09\\Automation_task\\outputs\\Wideformat76_{}.csv\"\n",
    "    Combined_data.to_csv(output_path.format((k[1])), index=False)\n",
    "    return Combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "84ecbfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "############## wideFormat77 ####################\n",
    "def wideFormat77(CNames):\n",
    "    global df7\n",
    "    \n",
    "    Combined_data = []\n",
    "    combined_final = []\n",
    "    non_prep_data = []\n",
    "    #Getting the details as list from files\n",
    "    for k in CNames.itertuples(index=False):\n",
    "        f=k[0] \n",
    "        #Checking the file type- xlsx   \n",
    "        if k[2]== 'csv':\n",
    "            try:\n",
    "                DF_FINAL=pd.read_csv(f)\n",
    "            except:\n",
    "                DF_FINAL=pd.read_csv(f,encoding='latin1')\n",
    "\n",
    "            non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        elif k[2]== 'xlsx':\n",
    "            sheet_to = pd.read_excel(f,sheet_name=None,dtype=str,header=None)\n",
    "\n",
    "            for sh in sheet_to.keys():\n",
    "\n",
    "                DF_FINAL = pd.read_excel(f,sheet_name=sh,dtype=str)\n",
    "                print(sh)\n",
    "                non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        for j in df7.itertuples(index=False):\n",
    "            if str(k[1]) == str(j[0]):\n",
    "                s = j[1]\n",
    "\n",
    "        for DF_FINAL in non_prep_data:\n",
    "            try:\n",
    "                if DF_FINAL.iloc[:, [s]].empty == False:\n",
    "                    DF_10=DF_FINAL.iloc[:, [s]]    \n",
    "                    m=0\n",
    "                    c=0\n",
    "                    #print(sh)\n",
    "                    #Getting the count of  empty rows\n",
    "                    for index, row in DF_10.iterrows():\n",
    "                        if(pd.notnull(row[0])): \n",
    "                            m=m+1\n",
    "                            break\n",
    "                        else:\n",
    "                            c=c+1\n",
    "\n",
    "                    if c==0:\n",
    "                    #This Case works when description is in one row\n",
    "                        if \"Unnamed: 2\" in DF_10:\n",
    "                            DF_FINAL.columns=DF_FINAL.iloc[0]\n",
    "                            #print(sh)\n",
    "                            FINAL=DF_FINAL.drop([c])\n",
    "                            FINAL['id']=k[1]\n",
    "                            FINAL.dropna(how='all', inplace=True)\n",
    "                            FINAL = FINAL.reset_index(drop=True)\n",
    "\n",
    "                            for i in FINAL.columns:\n",
    "                                x = str(i).lower().strip()\n",
    "                                FINAL=FINAL.rename(columns= {i:x})\n",
    "                            for i in FINAL.columns.tolist():\n",
    "                                for r in DF6.itertuples(index=False):\n",
    "                                    if str(i) == str(r[0]):\n",
    "                                        FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                            combined_final.append(FINAL)\n",
    "\n",
    "                        else:\n",
    "                            #This Case works when description is not found\n",
    "                            FINAL=DF_FINAL\n",
    "                            FINAL['id']=k[1]\n",
    "                            FINAL.dropna(how='all', inplace=True)\n",
    "                            FINAL = FINAL.reset_index(drop=True)\n",
    "\n",
    "                            for i in FINAL.columns:\n",
    "                                x = str(i).lower().strip()\n",
    "                                FINAL=FINAL.rename(columns= {i:x})\n",
    "                            for i in FINAL.columns.tolist():\n",
    "                                for r in DF6.itertuples(index=False):\n",
    "                                    if str(i) == str(r[0]):\n",
    "                                        FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                            combined_final.append(FINAL)\n",
    "\n",
    "\n",
    "\n",
    "                    elif c>=1:\n",
    "                        #This Case works when description is more than 1 row\n",
    "                        #Dropping 'c' rows\n",
    "                        DF_11=DF_FINAL.iloc[c:]\n",
    "                        DF_11[:c]=DF_11[:c].fillna(method='ffill', axis=1)\n",
    "                        DF_11[:c] = DF_11[:c].fillna(' ')\n",
    "\n",
    "                        if sh == \"Magee Physicians Group\":\n",
    "                            try:\n",
    "                                DF_FINAL.columns = (DF_FINAL.iloc[c] +' '+ DF_FINAL.iloc[c+1] +' '+ DF_FINAL.iloc[c+2])\n",
    "                                DF_FINAL = DF_FINAL.iloc[c+3:]  \n",
    "                            except:\n",
    "                                None\n",
    "                        if sh == \"Magee Rehabilitation Hospital\":\n",
    "                            try:\n",
    "                                DF_FINAL.columns = (DF_FINAL.iloc[c] +' '+ DF_FINAL.iloc[c+1])\n",
    "                                DF_FINAL = DF_FINAL.iloc[c+2:]\n",
    "                            except:\n",
    "                                None\n",
    "                    #Dropping the row\n",
    "                        FINAL = DF_FINAL.reset_index(drop=True)\n",
    "                        FINAL['id']=k[1]\n",
    "                        FINAL.dropna(how='all', inplace=True)\n",
    "                        FINAL = FINAL.reset_index(drop=True)\n",
    "                        # FINAL.columns.str.lower().strip()\n",
    "                        for i in FINAL.columns:\n",
    "                            x = str(i).lower().strip()\n",
    "                            FINAL=FINAL.rename(columns= {i:x})\n",
    "                        for i in FINAL.columns.tolist():\n",
    "                            for r in DF6.itertuples(index=False):\n",
    "                                if str(i) == str(r[0]):\n",
    "                                    FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                        combined_final.append(FINAL)\n",
    "\n",
    "\n",
    "\n",
    "                    else:\n",
    "                        None\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass\n",
    "\n",
    "\n",
    "\n",
    "        FINAL = pd.concat(combined_final) \n",
    "\n",
    "        Search_List = list(DF8[\"Dropping columns\"])\n",
    "             #dropping columns\n",
    "\n",
    "        FINAL= FINAL.drop(columns=[col for col in FINAL if col in Search_List])\n",
    "\n",
    "\n",
    "\n",
    "        column_list = ['inpatient-outpatient']\n",
    "        for col in column_list:\n",
    "            if col not in FINAL.columns:\n",
    "                FINAL[col] = ' '\n",
    "\n",
    "        df2=FINAL\n",
    "        df2 = df_column_uniquify(df2)\n",
    "        #Required format - variable list\n",
    "        Col_list = list(DF5[\"Columns\"])\n",
    "        df3=df2.melt(id_vars=[col for col in df2 if col in Col_list],var_name=\"name\",value_name='cost')\n",
    "        #df3=df1.melt(id_vars=['ID','Description','Cpt Code','Rev_Cd','Units'],var_name=\"Name\",value_name='Cost')\n",
    "\n",
    "\n",
    "        df4=df3\n",
    "        df4=df4[df4['cost'].notnull()]\n",
    "\n",
    "        #Dropping_columns=['Not offered','Not Contracted','N/A','Not a covered service','Not Offered','Not contracted','Not a covered service','N/A']\n",
    "        #df4 = df4[~df4['Cost'].isin(Dropping_columns)]\n",
    "        df4\n",
    "        Combined_data.append(df4)\n",
    "    Combined_data = pd.concat(Combined_data)\n",
    "    Combined_data\n",
    "    output_path = r\"C:\\Users\\User\\Zigna AI Corp\\Zigna AI Corp - RightPx\\Hospital Application_2022-03-09\\Automation_task\\outputs\\Wideformat77_{}.csv\"\n",
    "    Combined_data.to_csv(output_path.format((k[1])), index=False)\n",
    "    return Combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c7dbd77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "################### wideFormat79 ###################\n",
    "def wideFormat79(CNames):\n",
    "    global df7\n",
    "    \n",
    "    Combined_data = []\n",
    "    combined_final = []\n",
    "    non_prep_data = []\n",
    "    #Getting the details as list from files\n",
    "    for k in CNames.itertuples(index=False):\n",
    "        f=k[0] \n",
    "        #Checking the file type- xlsx   \n",
    "        if k[2]== 'csv':\n",
    "            try:\n",
    "                DF_FINAL=pd.read_csv(f)\n",
    "            except:\n",
    "                DF_FINAL=pd.read_csv(f,encoding='latin1')\n",
    "\n",
    "            non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        elif k[2]== 'xlsx':\n",
    "            sheet_to = pd.read_excel(f,sheet_name=None,dtype=str,header=None)\n",
    "\n",
    "            for sh in sheet_to.keys():\n",
    "\n",
    "                DF_FINAL = pd.read_excel(f,sheet_name=sh,dtype=str)\n",
    "                print(sh)\n",
    "                non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        for j in df7.itertuples(index=False):\n",
    "            if str(k[1]) == str(j[0]):\n",
    "                s = j[1]\n",
    "\n",
    "        for DF_FINAL in non_prep_data:\n",
    "            try:\n",
    "                if DF_FINAL.iloc[:, [s]].empty == False:\n",
    "                    DF_FINAL=pd.read_excel(f,sheet_name=sh,header=None)\n",
    "                    DF_FINAL[:1] = DF_FINAL[:1].fillna(method='ffill', axis=1)\n",
    "                    DF_FINAL[:1] = DF_FINAL[:1].fillna('')\n",
    "                    DF_FINAL[:2] = DF_FINAL[:2].fillna('')\n",
    "                    DF_FINAL.columns = (DF_FINAL.iloc[0] + ' ' +DF_FINAL.iloc[1])\n",
    "                    DF_FINAL = DF_FINAL.iloc[2:]      \n",
    "\n",
    "\n",
    "                    DF_10=DF_FINAL.iloc[:, [s]]    \n",
    "                    m=0\n",
    "                    c=0\n",
    "\n",
    "                    #Getting the count of  empty rows\n",
    "                    for index, row in DF_10.iterrows():\n",
    "                        if(pd.notnull(row[0])): \n",
    "                            m=m+1\n",
    "                            break\n",
    "                        else:\n",
    "                            c=c+1\n",
    "\n",
    "                    if c==0:\n",
    "                    #This Case works when description is in one row\n",
    "                        if \"Unnamed: 5\" in DF_10:\n",
    "                            DF_FINAL.columns=DF_FINAL.iloc[0]\n",
    "                            FINAL=DF_FINAL.drop([c])\n",
    "                            FINAL['id']=k[1]\n",
    "                            FINAL\n",
    "                        else:\n",
    "                            #This Case works when description is not found\n",
    "                            FINAL=DF_FINAL\n",
    "                            FINAL['id']=k[1]\n",
    "                            FINAL\n",
    "\n",
    "                    elif c>=1:\n",
    "                        #This Case works when description is more than 1 row\n",
    "                        #Dropping 'c' rows\n",
    "                        DF_11=DF_FINAL.iloc[c:]\n",
    "                        #row values as column names\n",
    "                        DF_11.columns=DF_11.iloc[0]\n",
    "                        #Dropping the row\n",
    "                        FINAL=DF_11.drop([c])\n",
    "                        FINAL['id']=k[1]\n",
    "                    else:\n",
    "                        None \n",
    "\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass\n",
    "\n",
    "\n",
    "        for i in FINAL.columns:\n",
    "            x = str(i).lower().strip()\n",
    "            FINAL=FINAL.rename(columns= {i:x})\n",
    "\n",
    "        for i in FINAL.columns.tolist():\n",
    "\n",
    "            for k in CNames.itertuples(index=False):\n",
    "\n",
    "                for r in DF6.itertuples(index=False):\n",
    "\n",
    "                    if str(k[1]) == str(r[2]):\n",
    "                        try:\n",
    "\n",
    "                            for i in FINAL.columns.tolist():\n",
    "\n",
    "                                if str(i) == str(r[0]):\n",
    "\n",
    "                                    FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                        except:\n",
    "                                pass\n",
    "\n",
    "        for i in FINAL.columns.tolist():\n",
    "            for r in DF6.itertuples(index=False):\n",
    "                if str(i) == str(r[0]):\n",
    "                    FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "\n",
    "        Search_List = list(DF8[\"Dropping columns\"])\n",
    "            #dropping columns\n",
    "\n",
    "        FINAL= FINAL.drop(columns=[col for col in FINAL if col in Search_List])\n",
    "\n",
    "        FINAL.loc[:, FINAL.columns.notnull()]\n",
    "\n",
    "        column_list = ['inpatient_outpatient']\n",
    "        for col in column_list:\n",
    "            if col not in FINAL.columns:\n",
    "                FINAL[col] = ' '\n",
    "\n",
    "\n",
    "\n",
    "        df2=FINAL\n",
    "        df2 = df_column_uniquify(df2)\n",
    "        #Required format - variable list\n",
    "        Col_list = list(DF5[\"Columns\"])\n",
    "        df3=df2.melt(id_vars=[col for col in df2 if col in Col_list],var_name=\"name\",value_name='cost')\n",
    "\n",
    "        df4=df3\n",
    "        df4=df4[df4['cost'].notnull()]\n",
    "        #Dropping_columns=['Not offered','Not Contracted','N/A','Not a covered service','Not Offered','Not contracted','Not a covered service','N/A']\n",
    "        #df4 = df4[~df4['Cost'].isin(Dropping_columns)]\n",
    "        df4\n",
    "        Combined_data.append(df4)\n",
    "    Combined_data = pd.concat(Combined_data)\n",
    "\n",
    "    Combined_data\n",
    "    output_path = r\"C:\\Users\\User\\Zigna AI Corp\\Zigna AI Corp - RightPx\\Hospital Application_2022-03-09\\Automation_task\\outputs\\Wideformat79_{}.csv\"\n",
    "    Combined_data.to_csv(output_path.format((k[1])), index=False)\n",
    "    return Combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c93a687a",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## wideFormat7_1 #######################\n",
    "def wideFormat7_1(CNames):\n",
    "    global df7\n",
    "    \n",
    "    Combined_data = []\n",
    "    combined_final = []\n",
    "    non_prep_data = []\n",
    "    #Getting the details as list from files\n",
    "    for k in CNames.itertuples(index=False):\n",
    "        f=k[0] \n",
    "        #Checking the file type- xlsx   \n",
    "        if k[2]== 'csv':\n",
    "            try:\n",
    "                DF_FINAL=pd.read_csv(f)\n",
    "            except:\n",
    "                DF_FINAL=pd.read_csv(f,encoding='latin1')\n",
    "\n",
    "            non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        elif k[2]== 'xlsx':\n",
    "            sheet_to = pd.read_excel(f,sheet_name=None,dtype=str,header=None)\n",
    "\n",
    "            for sh in sheet_to.keys():\n",
    "\n",
    "                DF_FINAL = pd.read_excel(f,sheet_name=sh,dtype=str)\n",
    "                print(sh)\n",
    "                non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        for j in df7.itertuples(index=False):\n",
    "            if str(k[1]) == str(j[0]):\n",
    "                s = j[1]\n",
    "\n",
    "        for DF_FINAL in non_prep_data:\n",
    "            try:\n",
    "                if DF_FINAL.iloc[:, [s]].empty == False:\n",
    "                    DF_10=DF_FINAL.iloc[:, [s]]    \n",
    "                    m=0\n",
    "                    c=0\n",
    "\n",
    "                    #Getting the count of  empty rows\n",
    "                    for index, row in DF_10.iterrows():\n",
    "                        if(pd.notnull(row[0])): \n",
    "                            m=m+1\n",
    "                            break\n",
    "                        else:\n",
    "                            c=c+1\n",
    "\n",
    "                    if c==0:\n",
    "                    #This Case works when description is in one row\n",
    "                        if \"Unnamed: 5\" in DF_10:\n",
    "                            DF_FINAL.columns=DF_FINAL.iloc[0]\n",
    "                            FINAL=DF_FINAL.drop([c])\n",
    "                            FINAL['id']=k[1]\n",
    "                            FINAL\n",
    "                        else:\n",
    "                            #This Case works when description is not found\n",
    "                            FINAL=DF_FINAL\n",
    "                            FINAL['id']=k[1]\n",
    "                            FINAL\n",
    "\n",
    "                    elif c>=1:\n",
    "                        #This Case works when description is more than 1 row\n",
    "                        #Dropping 'c' rows\n",
    "                        DF_11=DF_FINAL.iloc[c:]\n",
    "                        #row values as column names\n",
    "                        DF_11.columns=DF_11.iloc[0]\n",
    "                        #Dropping the row\n",
    "                        FINAL=DF_11.drop([c])\n",
    "                        FINAL['id']=k[1]\n",
    "                    else:\n",
    "                        None \n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass\n",
    "\n",
    "\n",
    "\n",
    "        Search_List = list(DF8[\"Dropping columns\"])\n",
    "        #dropping columns\n",
    "        FINAL= FINAL.drop(columns=[col for col in FINAL if col  in Search_List])\n",
    "\n",
    "        for i in FINAL.columns:\n",
    "            x = str(i).lower().strip()\n",
    "            FINAL=FINAL.rename(columns= {i:x})\n",
    "\n",
    "        for i in FINAL.columns.tolist():\n",
    "\n",
    "            for k in CNames.itertuples(index=False):\n",
    "\n",
    "                for r in DF6.itertuples(index=False):\n",
    "\n",
    "                    if str(k[1]) == str(r[2]):\n",
    "                        try:\n",
    "\n",
    "                            for i in FINAL.columns.tolist():\n",
    "\n",
    "                                if str(i) == str(r[0]):\n",
    "\n",
    "                                    FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                        except:\n",
    "                                pass\n",
    "\n",
    "        for i in FINAL.columns.tolist():\n",
    "            for r in DF6.itertuples(index=False):\n",
    "                if str(i) == str(r[0]):\n",
    "                    FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "        #Checking the  Inpatient/Outpatient column exists or not\n",
    "        column_list = ['inpatient-outpatient']\n",
    "        for col in column_list:\n",
    "            if col not in FINAL.columns:\n",
    "                FINAL[col] = ' '\n",
    "\n",
    "\n",
    "\n",
    "        df2=FINAL\n",
    "        df2 = df_column_uniquify(df2)\n",
    "        #Required format - variable list\n",
    "        Col_list = list(DF5[\"Columns\"])\n",
    "        df3=df2.melt(id_vars=[col for col in df2 if col in Col_list],var_name=\"name\",value_name='cost')\n",
    "\n",
    "\n",
    "        df4=df3\n",
    "        df4=df4[df4['cost'].notnull()]\n",
    "        #Dropping_columns=['Not offered','Not Contracted','N/A','Not a covered service','Not Offered','Not contracted','Not a covered service','N/A']\n",
    "        #df4 = df4[~df4['Cost'].isin(Dropping_columns)]\n",
    "        df4\n",
    "        Combined_data.append(df4)\n",
    "    Combined_data = pd.concat(Combined_data)\n",
    "\n",
    "    Combined_data\n",
    "    # Combined_data[\"id\"]=Combined_data.id.astype('int64')\n",
    "    # Combined_data.dtypes\n",
    "    Sample_output = Combined_data\n",
    "\n",
    "\n",
    "\n",
    "    try:\n",
    "        Sample_output['inpatient-outpatient'] = np.where((Sample_output['inpatient-outpatient'] ==' ') & (Sample_output['Primary Service and Ancillary Service'].str.contains('Outpatient')) , 'Outpatient', Sample_output['inpatient-outpatient'])\n",
    "        Sample_output['inpatient-outpatient'] = np.where((Sample_output['inpatient-outpatient'] ==' ') & (Sample_output['Primary Service and Ancillary Service'].str.contains('Inpatient')) , 'Inpatient', Sample_output['inpatient-outpatient'])\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    output_path = r\"C:\\Users\\User\\Zigna AI Corp\\Zigna AI Corp - RightPx\\Hospital Application_2022-03-09\\Automation_task\\outputs\\Wideformat7_1_{}.csv\"\n",
    "    Sample_output.to_csv(output_path.format((k[1])), index=False)\n",
    "    return Sample_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9547e848",
   "metadata": {},
   "outputs": [],
   "source": [
    "################## wideFormat91 #################\n",
    "def wideFormat91(CNames):\n",
    "    global df7     \n",
    "    Combined_data = []\n",
    "    combined_final = []\n",
    "    non_prep_data = []\n",
    "    #Getting the details as list from files\n",
    "    for k in CNames.itertuples(index=False):\n",
    "        f=k[0] \n",
    "        #Checking the file type- xlsx   \n",
    "        if k[2]== 'csv':\n",
    "            try:\n",
    "                DF_FINAL=pd.read_csv(f)\n",
    "            except:\n",
    "                DF_FINAL=pd.read_csv(f,encoding='latin1')\n",
    "                \n",
    "            non_prep_data.append(DF_FINAL)\n",
    "        \n",
    "        elif k[2]== 'xlsx':\n",
    "            sheet_to = pd.read_excel(f,sheet_name=None,dtype=str,header=None)\n",
    "         \n",
    "            for sh in sheet_to.keys():\n",
    "               \n",
    "                DF_FINAL = pd.read_excel(f,sheet_name=sh,dtype=str)\n",
    "                print(sh)\n",
    "                non_prep_data.append(DF_FINAL)\n",
    "                \n",
    "        for j in df7.itertuples(index=False):\n",
    "            if str(k[1]) == str(j[0]):\n",
    "                s = j[1]\n",
    "                \n",
    "        for DF_FINAL in non_prep_data:\n",
    "            try:\n",
    "                if DF_FINAL.iloc[:, [s]].empty == False:\n",
    "                    try:\n",
    "                        #df=pd.read_csv(f)\n",
    "                        DF_FINAL= pd.concat(pd.read_csv(f,sheet_name=None,dtype=str))\n",
    "                        DF_FINAL.reset_index(level=0, inplace=True)\n",
    "                        #DF6=pd.read_excel ('D:\\\\zigna Analytics\\\\Wide format 4\\\\Payers list v.xlsx',sheet_name='Rnme')\n",
    "                        for i in DF_FINAL.columns:\n",
    "                            x = str(i).lower().strip()\n",
    "                            DF_FINAL=DF_FINAL.rename(columns= {i:x})\n",
    "                        for i in DF_FINAL.columns.tolist():\n",
    "                            for r in DF6.itertuples(index=False):\n",
    "                                if str(r[2]) == \"nan\" :\n",
    "                                    if str(i) == str(r[0]):\n",
    "                                        DF_FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                    #df[\"description\"] = df[\"description\"].str.upper()\n",
    "                        def sjoin(x): return ';'.join(x[x.notnull()].astype(str))\n",
    "            \n",
    "                        DF_FINAL = DF_FINAL.groupby(level=0, axis=1).apply(lambda x: x.apply(sjoin, axis=1))\n",
    "                        DF_FINAL.drop([\"inpatient-outpatient\"], axis = 1, inplace = True)\n",
    "                    except:\n",
    "                        #df=pd.read_csv(f,encoding='latin1')\n",
    "                        DF_FINAL= pd.concat(pd.read_csv(f,sheet_name=None,encoding='latin1',dtype=str))\n",
    "                        DF_FINAL.reset_index(level=0, inplace=True)\n",
    "                        #DF6=pd.read_excel ('D:\\\\zigna Analytics\\\\Wide format 4\\\\Payers list v.xlsx',sheet_name='Rnme')\n",
    "                        for i in DF_FINAL.columns:\n",
    "                            x = str(i).lower().strip()\n",
    "                            DF_FINAL=DF_FINAL.rename(columns= {i:x})\n",
    "                        for i in DF_FINAL.columns.tolist():\n",
    "                            for r in DF6.itertuples(index=False):\n",
    "                                if str(r[2]) == \"nan\" :\n",
    "                                    if str(i) == str(r[0]):\n",
    "                                        DF_FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                    #df[\"description\"] = df[\"description\"].str.upper()\n",
    "                        def sjoin(x): return ';'.join(x[x.notnull()].astype(str))\n",
    "            \n",
    "                        DF_FINAL = DF_FINAL.groupby(level=0, axis=1).apply(lambda x: x.apply(sjoin, axis=1))\n",
    "                        DF_FINAL.drop([\"inpatient-outpatient\"], axis = 1, inplace = True)\n",
    "            \n",
    "                    if 'Unnamed: 0' not in DF_FINAL.iloc[:, [0]]:\n",
    "                        if 'Primary Service and Ancillary Services' not in DF_FINAL.iloc[:, [2]]:\n",
    "                            \n",
    "            \n",
    "                            DF_13=DF_FINAL.iloc[:, [s]]\n",
    "                            M=0\n",
    "                            C=0   \n",
    "            \n",
    "                            for index, row in DF_13.iterrows():\n",
    "                                if(pd.notnull(row[0])):\n",
    "                                    M=M+1\n",
    "                                    break\n",
    "                                else:\n",
    "                                    C=C+1\n",
    "            \n",
    "                            if C==0:\n",
    "                                #This Case works when description is in one row\n",
    "                                if \"Unnamed: 5\" in DF_13:\n",
    "                                    DF_FINAL.columns=DF_FINAL.iloc[0]\n",
    "                                    FINAL=DF_FINAL.drop([C])\n",
    "                                    FINAL['Hospital_Id']=k[1]\n",
    "                                    FINAL \n",
    "            \n",
    "                                else:\n",
    "                                    #This Case works when description is not found\n",
    "                                    FINAL=DF_FINAL\n",
    "                                    FINAL['Hospital_Id']=k[1]\n",
    "                                    FINAL\n",
    "                            elif C>=1:\n",
    "                                #This Case works when description is more than 1 row\n",
    "                                #Dropping 'c' rows\n",
    "                                DF_14=DF_FINAL.iloc[C:]\n",
    "                                #row values as column names\n",
    "                                DF_14.columns=DF_14.iloc[0]\n",
    "                                #Dropping the row\n",
    "                                FINAL=DF_14.drop([C])\n",
    "                                FINAL['Hospital_Id']=k[1] \n",
    "                                FINAL \n",
    "                            else:\n",
    "                                None\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass\n",
    "    \n",
    "            \n",
    "             \n",
    "                    \n",
    "    \n",
    "    \n",
    "        #for r in DF6.itertuples(index=False):\n",
    "            #FINAL.rename(columns={r[0]:r[1]}, inplace=True)\n",
    "        Search_List = list(DF8[\"Dropping columns\"])\n",
    "        #dropping columns\n",
    "        FINAL= FINAL.drop(columns=[col for col in FINAL if col in Search_List])\n",
    "        #Checking the  Inpatient/Outpatient column exists or not\n",
    "        column_list = ['inpatient-outpatient']\n",
    "        for col in column_list:\n",
    "            if col not in FINAL.columns:\n",
    "                FINAL[col] = ' '\n",
    "    \n",
    "        \n",
    "    \n",
    "        df2=FINAL\n",
    "        df2 = df_column_uniquify(df2)\n",
    "        #Required format - variable list\n",
    "        Col_list = list(DF5[\"Columns\"])\n",
    "        df3=df2.melt(id_vars=[col for col in df2 if col in Col_list],var_name=\"name\",value_name='cost')\n",
    "        #df3=df1.melt(id_vars=['ID','Description','Cpt Code','Rev_Cd','Units'],var_name=\"Name\",value_name='Cost')\n",
    "    \n",
    "      \n",
    "        df4=df3\n",
    "        df4=df4[df4['cost'].notnull()]\n",
    "    \n",
    "        #Dropping_columns=['Not offered','Not Contracted','N/A','Not a covered service','Not Offered','Not contracted','Not a covered service','N/A']\n",
    "        #df4 = df4[~df4['Cost'].isin(Dropping_columns)]\n",
    "        df4\n",
    "        Combined_data.append(df4)\n",
    "    Combined_data = pd.concat(Combined_data)\n",
    "    \n",
    "    Combined_data\n",
    "    output_path = r\"C:\\Users\\User\\Zigna AI Corp\\Zigna AI Corp - RightPx\\Hospital Application_2022-03-09\\Automation_task\\outputs\\Wideformat91_{}.csv\"\n",
    "    Combined_data.to_csv(output_path.format((k[1])), index=False)\n",
    "    return Combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "17a46404",
   "metadata": {},
   "outputs": [],
   "source": [
    "################# wideFormat92 #################\n",
    "def wideFormat92(CNames):\n",
    "    global df7       \n",
    "    Combined_data = []\n",
    "    combined_final = []\n",
    "    non_prep_data = []\n",
    "    #Getting the details as list from files\n",
    "    for k in CNames.itertuples(index=False):\n",
    "        f=k[0] \n",
    "        #Checking the file type- xlsx   \n",
    "        if k[2]== 'csv':\n",
    "            try:\n",
    "                DF_FINAL=pd.read_csv(f)\n",
    "            except:\n",
    "                DF_FINAL=pd.read_csv(f,encoding='latin1')\n",
    "                \n",
    "            non_prep_data.append(DF_FINAL)\n",
    "        \n",
    "        elif k[2]== 'xlsx':\n",
    "            sheet_to = pd.read_excel(f,sheet_name=None,dtype=str,header=None)\n",
    "         \n",
    "            for sh in sheet_to.keys():\n",
    "               \n",
    "                DF_FINAL = pd.read_excel(f,sheet_name=sh,dtype=str)\n",
    "                print(sh)\n",
    "                non_prep_data.append(DF_FINAL)\n",
    "                \n",
    "        for j in df7.itertuples(index=False):\n",
    "            if str(k[1]) == str(j[0]):\n",
    "                s = j[1]\n",
    "                \n",
    "        for DF_FINAL in non_prep_data:\n",
    "            try:\n",
    "                if DF_FINAL.iloc[:, [s]].empty == False:\n",
    "    \n",
    "    \n",
    "    \n",
    "                    DF_10=DF_FINAL.iloc[:, [s]]    \n",
    "                    m=0\n",
    "                    c=0\n",
    "    \n",
    "                    #Getting the count of  empty rows\n",
    "                    for index, row in DF_10.iterrows():\n",
    "                        if(pd.notnull(row[0])): \n",
    "                            m=m+1\n",
    "                            break\n",
    "                        else:\n",
    "                            c=c+1\n",
    "    \n",
    "                    if c==0:\n",
    "                    #This Case works when description is in one row\n",
    "                        if \"Unnamed: 2\" in DF_10:\n",
    "                            DF_FINAL.columns=DF_FINAL.iloc[0]\n",
    "                            FINAL=DF_FINAL.drop([c])\n",
    "                            FINAL['id']=k[1]\n",
    "                            FINAL.dropna(how='all', axis=1, inplace=True)\n",
    "                            for i in FINAL.columns:\n",
    "                                x = str(i).lower().strip()\n",
    "                                FINAL=FINAL.rename(columns= {i:x})\n",
    "                         \n",
    "                            for i in FINAL.columns.tolist():\n",
    "                         \n",
    "                                for k in CNames.itertuples(index=False):\n",
    "                         \n",
    "                                    for r in DF6.itertuples(index=False):\n",
    "                         \n",
    "                                        if str(k[1]) == str(r[2]):\n",
    "                                            try:\n",
    "                         \n",
    "                                                for i in FINAL.columns.tolist():\n",
    "                         \n",
    "                                                    if str(i) == str(r[0]):\n",
    "                         \n",
    "                                                        FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                                            except:\n",
    "                                                    pass\n",
    "                         \n",
    "                            for i in FINAL.columns.tolist():\n",
    "                                for r in DF6.itertuples(index=False):\n",
    "                                    if str(r[2]) == \"nan\" :\n",
    "                                        if str(i) == str(r[0]):\n",
    "                                            FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                            combined_final.append(FINAL)\n",
    "    \n",
    "                        else:\n",
    "                            #This Case works when description is not found\n",
    "                            FINAL=DF_FINAL\n",
    "                            FINAL['id']=k[1]\n",
    "                            FINAL.dropna(how='all', axis=1, inplace=True)\n",
    "                            for i in FINAL.columns:\n",
    "                                x = str(i).lower().strip()\n",
    "                                FINAL=FINAL.rename(columns= {i:x})\n",
    "                         \n",
    "                            for i in FINAL.columns.tolist():\n",
    "                         \n",
    "                                for k in CNames.itertuples(index=False):\n",
    "                         \n",
    "                                    for r in DF6.itertuples(index=False):\n",
    "                         \n",
    "                                        if str(k[1]) == str(r[2]):\n",
    "                                            try:\n",
    "                         \n",
    "                                                for i in FINAL.columns.tolist():\n",
    "                         \n",
    "                                                    if str(i) == str(r[0]):\n",
    "                         \n",
    "                                                        FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                                            except:\n",
    "                                                    pass\n",
    "                         \n",
    "                            for i in FINAL.columns.tolist():\n",
    "                                for r in DF6.itertuples(index=False):\n",
    "                                    if str(r[2]) == \"nan\" :\n",
    "                                        if str(i) == str(r[0]):\n",
    "                                            FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                            combined_final.append(FINAL)\n",
    "    \n",
    "    \n",
    "    \n",
    "                    elif c>=1:\n",
    "                        #This Case works when description is more than 1 row\n",
    "                        #Dropping 'c' rows\n",
    "                        DF_11=DF_FINAL.iloc[c:]\n",
    "                        #row values as column names\n",
    "                        DF_11.columns=DF_11.iloc[0]\n",
    "                        #Dropping the row\n",
    "                        FINAL=DF_11.drop([c])\n",
    "                        FINAL['id']=k[1]\n",
    "                        FINAL.dropna(how='all', axis=1, inplace=True)\n",
    "                        for i in FINAL.columns:\n",
    "                            x = str(i).lower().strip()\n",
    "                            FINAL=FINAL.rename(columns= {i:x})\n",
    "                     \n",
    "                        for i in FINAL.columns.tolist():\n",
    "                     \n",
    "                            for k in CNames.itertuples(index=False):\n",
    "                     \n",
    "                                for r in DF6.itertuples(index=False):\n",
    "                     \n",
    "                                    if str(k[1]) == str(r[2]):\n",
    "                                        try:\n",
    "                     \n",
    "                                            for i in FINAL.columns.tolist():\n",
    "                     \n",
    "                                                if str(i) == str(r[0]):\n",
    "                     \n",
    "                                                    FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                                        except:\n",
    "                                                pass\n",
    "                     \n",
    "                        for i in FINAL.columns.tolist():\n",
    "                            for r in DF6.itertuples(index=False):\n",
    "                                if str(r[2]) == \"nan\" :\n",
    "                                    if str(i) == str(r[0]):\n",
    "                                        FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                        combined_final.append(FINAL)\n",
    "                    else:\n",
    "                        None \n",
    "        \n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass\n",
    "    \n",
    "      \n",
    "        \n",
    "        FINAL = pd.concat(combined_final) \n",
    "        \n",
    "            #Search_List = list(DF8[\"Dropping columns\"])\n",
    "            #dropping columns\n",
    "            #FINAL= FINAL.drop(columns=[col for col in FINAL if col in Search_List])\n",
    "        #Checking the  Inpatient/Outpatient column exists or not\n",
    "        \n",
    "        column_list = ['inpatient-outpatient']\n",
    "        for col in column_list:\n",
    "            if col not in FINAL.columns:\n",
    "                FINAL[col] = ' '\n",
    "        \n",
    "        \n",
    "        #df2=FINAL[FINAL['cpt code'].notnull()] \n",
    "        \n",
    "        df2=FINAL\n",
    "        df2 = df_column_uniquify(df2)\n",
    "        #Required format - variable list\n",
    "        Col_list = list(DF5[\"Columns\"])\n",
    "        df3=df2.melt(id_vars=[col for col in df2 if col in Col_list],var_name=\"name\",value_name='cost')\n",
    "     \n",
    "            \n",
    "        df4=df3\n",
    "        df4=df4[df4['cost'].notnull()]\n",
    "       \n",
    "        #Dropping_columns=['Not offered','Not Contracted','N/A','Not a covered service','Not Offered','Not contracted','Not a covered service','N/A']\n",
    "        #df4 = df4[~df4['Cost'].isin(Dropping_columns)]\n",
    "        df4\n",
    "        Combined_data.append(df4)\n",
    "    Combined_data = pd.concat(Combined_data)\n",
    "            \n",
    "    Combined_data\n",
    "    #Combined_data[\"id\"]=Combined_data.id.astype('int64')\n",
    "    Combined_data.dtypes\n",
    "    \n",
    "    \n",
    "    output_path = r\"C:\\Users\\User\\Zigna AI Corp\\Zigna AI Corp - RightPx\\Hospital Application_2022-03-09\\Automation_task\\outputs\\Wideformat92_{}.csv\"\n",
    "    Combined_data.to_csv(output_path.format((k[1])), index=False)\n",
    "    return Combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "47570fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "################ wideFormat93 ##################\n",
    "def wideFormat93(CNames):\n",
    "    global df7       \n",
    "    Combined_data = []\n",
    "    combined_final = []\n",
    "    non_prep_data = []\n",
    "    #Getting the details as list from files\n",
    "    for k in CNames.itertuples(index=False):\n",
    "        f=k[0] \n",
    "        #Checking the file type- xlsx   \n",
    "        if k[2]== 'csv':\n",
    "            try:\n",
    "                DF_FINAL=pd.read_csv(f)\n",
    "            except:\n",
    "                DF_FINAL=pd.read_csv(f,encoding='latin1')\n",
    "                \n",
    "            non_prep_data.append(DF_FINAL)\n",
    "        \n",
    "        elif k[2]== 'xlsx':\n",
    "            sheet_to = pd.read_excel(f,sheet_name=None,dtype=str,header=None)\n",
    "         \n",
    "            for sh in sheet_to.keys():\n",
    "               \n",
    "                DF_FINAL = pd.read_excel(f,sheet_name=sh,dtype=str)\n",
    "                print(sh)\n",
    "                non_prep_data.append(DF_FINAL)\n",
    "                \n",
    "        for j in df7.itertuples(index=False):\n",
    "            if str(k[1]) == str(j[0]):\n",
    "                s = j[1]\n",
    "                \n",
    "        for DF_FINAL in non_prep_data:\n",
    "            try:\n",
    "                if DF_FINAL.iloc[:, [s]].empty == False:\n",
    "            \n",
    "            #Selecting -6th column from every file\n",
    "                    DF_10=DF_FINAL.iloc[:, [s]]    \n",
    "                    m=0\n",
    "                    c=0\n",
    "                \n",
    "                    #Getting the count of  empty rows\n",
    "                    for index, row in DF_10.iterrows():\n",
    "                        if(pd.notnull(row[0])): \n",
    "                            m=m+1\n",
    "                            break\n",
    "                        else:\n",
    "                            c=c+1\n",
    "                \n",
    "                    if c==0:\n",
    "                    #This Case works when description is in one row\n",
    "                        if \"Unnamed: 5\" in DF_10:\n",
    "                            DF_FINAL.columns=DF_FINAL.iloc[0]\n",
    "                            FINAL=DF_FINAL.drop([c])\n",
    "                            FINAL['id']=k[1]\n",
    "                            FINAL = FINAL.reset_index(drop=True)\n",
    "                            FINAL.dropna(how='all', axis=1, inplace=True)\n",
    "                            try:\n",
    "                                FINAL.drop(['Severity'],axis=1,inplace=True)\n",
    "                            except:\n",
    "                                pass\n",
    "                            #for r in DF6.itertuples(index=False):\n",
    "                            #    FINAL.rename(columns={r[0]:r[1]}, inplace=True)\n",
    "                            for i in FINAL.columns:\n",
    "                                x = str(i).lower().strip()\n",
    "                                FINAL=FINAL.rename(columns= {i:x})\n",
    "                            for i in FINAL.columns.tolist():\n",
    "                         \n",
    "                                for k in CNames.itertuples(index=False):\n",
    "                         \n",
    "                                    for r in DF6.itertuples(index=False):\n",
    "                         \n",
    "                                        if str(k[1]) == str(r[2]):\n",
    "                                            try:\n",
    "                         \n",
    "                                                for i in FINAL.columns.tolist():\n",
    "                         \n",
    "                                                    if str(i) == str(r[0]):\n",
    "                         \n",
    "                                                        FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                                            except:\n",
    "                                                pass\n",
    "                         \n",
    "                            for i in FINAL.columns.tolist():\n",
    "                                for r in DF6.itertuples(index=False):\n",
    "                                    if str(r[2]) == \"nan\" :\n",
    "                         \n",
    "                                        if str(i) == str(r[0]):\n",
    "                                            FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                            combined_final.append(FINAL)\n",
    "                \n",
    "                        else:\n",
    "                            #This Case works when description is not found\n",
    "                            FINAL=DF_FINAL\n",
    "                            FINAL['id']=k[1]\n",
    "                            FINAL = FINAL.reset_index(drop=True)\n",
    "                            FINAL.dropna(how='all', axis=1, inplace=True)\n",
    "                            try:\n",
    "                                FINAL.drop(['Severity'],axis=1,inplace=True)\n",
    "                            except:\n",
    "                                pass\n",
    "                            for i in FINAL.columns:\n",
    "                                x = str(i).lower().strip()\n",
    "                                FINAL=FINAL.rename(columns= {i:x}) \n",
    "                        \n",
    "                            for i in FINAL.columns.tolist():\n",
    "                         \n",
    "                                for k in CNames.itertuples(index=False):\n",
    "                         \n",
    "                                    for r in DF6.itertuples(index=False):\n",
    "                         \n",
    "                                        if str(k[1]) == str(r[2]):\n",
    "                                            try:\n",
    "                         \n",
    "                                                for i in FINAL.columns.tolist():\n",
    "                         \n",
    "                                                    if str(i) == str(r[0]):\n",
    "                         \n",
    "                                                        FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                                            except:\n",
    "                                                pass\n",
    "                         \n",
    "                            for i in FINAL.columns.tolist():\n",
    "                                for r in DF6.itertuples(index=False):\n",
    "                                    if str(r[2]) == \"nan\" :\n",
    "                         \n",
    "                                        if str(i) == str(r[0]):\n",
    "                                            FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                            combined_final.append(FINAL)\n",
    "                 \n",
    "                \n",
    "                \n",
    "                    elif c>=1:\n",
    "                        #This Case works when description is more than 1 row\n",
    "                        #Dropping 'c' rows\n",
    "                        DF_11=DF_FINAL.iloc[c:]\n",
    "                        #row values as column names\n",
    "                        DF_11.columns=DF_11.iloc[0]\n",
    "                        #Dropping the row\n",
    "                        FINAL=DF_11.drop([c])\n",
    "                        FINAL['id']=k[1]\n",
    "                        FINAL = FINAL.reset_index(drop=True)\n",
    "                        FINAL.dropna(how='all', axis=1, inplace=True)\n",
    "                        try:\n",
    "                            FINAL.drop(['Severity'],axis=1,inplace=True)\n",
    "                        except:\n",
    "                            pass\n",
    "                        for i in FINAL.columns:\n",
    "                            x = str(i).lower().strip()\n",
    "                            FINAL=FINAL.rename(columns= {i:x}) \n",
    "                    \n",
    "                        for i in FINAL.columns.tolist():\n",
    "                     \n",
    "                            for k in CNames.itertuples(index=False):\n",
    "                     \n",
    "                                for r in DF6.itertuples(index=False):\n",
    "                     \n",
    "                                    if str(k[1]) == str(r[2]):\n",
    "                                        try:\n",
    "                     \n",
    "                                            for i in FINAL.columns.tolist():\n",
    "                     \n",
    "                                                if str(i) == str(r[0]):\n",
    "                     \n",
    "                                                    FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                                        except:\n",
    "                                            pass\n",
    "                     \n",
    "                        for i in FINAL.columns.tolist():\n",
    "                            for r in DF6.itertuples(index=False):\n",
    "                                if str(r[2]) == \"nan\" :\n",
    "                     \n",
    "                                    if str(i) == str(r[0]):\n",
    "                                        FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                        combined_final.append(FINAL)\n",
    "                    else:\n",
    "                        None \n",
    "                             \n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass\n",
    "    \n",
    "    \n",
    "        FINAL = pd.concat(combined_final)\n",
    "        for i in FINAL.columns:\n",
    "           x = str(i).lower().strip()\n",
    "           FINAL=FINAL.rename(columns= {i:x}) \n",
    "    \n",
    "        for i in FINAL.columns.tolist():\n",
    "     \n",
    "            for k in CNames.itertuples(index=False):\n",
    "     \n",
    "                for r in DF6.itertuples(index=False):\n",
    "     \n",
    "                    if str(k[1]) == str(r[2]):\n",
    "                        try:\n",
    "     \n",
    "                            for i in FINAL.columns.tolist():\n",
    "     \n",
    "                                if str(i) == str(r[0]):\n",
    "     \n",
    "                                    FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                        except:\n",
    "                            pass\n",
    "     \n",
    "        for i in FINAL.columns.tolist():\n",
    "            for r in DF6.itertuples(index=False):\n",
    "                if str(r[2]) == \"nan\" :\n",
    "     \n",
    "                    if str(i) == str(r[0]):\n",
    "                        FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "         \n",
    "        Search_List = list(DF8[\"Dropping columns\"])\n",
    "             #dropping columns\n",
    "    \n",
    "        FINAL= FINAL.drop(columns=[col for col in FINAL if col in Search_List])\n",
    "        \n",
    "    \n",
    "      \n",
    "    \n",
    "        #Checking the  Inpatient/Outpatient column exists or not\n",
    "        column_list = ['inpatient-outpatient']\n",
    "        for col in column_list:\n",
    "            if col not in FINAL.columns:\n",
    "                FINAL[col] = ' '\n",
    "    \n",
    "        \n",
    "        df2=FINAL\n",
    "        df2 = df_column_uniquify(df2)\n",
    "        #Required format - variable list\n",
    "        Col_list = list(DF5[\"Columns\"])\n",
    "        df3=df2.melt(id_vars=[col for col in df2 if col in Col_list],var_name=\"name\",value_name='cost')\n",
    "        \n",
    "            \n",
    "        df4=df3\n",
    "        df4=df4[df4['cost'].notnull()]\n",
    "       \n",
    "        \n",
    "        df4\n",
    "        Combined_data.append(df4)\n",
    "    Combined_data = pd.concat(Combined_data)\n",
    "            \n",
    "    Combined_data\n",
    "    output_path = r\"C:\\Users\\User\\Zigna AI Corp\\Zigna AI Corp - RightPx\\Hospital Application_2022-03-09\\Automation_task\\outputs\\Wideformat93_{}.csv\"\n",
    "    Combined_data.to_csv(output_path.format((k[1])), index=False)\n",
    "    return Combined_data\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4409cfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "################### wideFormat97 #####################\n",
    "def wideFormat97(CNames):\n",
    "    global df7\n",
    "    \n",
    "    Combined_data = []\n",
    "    combined_final = []\n",
    "    non_prep_data = []\n",
    "\n",
    "    def similar(x1, x2):\n",
    "        return SequenceMatcher(None, x1, x2).ratio()\n",
    "    for k in CNames.itertuples(index=False):\n",
    "        f=k[0] \n",
    "\n",
    "        #Checking the file type- xlsx   \n",
    "        if k[2]== 'csv':\n",
    "            try:\n",
    "                DF_FINAL=pd.read_csv(f)\n",
    "            except:\n",
    "                DF_FINAL=pd.read_csv(f,encoding='latin1')\n",
    "\n",
    "            non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        elif k[2]== 'xlsx':\n",
    "            sheet_to = pd.read_excel(f, sheet_name = None,dtype=str)\n",
    "            for sh in sheet_to.keys():\n",
    "\n",
    "                    if len(set(sh.lower().split()) & set(f.lower().split())) != 0:\n",
    "                        DF_FINAL=pd.read_excel(f,sheet_name= sh)\n",
    "                        print(sh)\n",
    "                    else:\n",
    "                        lis = []\n",
    "                        for i in set(f.lower().split()):\n",
    "                            for j in set(sh.lower().split()):\n",
    "                                lis.append(similar(i,j))\n",
    "                                for p in lis:\n",
    "                                    if p >= 0.9:\n",
    "                                        DF_FINAL=pd.read_excel(f,sheet_name= sh)\n",
    "                                        print(DF_FINAL)\n",
    "                                        break\n",
    "                                    else:\n",
    "                                        pass\n",
    "            non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        for j in df7.itertuples(index=False):\n",
    "            if str(k[1]) == str(j[0]):\n",
    "                s = j[1]\n",
    "\n",
    "        for DF_FINAL in non_prep_data:\n",
    "            try:\n",
    "                if DF_FINAL.iloc[:, [s]].empty == False:\n",
    "                    DF_10=DF_FINAL.iloc[:, [s]]    \n",
    "                    m=0\n",
    "                    c=0\n",
    "\n",
    "                    #Getting the count of  empty rows..3\n",
    "                    for index, row in DF_10.iterrows():\n",
    "                        if(pd.notnull(row[0])): \n",
    "                            m=m+1\n",
    "                            break\n",
    "                        else:\n",
    "                            c=c+1\n",
    "\n",
    "                    if c==0:\n",
    "                    #This Case works when description is in one row\n",
    "                        if \"Unnamed: 0\" in DF_10:\n",
    "                            DF_FINAL.columns=DF_FINAL.iloc[0]\n",
    "                            FINAL=DF_FINAL.drop([c])\n",
    "                            FINAL['id']=k[1]\n",
    "                            FINAL\n",
    "                        else:\n",
    "                            #This Case works when description is not found\n",
    "                            FINAL=DF_FINAL\n",
    "                            FINAL['id']=k[1]\n",
    "                            FINAL\n",
    "\n",
    "                    elif c>=1:\n",
    "                        #This Case works when description is more than 1 row\n",
    "                        #Dropping 'c' rows\n",
    "                        DF_11=DF_FINAL.iloc[c:]\n",
    "                        #row values as column names\n",
    "                        DF_11.columns=DF_11.iloc[0]\n",
    "                        #Dropping the row\n",
    "                        FINAL=DF_11.drop([c])\n",
    "                        FINAL['id']=k[1]\n",
    "\n",
    "                    else:\n",
    "                        None \n",
    "\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass\n",
    "        FINAL = FINAL.loc[:, FINAL.columns.notnull()]    \n",
    "        # FINAL['sheet_name'] = sh\n",
    "        try:\n",
    "            FINAL['Shoppable Service'].fillna(method='ffill', inplace=True)\n",
    "        except:\n",
    "            pass\n",
    "        for i in FINAL.columns:\n",
    "            x = str(i).lower().strip()\n",
    "            FINAL=FINAL.rename(columns= {i:x})    \n",
    "\n",
    "\n",
    "        for i in FINAL.columns.tolist():\n",
    "\n",
    "            for k in CNames.itertuples(index=False):\n",
    "\n",
    "                for r in DF6.itertuples(index=False):\n",
    "\n",
    "                    if str(k[1]) == str(r[2]):\n",
    "                        try:\n",
    "\n",
    "                            for i in FINAL.columns.tolist():\n",
    "\n",
    "                                if str(i) == str(r[0]):\n",
    "\n",
    "                                    FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                        except:\n",
    "                            pass\n",
    "\n",
    "        for i in FINAL.columns.tolist():\n",
    "\n",
    "\n",
    "            for r in DF6.itertuples(index=False):\n",
    "\n",
    "\n",
    "\n",
    "                if str(r[2]) == \"nan\" :\n",
    "\n",
    "                    if str(i) == str(r[0]):\n",
    "                        FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "        Search_List = list(DF8[\"Dropping columns\"])\n",
    "        #dropping columns\n",
    "        FINAL= FINAL.drop(columns=[col for col in FINAL if col  in Search_List])\n",
    "\n",
    "\n",
    "        column_list = ['inpatient-outpatient']\n",
    "        for col in column_list:\n",
    "            if col not in FINAL.columns:\n",
    "                FINAL[col] = ' '\n",
    "\n",
    "\n",
    "        df2=FINAL\n",
    "        df2 = df_column_uniquify(df2)\n",
    "        #Required format - variable list\n",
    "        Col_list = list(DF5[\"Columns\"])\n",
    "        df3=df2.melt(id_vars=[col for col in df2 if col in Col_list],var_name=\"name\",value_name='cost')\n",
    "\n",
    "\n",
    "        df4=df3\n",
    "        df4=df4[df4['cost'].notnull()]\n",
    "        #Dropping_columns=['Not offered','Not Contracted','N/A','Not a covered service','Not Offered','Not contracted','Not a covered service','N/A']\n",
    "        #df4 = df4[~df4['Cost'].isin(Dropping_columns)]\n",
    "        df4\n",
    "        Combined_data.append(df4)\n",
    "    Combined_data = pd.concat(Combined_data)\n",
    "\n",
    "    Combined_data\n",
    "    #Combined_data[\"id\"]=Combined_data.id.astype('int64')\n",
    "    #Combined_data.dtypes\n",
    "    Sample_output = Combined_data\n",
    "\n",
    "    output_path = r\"C:\\Users\\User\\Zigna AI Corp\\Zigna AI Corp - RightPx\\Hospital Application_2022-03-09\\Automation_task\\outputs\\Wideformat97_{}.csv\"\n",
    "    Sample_output.to_csv(output_path.format(k[1]), index=False)\n",
    "    return Sample_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0768ca81",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### wideFormat98 ###################\n",
    "def wideFormat98(CNames):\n",
    "    global df7      \n",
    "    Combined_data = []\n",
    "    combined_final = []\n",
    "    non_prep_data = []\n",
    "    #Getting the details as list from files\n",
    "    for k in CNames.itertuples(index=False):\n",
    "        f=k[0] \n",
    "        #Checking the file type- xlsx   \n",
    "        if k[2]== 'csv':\n",
    "            try:\n",
    "                DF_FINAL=pd.read_csv(f)\n",
    "            except:\n",
    "                DF_FINAL=pd.read_csv(f,encoding='latin1')\n",
    "                \n",
    "            non_prep_data.append(DF_FINAL)\n",
    "        \n",
    "        elif k[2]== 'xlsx':\n",
    "            sheet_to = pd.read_excel(f,sheet_name=None,dtype=str,header=None)\n",
    "         \n",
    "            for sh in sheet_to.keys():\n",
    "               \n",
    "                DF_FINAL = pd.read_excel(f,sheet_name=sh,dtype=str)\n",
    "                print(sh)\n",
    "                non_prep_data.append(DF_FINAL)\n",
    "                \n",
    "        for j in df7.itertuples(index=False):\n",
    "            if str(k[1]) == str(j[0]):\n",
    "                s = j[1]\n",
    "                \n",
    "        for DF_FINAL in non_prep_data:\n",
    "            try:\n",
    "                if DF_FINAL.iloc[:, [s]].empty == False:\n",
    "                    DF_FINAL[:1] = DF_FINAL[:1].fillna(method='ffill', axis=1)\n",
    "                    DF_FINAL[:2] = DF_FINAL[:2].fillna(' ')\n",
    "                    DF_FINAL.columns = (DF_FINAL.iloc[0] + ' ' + DF_FINAL.iloc[1])\n",
    "                    DF_FINAL = DF_FINAL.iloc[2:]\n",
    "    \n",
    "                    FINAL = DF_FINAL.reset_index(drop=True)\n",
    "    \n",
    "                    FINAL['id']=k[1]  \n",
    "                    DF_10=DF_FINAL.iloc[:, [s]]    \n",
    "                    m=0\n",
    "                    c=0\n",
    "                    \n",
    "                    #Getting the count of  empty rows\n",
    "                    for index, row in DF_10.iterrows():\n",
    "                        if(pd.notnull(row[0])): \n",
    "                            m=m+1\n",
    "                            break\n",
    "                        else:\n",
    "                            c=c+1\n",
    "                            \n",
    "                    if c==0:\n",
    "                    #This Case works when description is in one row\n",
    "                        if \"Unnamed: 1\" in DF_10:\n",
    "                            DF_FINAL=DF_FINAL.iloc[0]\n",
    "                            FINAL=DF_FINAL.drop([c])\n",
    "                            FINAL['id']=k[1]\n",
    "                            FINAL\n",
    "                        else:\n",
    "                            #This Case works when description is not found\n",
    "                            FINAL=DF_FINAL\n",
    "                            FINAL['id']=k[1]\n",
    "                            FINAL\n",
    "                            \n",
    "                    elif c>=1:\n",
    "                            #This Case works when description is more than 1 row\n",
    "                            #Dropping 'c' rows\n",
    "                            DF_11=DF_FINAL.iloc[c:]\n",
    "                            #row values as column names\n",
    "                            DF_11.columns=DF_11.iloc[0]\n",
    "                            #Dropping the row\n",
    "                            FINAL=DF_11.drop([c])\n",
    "                            FINAL['id']=k[1]\n",
    "                    else:\n",
    "                        None \n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass\n",
    "    \n",
    "    \n",
    "        for i in FINAL.columns:\n",
    "            x = str(i).lower().strip()\n",
    "            FINAL=FINAL.rename(columns= {i:x}) \n",
    "    \n",
    "        for i in FINAL.columns.tolist():\n",
    "    \n",
    "            for k in CNames.itertuples(index=False):\n",
    "    \n",
    "                for r in DF6.itertuples(index=False):\n",
    "    \n",
    "                    if str(k[1]) == str(r[2]):\n",
    "                        try:\n",
    "    \n",
    "                            for i in FINAL.columns.tolist():\n",
    "    \n",
    "                                if str(i) == str(r[0]):\n",
    "    \n",
    "                                    FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                        except:\n",
    "                            pass\n",
    "    \n",
    "        for i in FINAL.columns.tolist():\n",
    "            for r in DF6.itertuples(index=False):\n",
    "                if str(r[2]) == \"nan\" :\n",
    "    \n",
    "                    if str(i) == str(r[0]):\n",
    "                        FINAL.rename(columns={i:r[1]}, inplace=True)   \n",
    "        \n",
    "        Search_List = list(DF8[\"Dropping columns\"])\n",
    "        #dropping columns\n",
    "        FINAL= FINAL.drop(columns=[col for col in FINAL if col  in Search_List])\n",
    "        \n",
    "        # for i in FINAL.columns.tolist():\n",
    "        #     for r in DF6.itertuples(index=False):\n",
    "        #         if str(i) == str(r[0]):\n",
    "        #             FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "        #Checking the  Inpatient/Outpatient column exists or not\n",
    "        column_list = ['inpatient-outpatient']\n",
    "        for col in column_list:\n",
    "            if col not in FINAL.columns:\n",
    "                FINAL[col] = ' '\n",
    "        \n",
    "    \n",
    "        df2=FINAL\n",
    "        df2 = df_column_uniquify(df2)\n",
    "        #Required format - variable list\n",
    "        Col_list = list(DF5[\"Columns\"])\n",
    "        df3=df2.melt(id_vars=[col for col in df2 if col in Col_list],var_name=\"name\",value_name='cost')\n",
    "        #df3=df1.melt(id_vars=['ID','Description','Cpt Code','Rev_Cd','Units'],var_name=\"Name\",value_name='Cost')\n",
    "            \n",
    "        df4=df3\n",
    "        df4=df4[df4['cost'].notnull()]\n",
    "        #Dropping_columns=['Not offered','Not Contracted','N/A','Not a covered service','Not Offered','Not contracted','Not a covered service','N/A']\n",
    "        #df4 = df4[~df4['Cost'].isin(Dropping_columns)]\n",
    "        df4\n",
    "        Combined_data.append(df4)\n",
    "    Combined_data = pd.concat(Combined_data)\n",
    "            \n",
    "    Combined_data\n",
    "    #Combined_data[\"id\"]=Combined_data.id.astype('int64')\n",
    "    #Combined_data.dtypes\n",
    "    Combined_data\n",
    "    output_path = r\"C:\\Users\\User\\Zigna AI Corp\\Zigna AI Corp - RightPx\\Hospital Application_2022-03-09\\Automation_task\\outputs\\Wideformat98_{}.csv\"\n",
    "    Combined_data.to_csv(output_path.format((k[1])), index=False)\n",
    "    return Combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4136e473",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### wideFormat13_1 ####################\n",
    "def wideFormat13_1(CNames):\n",
    "    global df7\n",
    "    \n",
    "    Combined_data = []\n",
    "    combined_final = []\n",
    "    non_prep_data = []\n",
    "    #Getting the details as list from files\n",
    "    for k in CNames.itertuples(index=False):\n",
    "        f=k[0] \n",
    "        #Checking the file type- xlsx   \n",
    "        if k[2]== 'csv':\n",
    "            try:\n",
    "                DF_FINAL=pd.read_csv(f)\n",
    "            except:\n",
    "                DF_FINAL=pd.read_csv(f,encoding='latin1')\n",
    "\n",
    "            non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        elif k[2]== 'xlsx':\n",
    "            sheet_to = pd.read_excel(f,sheet_name=None,dtype=str,header=None)\n",
    "\n",
    "            for sh in sheet_to.keys():\n",
    "\n",
    "                DF_FINAL = pd.read_excel(f,sheet_name=sh,dtype=str)\n",
    "                print(sh)\n",
    "                non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        for j in df7.itertuples(index=False):\n",
    "            if str(k[1]) == str(j[0]):\n",
    "                s = j[1]\n",
    "\n",
    "        for DF_FINAL in non_prep_data:\n",
    "            try:\n",
    "                if DF_FINAL.iloc[:, [s]].empty == False:\n",
    "                    DF_10=DF_FINAL.iloc[:, [s]]    \n",
    "                    m=0\n",
    "                    c=0\n",
    "\n",
    "                    #Getting the count of  empty rows\n",
    "                    for index, row in DF_10.iterrows():\n",
    "                        if(pd.notnull(row[0])): \n",
    "                            m=m+1\n",
    "                            break\n",
    "                        else:\n",
    "                            c=c+1\n",
    "\n",
    "                    if c==0:\n",
    "                    #This Case works when description is in one row\n",
    "                        if \"Unnamed: 5\" in DF_10:\n",
    "                            DF_FINAL.columns=DF_FINAL.iloc[0]\n",
    "                            FINAL=DF_FINAL.drop([c])\n",
    "                            FINAL['id']=k[1]\n",
    "                            FINAL\n",
    "                        else:\n",
    "                            #This Case works when description is not found\n",
    "                            FINAL=DF_FINAL\n",
    "                            FINAL['id']=k[1]\n",
    "                            FINAL\n",
    "\n",
    "                    elif c>=1:\n",
    "                        #This Case works when description is more than 1 row\n",
    "                        #Dropping 'c' rows\n",
    "                        DF_11=DF_FINAL.iloc[c:]\n",
    "                        #row values as column names\n",
    "                        DF_11.columns=DF_11.iloc[0]\n",
    "                        #Dropping the row\n",
    "                        FINAL=DF_11.drop([c])\n",
    "                        FINAL['id']=k[1]\n",
    "                        FINAL\n",
    "                    else:\n",
    "                        None\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass\n",
    "        try:\n",
    "            FINAL = pd.concat(combined_final)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "        FINAL = FINAL.loc[:, FINAL.columns.notnull()]\n",
    "\n",
    "\n",
    "        try:\n",
    "            for col in FINAL.columns:\n",
    "                if col =='unnamed: 0':\n",
    "                    FINAL=FINAL.drop([\"unnamed: 0\"],axis=1)\n",
    "                else:\n",
    "                       None\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        for i in FINAL.columns:\n",
    "            x = str(i).lower().strip()\n",
    "            FINAL=FINAL.rename(columns= {i:x})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        for k in CNames.itertuples(index=False):\n",
    "            for r in DF6.itertuples(index=False):\n",
    "                if str(k[1]) == str(r[2]):\n",
    "                    try:\n",
    "                        for i in FINAL.columns.tolist():\n",
    "                            if str(i) == str(r[0]):\n",
    "                                FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                    except:\n",
    "                        pass\n",
    "        for i in FINAL.columns.tolist():\n",
    "\n",
    "            for r in DF6.itertuples(index=False):\n",
    "\n",
    "\n",
    "\n",
    "                if str(r[2]) == \"nan\" :\n",
    "\n",
    "                    if str(i) == str(r[0]):\n",
    "                        FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "\n",
    "        Search_List = list(DF8[\"Dropping columns\"])\n",
    "        # Combining the payer, benfit and name columns. then we are dropping the unwanted  columns.\n",
    "\n",
    "        FINAL= FINAL.drop(columns=[col for col in FINAL if col in Search_List])\n",
    "        #Checking the  Inpatient/Outpatient column exists or not\n",
    "        column_list = ['inpatient_outpatient']\n",
    "        for col in column_list:\n",
    "            if col not in FINAL.columns:\n",
    "                FINAL[col] = ' '   \n",
    "\n",
    "\n",
    "        new = FINAL['description'].str.split(\" \",n=2,expand=True)\n",
    "        # new = FINAL['description'].str.split(\" \",n=2,expand=True)\n",
    "\n",
    "        FINAL['Cpt Code'] = new[0]\n",
    "        FINAL['HCPCS Code'] = new[1]\n",
    "\n",
    "        FINAL['HCPCS Code'] = FINAL['HCPCS Code'].astype(str)\n",
    "\n",
    "        FINAL[\"Cpt Code\"] = np.where(FINAL['Cpt Code'].str.endswith('-') , FINAL['Cpt Code'].replace('-','', regex=True),FINAL['Cpt Code'])\n",
    "        FINAL['Cpt Code'] = FINAL['Cpt Code'].str.strip()\n",
    "\n",
    "        column_list = ['Cpt Code1','HCPCS Code1']\n",
    "        for col in column_list:\n",
    "            if col not in FINAL.columns:\n",
    "                FINAL[col] = ' '  \n",
    "\n",
    "\n",
    "        FINAL['Cpt Code1'] = pd.to_numeric(FINAL['Cpt Code'],errors=\"coerce\")\n",
    "        FINAL['HCPCS Code1'] = pd.to_numeric(FINAL['HCPCS Code'],errors=\"coerce\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        for index, row in FINAL.iterrows():\n",
    "            if re.findall(r'^[A-Z]{1}[0-9]{4}',FINAL['Cpt Code'][index]):\n",
    "                FINAL['Cpt Code1'][index] = FINAL['Cpt Code'][index]\n",
    "            else:\n",
    "                FINAL['Cpt Code1'][index] = FINAL['Cpt Code1'][index] \n",
    "        for index, row in FINAL.iterrows():\n",
    "            if re.findall(r'^[A-Z]{1}[0-9]{4}',FINAL['HCPCS Code'][index]):\n",
    "                FINAL['HCPCS Code1'][index] = FINAL['HCPCS Code'][index]\n",
    "            else:\n",
    "                FINAL['HCPCS Code1'][index] = FINAL['HCPCS Code1'][index]         \n",
    "        for index, row in FINAL.iterrows():\n",
    "            if re.findall(r'^[0-9]{5}',FINAL['Cpt Code'][index]):\n",
    "                FINAL['Cpt Code1'][index] = FINAL['Cpt Code'].str[:5][index]\n",
    "            else:\n",
    "                FINAL['Cpt Code1'][index] = FINAL['Cpt Code1'][index]\n",
    "\n",
    "\n",
    "        FINAL['Cpt Code1'] = FINAL['Cpt Code1'].astype(str)\n",
    "        FINAL['HCPCS Code1'] = FINAL['HCPCS Code1'].astype(str)\n",
    "        FINAL['Cpt Code1']=FINAL['Cpt Code1'].replace('\\.0', '', regex=True)\n",
    "        FINAL['HCPCS Code1'] = FINAL['HCPCS Code1'].replace('\\.0', '', regex=True)\n",
    "        FINAL.drop([\"Cpt Code\"], axis = 1, inplace = True)\n",
    "        FINAL.drop([\"HCPCS Code\"], axis = 1, inplace = True)\n",
    "        FINAL=FINAL.rename(columns = {'Cpt Code1': \"CPT\"})\n",
    "        FINAL=FINAL.rename(columns = {'HCPCS Code1': \"HCPCS\"})\n",
    "\n",
    "        # FINAL['CPT'] = FINAL['CPT'].astype(str)\n",
    "        # FINAL['CPT'].fillna(\" \", inplace=True)\n",
    "        FINAL['CPT'] = FINAL['CPT'].replace(r'nan',\"\")\n",
    "        FINAL['HCPCS'] = FINAL['HCPCS'].replace(r'nan',\"\")\n",
    "\n",
    "\n",
    "\n",
    "        # FINAL['HCPCS'].fillna(\" \", inplace=True)\n",
    "        FINAL['cpt_hcpcs'] = FINAL['CPT'] + FINAL['HCPCS']\n",
    "        FINAL.drop([\"CPT\"], axis = 1, inplace = True)\n",
    "        FINAL.drop([\"HCPCS\"], axis = 1, inplace = True)\n",
    "        # FINAL[\"CPT/HCPCS\"].replace(\" \",np.nan,inplace=True)\n",
    "        FINAL=FINAL[FINAL['cpt_hcpcs'].notnull()]\n",
    "\n",
    "        FINAL['cpt_hcpcs'] = FINAL['cpt_hcpcs'].astype(str)\n",
    "\n",
    "\n",
    "        df2=FINAL\n",
    "        df2 = df_column_uniquify(df2)\n",
    "        #Required format - variable list\n",
    "        Col_list = list(DF5[\"Columns\"])\n",
    "        df3=df2.melt(id_vars=[col for col in df2 if col in Col_list],var_name=\"name\",value_name='cost')\n",
    "        #df3=df1.melt(id_vars=['ID','Description','Cpt Code','Rev_Cd','Units'],var_name=\"Name\",value_name='Cost')\n",
    "\n",
    "\n",
    "\n",
    "        df4=df3\n",
    "        df4=df4[df4['cost'].notnull()]\n",
    "        df4=df4[df4['name'].notnull()]\n",
    "        #Dropping_columns=['Not offered','Not Contracted','N/A','Not a covered service','Not Offered','Not contracted','Not a covered service','N/A']\n",
    "        #df4 = df4[~df4['Cost'].isin(Dropping_columns)]\n",
    "        df4\n",
    "        Combined_data.append(df4)\n",
    "    Combined_data = pd.concat(Combined_data)\n",
    "\n",
    "    Combined_data\n",
    "    Combined_data.drop_duplicates()\n",
    "    #Combined_data[\"id\"]=Combined_data.id.astype('int64')\n",
    "    #Combined_data.dtypes\n",
    "\n",
    "    #Joining both hospital data with shoppable data by ID\n",
    "    #Sample_output=pd.merge(left=DHC_Hosp_data1, right=Combined_data,how='inner',left_on=['Hospital_Id'],right_on=['id'])\n",
    "    Sample_output = Combined_data\n",
    "    #Dropping the columns\n",
    "    #Sample_output.drop([\"id\"], axis = 1, inplace = True)\n",
    "    #Sample_output['inpatient-outpatient'] = np.where((Sample_output['inpatient-outpatient'] ==' ') & (Sample_output['name'].str.contains('inpatient/outpatient/drug')) , 'IP/OP', Sample_output['inpatient-outpatient'])\n",
    "    #Sample_output['inpatient-outpatient'] = np.where((Sample_output['inpatient-outpatient'] ==' ') & (Sample_output['name'].str.contains('inpatient/outpatient/drug')) , 'IP/OP', Sample_output['inpatient-outpatient'])\n",
    "    # Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains('ip & op')) , 'IP & OP', Sample_output['inpatient_outpatient'])\n",
    "    # Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains('ip & op')) , 'IP & OP', Sample_output['inpatient_outpatient'])\n",
    "    # Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains('ip/op')) , 'Inpatient', Sample_output['inpatient_outpatient'])\n",
    "    # Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains('ip/op')) , 'Outpatient', Sample_output['inpatient_outpatient'])\n",
    "    # Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains('inpatient')) , 'Inpatient', Sample_output['inpatient_outpatient'])\n",
    "    # Sample_output['inpatient_outpatient'] = np.where((Sample_output['inpatient_outpatient'] ==' ') & (Sample_output['name'].str.contains('outpatient')) , 'Outpatient', Sample_output['inpatient_outpatient'])\n",
    "    # #Sample_output['inpatient-outpatient'] = np.where((Sample_output['inpatient-outpatient'] ==' ') & (Sample_output['name'].str.contains('ip')) , 'Inpatient', Sampl\n",
    "\n",
    "\n",
    "    output_path = r\"C:\\Users\\User\\Zigna AI Corp\\Zigna AI Corp - RightPx\\Hospital Application_2022-03-09\\Automation_task\\outputs\\Wideformat13_1_{}.csv\"\n",
    "    Sample_output.to_csv(output_path.format((k[1])), index=False)\n",
    "    return Sample_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eeccbee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### wideFormat101 ##################\n",
    "def wideFormat101(CNames):\n",
    "    global df7\n",
    "    \n",
    "    Combined_data = []\n",
    "    combined_final = []\n",
    "    non_prep_data = []\n",
    "\n",
    "\n",
    "    #Getting the details as list from files\n",
    "    for k in CNames.itertuples(index=False):\n",
    "        f=k[0] \n",
    "        #Checking the file type- xlsx   \n",
    "        if k[2]== 'csv':\n",
    "            try:\n",
    "                DF_FINAL=pd.read_csv(f)\n",
    "            except:\n",
    "                DF_FINAL=pd.read_csv(f,encoding='latin1')\n",
    "\n",
    "            non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        elif k[2]== 'xlsx':\n",
    "            sheet_to = pd.read_excel(f,sheet_name=None,dtype=str,header=None)\n",
    "\n",
    "            for sh in sheet_to.keys():           \n",
    "                DF_FINAL = pd.read_excel(f,sheet_name=sh,dtype=str,header=None)\n",
    "                DF_FINAL[:1] = DF_FINAL[:1].fillna('')\n",
    "                DF_FINAL[:2] = DF_FINAL[:2].fillna(method='ffill', axis=1)\n",
    "                DF_FINAL[:2] = DF_FINAL[:2].fillna('')\n",
    "                DF_FINAL.columns = (DF_FINAL.iloc[0] + ' ' +DF_FINAL.iloc[1])\n",
    "                DF_FINAL = DF_FINAL.iloc[2:]\n",
    "\n",
    "                print(sh)\n",
    "                non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        for j in df7.itertuples(index=False):\n",
    "            if str(k[1]) == str(j[0]):\n",
    "                s = j[1]\n",
    "\n",
    "        for DF_FINAL in non_prep_data:\n",
    "            try:\n",
    "                if DF_FINAL.iloc[:, [s]].empty == False:\n",
    "\n",
    "\n",
    "                    DF_10 = DF_FINAL.iloc[:,[s]]\n",
    "                    m=0\n",
    "                    c=0\n",
    "\n",
    "                    #Getting the count of  empty rows\n",
    "                    for index, row in DF_10.iterrows():\n",
    "                        if(pd.notnull(row[0])): \n",
    "                            m=m+1\n",
    "                            break\n",
    "                        else:\n",
    "                            c=c+1\n",
    "\n",
    "                    if c==0:\n",
    "                    #This Case works when description is in one row\n",
    "                        if \"Unnamed: 5\" in DF_10:\n",
    "                            DF_FINAL.columns=DF_FINAL.iloc[0]\n",
    "                            FINAL=DF_FINAL.drop([c])\n",
    "                            FINAL['id']=k[1]\n",
    "                            FINAL\n",
    "                        else:\n",
    "                            #This Case works when description is not found\n",
    "                            FINAL=DF_FINAL\n",
    "                            FINAL['id']=k[1]\n",
    "                            FINAL\n",
    "\n",
    "                    elif c>=1:\n",
    "                        #This Case works when description is more than 1 row\n",
    "                        #Dropping 'c' rows\n",
    "                        DF_11=DF_FINAL.iloc[c:]\n",
    "                        #row values as column names\n",
    "                        DF_11.columns=DF_11.iloc[0]\n",
    "                        #Dropping the row\n",
    "                        FINAL=DF_11.drop([c])\n",
    "                        FINAL['id']=k[1]\n",
    "                    else:\n",
    "                        None \n",
    "\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass\n",
    "\n",
    "        for i in FINAL.columns:    \n",
    "            x = str(i).lower().strip()\n",
    "            FINAL=FINAL.rename(columns= {i:x})\n",
    "\n",
    "        for i in FINAL.columns.tolist():\n",
    "\n",
    "            for k in CNames.itertuples(index=False):\n",
    "\n",
    "                for r in DF6.itertuples(index=False):\n",
    "\n",
    "                    if str(k[1]) == str(r[2]):\n",
    "                        try:\n",
    "\n",
    "                            for i in FINAL.columns.tolist():\n",
    "\n",
    "                                if str(i) == str(r[0]):\n",
    "\n",
    "                                    FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                        except:\n",
    "                                pass\n",
    "\n",
    "        for i in FINAL.columns.tolist():\n",
    "            for r in DF6.itertuples(index=False):\n",
    "                if str(r[2]) == \"nan\" :\n",
    "                    if str(i) == str(r[0]):\n",
    "                        FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "\n",
    "        column_list = ['inpatient-outpatient']\n",
    "        for col in column_list:\n",
    "            if col not in FINAL.columns:\n",
    "                FINAL[col] = ' '\n",
    "\n",
    "        FINAL['description'] = np.where((FINAL['CPT/DRG'].notnull())&(FINAL['description'].isnull()),\"NA\",FINAL['description'])\n",
    "\n",
    "        FINAL['CPT/DRG'].fillna(method='ffill', inplace=True)\n",
    "        #FINAL=FINAL[FINAL['DETAIL '].notnull()]\n",
    "        FINAL[\"LineItem_cnt\"] = FINAL.groupby(\"CPT/DRG\")[\"CPT/DRG\"].transform('count')\n",
    "        FINAL[\"LineItem_cnt\"]=FINAL[\"LineItem_cnt\"]-1\n",
    "\n",
    "        FINAL=FINAL[(FINAL[\"LineItem_cnt\"] ==0) | ((FINAL[\"LineItem_cnt\"] >=1))] #& (FINAL[\"DETAIL \"].str.contains(\"\",case=False))) ]\n",
    "\n",
    "        Search_List = list(DF8[\"Dropping columns\"])\n",
    "        #dropping columns\n",
    "        FINAL= FINAL.drop(columns=[col for col in FINAL if col in Search_List])\n",
    "\n",
    "        FINAL = FINAL[pd.notnull(FINAL['Shoppable Service Category'])]\n",
    "\n",
    "        df2=FINAL\n",
    "        df2 = df_column_uniquify(df2)\n",
    "        #Required format - variable list\n",
    "        Col_list = list(DF5[\"Columns\"])\n",
    "        df3=df2.melt(id_vars=[col for col in df2 if col in Col_list],var_name=\"name\",value_name='cost')\n",
    "        #df3=df1.melt(id_vars=['ID','Description','Cpt Code','Rev_Cd','Units'],var_name=\"Name\",value_name='Cost')\n",
    "\n",
    "        #df3['payer'] = None\n",
    "        #df3['insurance Type'] = None\n",
    "        #df3['Benefit Type']=None\n",
    "\n",
    "        #Name_List = list(DF1[\"Payers\"])\n",
    "\n",
    "        #Name_List1 = list(DF2[\"Insurance Type\"])\n",
    "\n",
    "        #Name_List2 = list(DF3[\"Benefit Type\"])\n",
    "\n",
    "        #Finding Payers from the list\n",
    "        #for i in Name_List:\n",
    "        #    df3['payer'][(df3['name'].str.contains(i,case=False,na=False))] = i\n",
    "        #Finding Insurancetype from the list    \n",
    "        #for j in Name_List1:\n",
    "        #    df3['insurance Type'][(df3['name'].str.contains(j,case=False,na=False))] = j\n",
    "\n",
    "        #Finding Benefit Type from the list  \n",
    "        #for k in Name_List2:\n",
    "        #    df3['Benefit Type'][(df3['name'].str.contains(k,case=False,na=False))] = k \n",
    "\n",
    "        df4=df3\n",
    "        df4=df4[df4['cost'].notnull()]\n",
    "        #Dropping_columns=['Not offered','Not Contracted','N/A','Not a covered service','Not Offered','Not contracted','Not a covered service','N/A']\n",
    "        #df4 = df4[~df4['Cost'].isin(Dropping_columns)]\n",
    "        df4\n",
    "        Combined_data.append(df4)\n",
    "    Combined_data = pd.concat(Combined_data)\n",
    "\n",
    "    Combined_data\n",
    "    \n",
    "\n",
    "    Combined_data = Combined_data.drop_duplicates()\n",
    "    try:\n",
    "\n",
    "        Combined_data['inpatient-outpatient'] = np.where((Combined_data['inpatient-outpatient'] ==' ') & (Combined_data['name'].str.contains(' ip')) , 'Inpatient', Combined_data['inpatient-outpatient'])\n",
    "        Combined_data['inpatient-outpatient'] = np.where((Combined_data['inpatient-outpatient'] ==' ') & (Combined_data['name'].str.contains(' op')) , 'Outpatient', Combined_data['inpatient-outpatient'])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    output_path = r\"C:\\Users\\User\\Zigna AI Corp\\Zigna AI Corp - RightPx\\Hospital Application_2022-03-09\\Automation_task\\outputs\\Wideformat101_{}.csv\"\n",
    "    Combined_data.to_csv(output_path.format(k[1]), index=False)\n",
    "    return Combined_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "117bb1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### wideFormat109 #######################\n",
    "def wifeFormat109(CNames):\n",
    "    global df7\n",
    "    \n",
    "    Combined_data = []\n",
    "    combined_final = []\n",
    "    non_prep_data = []\n",
    "\n",
    "    #Getting the details as list from files\n",
    "    for k in CNames.itertuples(index=False):\n",
    "        f=k[0] \n",
    "        #Checking the file type- xlsx   \n",
    "        if k[2]== 'csv':\n",
    "            try:\n",
    "                DF_FINAL=pd.read_csv(f)\n",
    "            except:\n",
    "                DF_FINAL=pd.read_csv(f,encoding='latin1')\n",
    "\n",
    "            non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        elif k[2]== 'xlsx':\n",
    "            sheet_to = pd.read_excel(f,sheet_name=None,dtype=str,header=None)\n",
    "\n",
    "            for sh in sheet_to.keys():\n",
    "\n",
    "                DF_FINAL = pd.read_excel(f,sheet_name=sh,dtype=str)\n",
    "                print(sh)\n",
    "                non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        for j in df7.itertuples(index=False):\n",
    "            if str(k[1]) == str(j[0]):\n",
    "                s = j[1]\n",
    "\n",
    "        for DF_FINAL in non_prep_data:\n",
    "            try:\n",
    "                if DF_FINAL.iloc[:, [s]].empty == False:\n",
    "\n",
    "\n",
    "                    DF_10 = DF_FINAL.iloc[:,[s]]\n",
    "                    m=0\n",
    "                    c=0\n",
    "\n",
    "                    #Getting the count of  empty rows\n",
    "                    for index, row in DF_10.iterrows():\n",
    "                        if(pd.notnull(row[0])): \n",
    "                            m=m+1\n",
    "                            break\n",
    "                        else:\n",
    "                            c=c+1\n",
    "\n",
    "                    if c==0:\n",
    "                    #This Case works when description is in one row\n",
    "                        if \"Unnamed: 2\" in DF_10:\n",
    "                            DF_FINAL.columns=DF_FINAL.iloc[0]\n",
    "                            FINAL=DF_FINAL.drop([c])\n",
    "                            FINAL['id']=k[1]\n",
    "                            FINAL\n",
    "                        else:\n",
    "                            #This Case works when description is not found\n",
    "                            FINAL=DF_FINAL\n",
    "                            FINAL['id']=k[1]\n",
    "                            FINAL\n",
    "\n",
    "                    elif c>=1:\n",
    "                        #This Case works when description is more than 1 row\n",
    "                        #Dropping 'c' rows\n",
    "                        DF_11=DF_FINAL.iloc[c:]\n",
    "                        DF_11[:c+1]=DF_11[:c+1].fillna(method='ffill', axis=1)\n",
    "                        DF_11[:c+1] = DF_11[:c+1].fillna(' ')\n",
    "                        DF_FINAL.columns = (DF_FINAL.iloc[c] + ' ' + DF_FINAL.iloc[c+1] + ' ' + DF_FINAL.iloc[c+2] )\n",
    "                        DF_FINAL = DF_FINAL.iloc[c+3:]\n",
    "                        DF_FINAL = DF_FINAL.dropna(how='all',axis=0)\n",
    "                        FINAL = DF_FINAL.reset_index(drop=True)\n",
    "\n",
    "                        #Dropping the row\n",
    "                        FINAL['id']=k[1]\n",
    "                    else:\n",
    "                        None \n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass\n",
    "\n",
    "\n",
    "        FINAL['CPT/HCPCS CODE    '] = FINAL['CPT/HCPCS CODE    '].replace(np.nan, 0)\n",
    "\n",
    "    #    FINAL[FINAL[\"CPT/HCPCS\"].str.contains(\" SERVICES\")==False]\n",
    "        FINAL['bool series'] =  pd.notnull(FINAL[\"SHOPPABLE SERVICE    \"])\n",
    "        FINAL['code1'] = FINAL.loc[FINAL['bool series'] == True, 'CPT/HCPCS CODE    ']\n",
    "    #    FINAL['Primary Service and Ancillary Service1'] = FINAL.loc[FINAL['bool series'] == True, 'Primary Service and Ancillary Service']\n",
    "    #    FINAL=FINAL[~(FINAL[\"description\"].str.contains(' rate type'))]\n",
    "        FINAL['SHOPPABLE SERVICE    '] = FINAL['SHOPPABLE SERVICE    '].fillna(method='ffill', axis=0)\n",
    "        FINAL['code1'] = FINAL['code1'].fillna(method='ffill', axis=0)    \n",
    "\n",
    "\n",
    "        for i in FINAL.columns:    \n",
    "            x = str(i).lower().strip()\n",
    "            FINAL=FINAL.rename(columns= {i:x})\n",
    "\n",
    "        for i in FINAL.columns.tolist():\n",
    "\n",
    "            for k in CNames.itertuples(index=False):\n",
    "\n",
    "                for r in DF6.itertuples(index=False):\n",
    "\n",
    "                    if str(k[1]) == str(r[2]):\n",
    "                        try:\n",
    "\n",
    "                            for i in FINAL.columns.tolist():\n",
    "\n",
    "                                if str(i) == str(r[0]):\n",
    "\n",
    "                                    FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                        except:\n",
    "                                pass\n",
    "\n",
    "        try:\n",
    "            FINAL = FINAL.loc[:, ~FINAL.columns.str.contains(' rate type')]\n",
    "        except:\n",
    "            None\n",
    "\n",
    "        for i in FINAL.columns.tolist():\n",
    "            for r in DF6.itertuples(index=False):\n",
    "                if str(r[2]) == \"nan\" :\n",
    "                    if str(i) == str(r[0]):\n",
    "                        FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "\n",
    "        column_list = ['inpatient-outpatient']\n",
    "        for col in column_list:\n",
    "            if col not in FINAL.columns:\n",
    "                FINAL[col] = ' '\n",
    "\n",
    "\n",
    "\n",
    "        all_columns = list(FINAL)\n",
    "        FINAL[all_columns] = FINAL[all_columns].replace('\\$|,', '', regex=True)\n",
    "        cols=[i for i in FINAL.columns if i not in [\"CPT/HCPCS\",\"Hospital_Id\",\"Primary Service and Ancillary Service\",\"description\", \"inpatient-outpatient\",\"bool series\", \"code1\"]]\n",
    "\n",
    "        for col in cols:\n",
    "            FINAL[col] = pd.to_numeric(FINAL[col], errors='coerce')         \n",
    "\n",
    "\n",
    "        Search_List = list(DF8[\"Dropping columns\"])\n",
    "            #dropping columns\n",
    "        FINAL= FINAL.drop(columns=[col for col in FINAL if col in Search_List])\n",
    "\n",
    "        FINAL[\"LineItem_cnt\"] = FINAL.groupby([\"description\",\"code1\"])[\"code1\"].transform('count')\n",
    "        FINAL[\"LineItem_cnt\"]=FINAL[\"LineItem_cnt\"]-1\n",
    "\n",
    "\n",
    "        FINAL=FINAL.groupby(['description','Hospital_Id', 'inpatient-outpatient', 'code1', 'LineItem_cnt']).aggregate(['sum']).reset_index()\n",
    "        FINAL.columns = FINAL.columns.get_level_values(0)\n",
    "        FINAL\n",
    "\n",
    "\n",
    "\n",
    "        FINAL=FINAL.rename(columns = {'code1': \"CPT/HCPCS\"}) \n",
    "        FINAL['CPT/HCPCS'] = FINAL['CPT/HCPCS'].replace(0,np.nan)\n",
    "\n",
    "        df2=FINAL  \n",
    "        df2 = df_column_uniquify(df2)\n",
    "        #Required format - variable list\n",
    "        Col_list = list(DF5[\"Columns\"])\n",
    "        df3=df2.melt(id_vars=[col for col in df2 if col in Col_list],var_name=\"name\",value_name='cost')\n",
    "        #df3=df1.melt(id_vars=['ID','Description','Cpt Code','Rev_Cd','Units'],var_name=\"Name\",value_name='Cost')\n",
    "        df3=df3[df3['name'].notnull()] \n",
    "\n",
    "        df4=df3\n",
    "        df4[\"cost\"] = df4[\"cost\"].replace('',np.nan)\n",
    "        df4[\"cost\"] = df4[\"cost\"].replace(0,np.nan)\n",
    "\n",
    "\n",
    "        df4=df4[df4['cost'].notnull()]\n",
    "\n",
    "        df4\n",
    "        Combined_data.append(df4)\n",
    "    Combined_data = pd.concat(Combined_data)\n",
    "\n",
    "\n",
    "    output_path = r\"C:\\Users\\User\\Zigna AI Corp\\Zigna AI Corp - RightPx\\Hospital Application_2022-03-09\\Automation_task\\outputs\\Wideformat109_{}.csv\"\n",
    "    Combined_data.to_csv(output_path.format(k[1]), index=False)\n",
    "    return Combined_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f9df5480",
   "metadata": {},
   "outputs": [],
   "source": [
    "################### wideFormat10 ###################\n",
    "def wideFormat10(CNames):\n",
    "    global df7\n",
    "    \n",
    "    Combined_data = []\n",
    "    combined_final = []\n",
    "    non_prep_data = []\n",
    "\n",
    "    #Getting the details as list from files\n",
    "    for k in CNames.itertuples(index=False):\n",
    "        f=k[0] \n",
    "        #Checking the file type- xlsx   \n",
    "        if k[2]== 'csv':\n",
    "            try:\n",
    "                DF_FINAL=pd.read_csv(f)\n",
    "            except:\n",
    "                DF_FINAL=pd.read_csv(f,encoding='latin1')\n",
    "\n",
    "            non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        elif k[2]== 'xlsx':\n",
    "            sheet_to = pd.read_excel(f,sheet_name=None,dtype=str,header=None)\n",
    "\n",
    "            for sh in sheet_to.keys():\n",
    "\n",
    "                DF_FINAL = pd.read_excel(f,sheet_name=sh,dtype=str)\n",
    "                print(sh)\n",
    "                non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        for j in df7.itertuples(index=False):\n",
    "            if str(k[1]) == str(j[0]):\n",
    "                s = j[1]\n",
    "\n",
    "        for DF_FINAL in non_prep_data:\n",
    "            try:\n",
    "                if DF_FINAL.iloc[:, [s]].empty == False:\n",
    "\n",
    "\n",
    "                    DF_10 = DF_FINAL.iloc[:,[s]]\n",
    "                    m=0\n",
    "                    c=0\n",
    "\n",
    "                    #Getting the count of  empty rows\n",
    "                    for index, row in DF_10.iterrows():\n",
    "                        if(pd.notnull(row[0])): \n",
    "                            m=m+1\n",
    "                            break\n",
    "                        else:\n",
    "                            c=c+1\n",
    "\n",
    "                    if c==0:\n",
    "                    #This Case works when description is in one row\n",
    "                        if \"Unnamed: 2\" in DF_10:\n",
    "                            DF_FINAL.columns=DF_FINAL.iloc[0]\n",
    "                            FINAL=DF_FINAL.drop([c])\n",
    "                            FINAL['id']=k[1]\n",
    "                            FINAL\n",
    "                        else:\n",
    "                            #This Case works when description is not found\n",
    "                            FINAL=DF_FINAL\n",
    "                            FINAL['id']=k[1]\n",
    "                            FINAL\n",
    "\n",
    "                    elif c>=1:\n",
    "                        #This Case works when description is more than 1 row\n",
    "                        #Dropping 'c' rows\n",
    "                        DF_11=DF_FINAL.iloc[c:]\n",
    "                        #row values as column names\n",
    "                        DF_11.columns=DF_11.iloc[0]\n",
    "                        #Dropping the row\n",
    "                        FINAL=DF_11.drop([c])\n",
    "                        FINAL['id']=k[1]\n",
    "                    else:\n",
    "                        None \n",
    "\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass        \n",
    "\n",
    "\n",
    "            DATA1=FINAL[FINAL['Shoppable_Cd'].notnull()]\n",
    "            DATA1['HCPC/Cpt_Cd'] = np.where(DATA1['Shoppable_Cd'] != 'Total', DATA1['Shoppable_Cd'], DATA1['HCPC/Cpt_Cd'])\n",
    "            DATA1['HCPC/Cpt_Cd'].fillna(method='ffill', inplace=True)\n",
    "            DATA1['Rev_Cd'].fillna(method='ffill', inplace=True)\n",
    "            DATA1['Rev_Cd_Descr'].fillna(method='ffill', inplace=True)\n",
    "            DATA1['Quantity/Units'].fillna(method='ffill', inplace=True)\n",
    "            DATA2= DATA1[DATA1['Shoppable_Cd']=='Total']\n",
    "            DATA2\n",
    "            FINAL['Shoppable_Cd'].fillna(method='ffill', inplace=True)\n",
    "            FINAL['Descr'].fillna(method='ffill', inplace=True)\n",
    "            DATA3=FINAL.groupby([\"Shoppable_Cd\", \"Descr\"]).size().reset_index(name=\"LineItem_cnt\")\n",
    "            DATA3\n",
    "            DATA4= DATA3[DATA3['Shoppable_Cd']!='Total']\n",
    "            DATA4\n",
    "            new_df = pd.merge(DATA2, DATA4,  how='left', left_on=['HCPC/Cpt_Cd','Descr'], right_on = ['Shoppable_Cd','Descr'])\n",
    "\n",
    "\n",
    "            for i in new_df.columns:\n",
    "                x = str(i).lower().strip()\n",
    "                new_df=new_df.rename(columns= {i:x})\n",
    "                FINAL1 = new_df\n",
    "\n",
    "            for i in FINAL1.columns.tolist():\n",
    "\n",
    "                for k in CNames.itertuples(index=False):\n",
    "\n",
    "                    for r in DF6.itertuples(index=False):\n",
    "\n",
    "                        if str(k[1]) == str(r[2]):\n",
    "                            try:\n",
    "\n",
    "                                for i in FINAL1.columns.tolist():\n",
    "\n",
    "                                    if str(i) == str(r[0]):\n",
    "\n",
    "                                        FINAL1.rename(columns={i:r[1]}, inplace=True)\n",
    "                            except:\n",
    "                                    pass\n",
    "\n",
    "            for i in FINAL1.columns.tolist():\n",
    "                for r in DF6.itertuples(index=False):\n",
    "                    if str(r[2]) == \"nan\" :\n",
    "                        if str(i) == str(r[0]):\n",
    "                            FINAL1.rename(columns={i:r[1]}, inplace=True)\n",
    "\n",
    "            Search_List = list(DF8[\"Dropping columns\"])\n",
    "        #dropping columns\n",
    "            FINAL1= FINAL1.drop(columns=[col for col in FINAL1 if col in Search_List])\n",
    "\n",
    "            column_list = ['inpatient-outpatient']\n",
    "            for col in column_list:\n",
    "                if col not in FINAL1.columns:\n",
    "                    FINAL1[col] = ' '\n",
    "\n",
    "            df2=FINAL1\n",
    "            df2 = df_column_uniquify(df2)\n",
    "\n",
    "            Col_list = list(DF5[\"Columns\"])\n",
    "            df3=df2.melt(id_vars=[col for col in df2 if col in Col_list],var_name=\"name\",value_name='cost')\n",
    "\n",
    "            df4=df3\n",
    "            df4=df4[df4['cost'].notnull()]\n",
    "\n",
    "            df4\n",
    "            Combined_data.append(df4)\n",
    "\n",
    "    Combined_data = pd.concat(Combined_data)        \n",
    "\n",
    "    try:\n",
    "\n",
    "        Combined_data['inpatient-outpatient'] = np.where((Combined_data['inpatient-outpatient'] ==' ') & (Combined_data['name'].str.contains(' ip')) , 'Inpatient', Combined_data['inpatient-outpatient'])\n",
    "        Combined_data['inpatient-outpatient'] = np.where((Combined_data['inpatient-outpatient'] ==' ') & (Combined_data['name'].str.contains(' op')) , 'Outpatient', Combined_data['inpatient-outpatient'])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "    # Drop if any duplicate column comes in the data\n",
    "    Sample_output = Combined_data.drop_duplicates()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    output_path = r\"C:\\Users\\User\\Zigna AI Corp\\Zigna AI Corp - RightPx\\Hospital Application_2022-03-09\\Automation_task\\outputs\\Wideformat10_{}.csv\"\n",
    "    Sample_output.to_csv(output_path.format(k[1]), index=False)\n",
    "    return Sample_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "576fc76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### wideFormat116 #######################\n",
    "def wideFormat116(CNames):\n",
    "    global df7\n",
    "    \n",
    "    Combined_data = []\n",
    "    combined_final = []\n",
    "    non_prep_data = []\n",
    "\n",
    "\n",
    "    for k in CNames.itertuples(index=False):\n",
    "        f=k[0] \n",
    "        #Checking the file type- xlsx   \n",
    "        if k[2]== 'csv':\n",
    "            try:\n",
    "                DF_FINAL=pd.read_csv(f)\n",
    "            except:\n",
    "                DF_FINAL=pd.read_csv(f,encoding='latin1')\n",
    "\n",
    "            non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        elif k[2]== 'xlsx':\n",
    "            sheet_to = pd.read_excel(f,sheet_name=None,dtype=str,header=None)\n",
    "\n",
    "            for sh in sheet_to.keys():\n",
    "\n",
    "                DF_FINAL = pd.read_excel(f,sheet_name=sh,dtype=str)\n",
    "                print(sh)\n",
    "                non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        for j in df7.itertuples(index=False):\n",
    "            if str(k[1]) == str(j[0]):\n",
    "                s = j[1]\n",
    "\n",
    "        for DF_FINAL in non_prep_data:\n",
    "            try:\n",
    "                if DF_FINAL.iloc[:, [s]].empty == False:\n",
    "\n",
    "\n",
    "                    DF_10 = DF_FINAL.iloc[:,[s]]\n",
    "                    m=0\n",
    "                    c=0\n",
    "\n",
    "                    for index, row in DF_10.iterrows():\n",
    "                        if(pd.notnull(row[0])): \n",
    "                            m=m+1\n",
    "                            break\n",
    "                        else:\n",
    "                            c=c+1\n",
    "\n",
    "                    if c==0:\n",
    "                    #This Case works when description is in one row\n",
    "                        if \"Unnamed: 5\" in DF_10:\n",
    "                            DF_FINAL.columns=DF_FINAL.iloc[0]\n",
    "                            FINAL=DF_FINAL.drop([c])\n",
    "                            FINAL['id']=k[1]\n",
    "                            FINAL\n",
    "                        else:\n",
    "                            #This Case works when description is not found\n",
    "                            FINAL=DF_FINAL\n",
    "                            FINAL['id']=k[1]\n",
    "                            FINAL\n",
    "\n",
    "                    elif c>=1:\n",
    "                        #This Case works when description is more than 1 row\n",
    "                        #Dropping 'c' rows\n",
    "                        DF_11=DF_FINAL.iloc[c:]\n",
    "                        #row values as column names\n",
    "                        DF_11.columns=DF_11.iloc[0]\n",
    "                        #Dropping the row\n",
    "                        FINAL=DF_11.drop([c])\n",
    "                        FINAL['id']=k[1]\n",
    "\n",
    "                    else:\n",
    "                        None \n",
    "            except Exception as e:   \n",
    "                print(e)\n",
    "                pass\n",
    "\n",
    "\n",
    "        for i in FINAL.columns:\n",
    "\n",
    "           x = str(i).lower().strip()\n",
    "           FINAL=FINAL.rename(columns= {i:x})\n",
    "\n",
    "        for i in FINAL.columns.tolist():\n",
    "\n",
    "            for k in CNames.itertuples(index=False):\n",
    "\n",
    "                for r in DF6.itertuples(index=False):\n",
    "\n",
    "                    if str(k[1]) == str(r[2]):\n",
    "                        try:\n",
    "\n",
    "                            for i in FINAL.columns.tolist():\n",
    "\n",
    "                                if str(i) == str(r[0]):\n",
    "\n",
    "                                    FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                        except:\n",
    "                                pass\n",
    "\n",
    "        for i in FINAL.columns.tolist():\n",
    "            for r in DF6.itertuples(index=False):\n",
    "                if str(r[2]) == \"nan\" :\n",
    "                    if str(i) == str(r[0]):\n",
    "                        FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "\n",
    "        Search_List = list(DF8[\"Dropping columns\"])\n",
    "            #dropping columns\n",
    "        FINAL= FINAL.drop(columns=[col for col in FINAL if col in Search_List])\n",
    "\n",
    "        column_list = ['inpatient-outpatient']\n",
    "        for col in column_list:\n",
    "            if col not in FINAL.columns:\n",
    "                FINAL[col] = ' '\n",
    "\n",
    "    #    FINAL['descripition1'] = np.where((FINAL['CPT/HCPCS'].notnull()) & (FINAL['description'].notnull()) , FINAL['description'],\"\")\n",
    "    #    lst=['Procedure/Charge Number','rev_cd','description']\n",
    "    #    if CNames['id'].isin(['1215']).any():\n",
    "    #        FINAL.drop(columns=[col for col in FINAL if col  in lst],axis=1,inplace=True)\n",
    "    #        \n",
    "    #    else:\n",
    "    #        pass\n",
    "    #    if CNames['id'].isin(['1215']).any():\n",
    "    #          \n",
    "    #        FINAL=FINAL.rename(columns = {'descripition1': \"description\"})\n",
    "    #    else:\n",
    "    #        pass\n",
    "\n",
    "        FINAL = FINAL.replace(r'^\\s*$', np.NaN, regex=True)\n",
    "        cols=['CPT/HCPCS','description']\n",
    "        FINAL[cols]=FINAL[cols].ffill()\n",
    "\n",
    "\n",
    "        FINAL['LineItem_cnt'] = None \n",
    "        FINAL['LineItem_cnt'] = FINAL.groupby(['CPT/HCPCS','description']).transform(np.size)\n",
    "        FINAL['LineItem_cnt']=FINAL['LineItem_cnt']-1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        FINAL.fillna(value = 0,inplace = True)\n",
    "\n",
    "        col_list1=['CPT/HCPCS','LineItem_cnt','description']\n",
    "        FINAL1=FINAL.groupby([col for col in FINAL if col  in col_list1]).aggregate(['sum']).reset_index()\n",
    "        FINAL.columns = FINAL.columns.get_level_values(0)\n",
    "        FINAL['inpatient-outpatient'] = np.where((FINAL['inpatient-outpatient'] == 0)  , ' ', FINAL['inpatient-outpatient'])\n",
    "\n",
    "\n",
    "\n",
    "        df2=FINAL\n",
    "        df2 = df_column_uniquify(df2)\n",
    "        #Required format - variable list\n",
    "        Col_list = list(DF5[\"Columns\"])\n",
    "        df3=df2.melt(id_vars=[col for col in df2 if col in Col_list],var_name=\"name\",value_name='cost')\n",
    "        #df3=df1.melt(id_vars=['ID','Description','Cpt Code','Rev_Cd','Units'],var_name=\"Name\",value_name='Cost')\n",
    "\n",
    "\n",
    "        df4=df3\n",
    "        df4=df4[df4['cost'].notnull()]\n",
    "        #Dropping_columns=['Not offered','Not Contracted','N/A','Not a covered service','Not Offered','Not contracted','Not a covered service','N/A']\n",
    "        #df4 = df4[~df4['Cost'].isin(Dropping_columns)]\n",
    "        df4\n",
    "        Combined_data.append(df4)\n",
    "    Combined_data = pd.concat(Combined_data)\n",
    "\n",
    "    Combined_data = Combined_data.drop_duplicates()\n",
    "    try:\n",
    "\n",
    "        Combined_data['inpatient-outpatient'] = np.where((Combined_data['inpatient-outpatient'] ==' ') & (Combined_data['name'].str.contains(' ip')) , 'Inpatient', Combined_data['inpatient-outpatient'])\n",
    "        Combined_data['inpatient-outpatient'] = np.where((Combined_data['inpatient-outpatient'] ==' ') & (Combined_data['name'].str.contains(' op')) , 'Outpatient', Combined_data['inpatient-outpatient'])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "    output_path = r\"C:\\Users\\User\\Zigna AI Corp\\Zigna AI Corp - RightPx\\Hospital Application_2022-03-09\\Automation_task\\outputs\\Wideformat116_{}.csv\"\n",
    "    Combined_data.to_csv(output_path.format(k[1]), index=False)\n",
    "    return Combined_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "91f58f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## wideFormat16 ####################\n",
    "def wideFormat16(CNames):\n",
    "    global df7\n",
    "    \n",
    "    Combined_data = []\n",
    "    combined_final = []\n",
    "    non_prep_data = []\n",
    "\n",
    "    #Getting the details as list from files\n",
    "    for k in CNames.itertuples(index=False):\n",
    "        f=k[0] \n",
    "        #Checking the file type- xlsx   \n",
    "        if k[2]== 'csv':\n",
    "            try:\n",
    "                DF_FINAL=pd.read_csv(f)\n",
    "            except:\n",
    "                DF_FINAL=pd.read_csv(f,encoding='latin1')\n",
    "\n",
    "            non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        elif k[2]== 'xlsx':\n",
    "            sheet_to = pd.read_excel(f,sheet_name=None,dtype=str,header=None)\n",
    "\n",
    "            for sh in sheet_to.keys():\n",
    "\n",
    "                DF_FINAL = pd.read_excel(f,sheet_name=sh,dtype=str)\n",
    "                print(sh)\n",
    "                non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        for j in df7.itertuples(index=False):\n",
    "            if str(k[1]) == str(j[0]):\n",
    "                s = j[1]\n",
    "\n",
    "        for DF_FINAL in non_prep_data:\n",
    "            try:\n",
    "                if DF_FINAL.iloc[:, [s]].empty == False:\n",
    "\n",
    "\n",
    "                    DF_10 = DF_FINAL.iloc[:,[s]]\n",
    "                    m=0\n",
    "                    c=0\n",
    "                    #Getting the count of  empty rows\n",
    "                    for index, row in DF_10.iterrows():\n",
    "                        if(pd.notnull(row[0])): \n",
    "                            m=m+1\n",
    "                            break\n",
    "                        else:\n",
    "                            c=c+1\n",
    "\n",
    "                    if c==0:\n",
    "                    #This Case works when description is in one row\n",
    "                        if \"Unnamed: 5\" in DF_10:\n",
    "                            DF_FINAL.columns=DF_FINAL.iloc[0]\n",
    "                            FINAL=DF_FINAL.drop([c])\n",
    "                            FINAL['id']=k[1]\n",
    "                            FINAL\n",
    "                        else:\n",
    "                            #This Case works when description is not found\n",
    "                            FINAL=DF_FINAL\n",
    "                            FINAL['id']=k[1]\n",
    "                            FINAL\n",
    "\n",
    "                    elif c>=1:\n",
    "                        #This Case works when description is more than 1 row\n",
    "                        #Dropping 'c' rows\n",
    "                        DF_11=DF_FINAL.iloc[c:]\n",
    "                        #row values as column names\n",
    "                        DF_11.columns=DF_11.iloc[0]\n",
    "                        #Dropping the row\n",
    "                        FINAL=DF_11.drop([c])\n",
    "                        FINAL['id']=k[1]\n",
    "                    else:\n",
    "                        None \n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass\n",
    "\n",
    "        for i in FINAL.columns:          \n",
    "            x = str(i).lower().strip()\n",
    "            FINAL=FINAL.rename(columns= {i:x})\n",
    "\n",
    "        for i in FINAL.columns.tolist():\n",
    "\n",
    "            for k in CNames.itertuples(index=False):\n",
    "\n",
    "                for r in DF6.itertuples(index=False):\n",
    "\n",
    "                    if str(k[1]) == str(r[2]):\n",
    "                        try:\n",
    "\n",
    "                            for i in FINAL.columns.tolist():\n",
    "\n",
    "                                if str(i) == str(r[0]):\n",
    "\n",
    "                                    FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                        except:\n",
    "                                pass\n",
    "\n",
    "        for i in FINAL.columns.tolist():\n",
    "            for r in DF6.itertuples(index=False):\n",
    "                if str(r[2]) == \"nan\" :\n",
    "                    if str(i) == str(r[0]):\n",
    "                        FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "\n",
    "        Search_List = list(DF8[\"Dropping columns\"])\n",
    "        #dropping columns\n",
    "        FINAL= FINAL.drop(columns=[col for col in FINAL if col in Search_List])\n",
    "\n",
    "        column_list = ['inpatient-outpatient']\n",
    "        for col in column_list:\n",
    "            if col not in FINAL.columns:\n",
    "                FINAL[col] = ' '\n",
    "\n",
    "        FINAL1=FINAL[FINAL['Primary Service and Ancillary Service'].notnull()]\n",
    "        FINAL1['description'].fillna(method='ffill', inplace=True)\n",
    "        FINAL1['Shoppable Service Category'].fillna(method='ffill', inplace=True)\n",
    "\n",
    "        FINAL1['cpt code']=FINAL1['description'].str.extract('(\\d+)')\n",
    "        #FINAL1['description1'] = FINAL1['description'].str.replace('\\d+','')\n",
    "\n",
    "        FINAL1.loc[FINAL1['cpt code']== '0297', 'cpt code'] = \"G0297\"\n",
    "    #    Name_List1 = list((DF9[\"cpt codes\"]).astype(str))\n",
    "    #    FINAL1['description1'] = FINAL1['description'].str.replace('|'.join(Name_List1),'',case=False)\n",
    "    #    FINAL1['description1']=FINAL1['description1'].str.replace('MS DRG /APR DRG 304','')\n",
    "    #    FINAL1['description1']=FINAL1['description1'].str.replace('MS DRG /APR DRG 301','')\n",
    "    #    FINAL1['description1']=FINAL1['description1'].str.replace('MS DRG /APR DRG 302','')\n",
    "    #    FINAL1['description1']=FINAL1['description1'].str.replace('MS DRG /APR DRG 321','')\n",
    "    #    FINAL1['description1']=FINAL1['description1'].str.replace('MS DRG /APR DRG 513','')\n",
    "    #    FINAL1['description1']=FINAL1['description1'].str.replace('MS DRG /APR DRG 560','')\n",
    "    #    FINAL1['description1']=FINAL1['description1'].str.replace('MS DRG /APR DRG 540','')\n",
    "    #    FINAL1['description1']=FINAL1['description1'].str.replace('MS DRG /APR DRG 640','')\n",
    "    #    FINAL1['description1']=FINAL1['description1'].str.replace('MS DRG /APR 480','')\n",
    "    #    FINAL1['description1']=FINAL1['description1'].str.strip()\n",
    "\n",
    "        FINAL1[\"LineItem_cnt\"] = FINAL1.groupby(\"description\")[\"description\"].transform('count')\n",
    "        FINAL1[\"LineItem_cnt\"]=FINAL1[\"LineItem_cnt\"]-1\n",
    "        FINAL1\n",
    "        FINAL2=FINAL1[(FINAL1[\"LineItem_cnt\"] ==0) | ((FINAL1[\"LineItem_cnt\"] >=1) & (FINAL1[\"Primary Service and Ancillary Service\"].str.contains(\"Total\",case=False))) ]\n",
    "\n",
    "\n",
    "        FINAL2.drop([\"description\"], axis = 1, inplace = True)\n",
    "        FINAL3=FINAL2.rename(columns={'description1': 'description'})\n",
    "\n",
    "\n",
    "        #Checking the  Inpatient/Outpatient column exists or not\n",
    "\n",
    "\n",
    "        #Search_List = list(DF3[\"Keeping columns\"])\n",
    "        #Keeping columns\n",
    "        #df1= FINAL.drop(columns=[col for col in FINAL if col not in Search_List])\n",
    "        #Removing the empty rows from'cpt code'\n",
    "        #df2 = df1.dropna(axis=0, subset=['Cpt Code'])\n",
    "\n",
    "        #df2=FINAL[FINAL['cpt code'].notnull()] \n",
    "\n",
    "        df2=FINAL3\n",
    "        df2 = df_column_uniquify(df2)\n",
    "        #Required format - variable list\n",
    "        Col_list = list(DF5[\"Columns\"])\n",
    "        df3=df2.melt(id_vars=[col for col in df2 if col in Col_list],var_name=\"name\",value_name='cost')\n",
    "        #df3=df1.melt(id_vars=['ID','Description','Cpt Code','Rev_Cd','Units'],var_name=\"Name\",value_name='Cost')\n",
    "\n",
    "        #df3['payer'] = None\n",
    "        #df3['insurance Type'] = None\n",
    "        #df3['Benefit Type']=None\n",
    "\n",
    "        #Name_List = list(DF1[\"Payers\"])\n",
    "\n",
    "        #Name_List1 = list(DF2[\"Insurance Type\"])\n",
    "\n",
    "        #Name_List2 = list(DF3[\"Benefit Type\"])\n",
    "\n",
    "        #Finding Payers from the list\n",
    "        #for i in Name_List:\n",
    "        #    df3['payer'][(df3['name'].str.contains(i,case=False,na=False))] = i\n",
    "        #Finding Insurancetype from the list    \n",
    "        #for j in Name_List1:\n",
    "        #    df3['insurance Type'][(df3['name'].str.contains(j,case=False,na=False))] = j\n",
    "\n",
    "        #Finding Benefit Type from the list  \n",
    "        #for k in Name_List2:\n",
    "        #    df3['Benefit Type'][(df3['name'].str.contains(k,case=False,na=False))] = k \n",
    "\n",
    "        df4=df3\n",
    "        df4=df4[df4['cost'].notnull()]\n",
    "        #Dropping_columns=['Not offered','Not Contracted','N/A','Not a covered service','Not Offered','Not contracted','Not a covered service','N/A']\n",
    "        #df4 = df4[~df4['Cost'].isin(Dropping_columns)]\n",
    "        df4\n",
    "        Combined_data.append(df4)\n",
    "    Combined_data = pd.concat(Combined_data)\n",
    "\n",
    "    Combined_data\n",
    "    # Combined_data[\"id\"\n",
    "\n",
    "\n",
    "    Combined_data = Combined_data.drop_duplicates()\n",
    "    try:\n",
    "\n",
    "        Combined_data['inpatient-outpatient'] = np.where((Combined_data['inpatient-outpatient'] ==' ') & (Combined_data['name'].str.contains(' ip')) , 'Inpatient', Combined_data['inpatient-outpatient'])\n",
    "        Combined_data['inpatient-outpatient'] = np.where((Combined_data['inpatient-outpatient'] ==' ') & (Combined_data['name'].str.contains(' op')) , 'Outpatient', Combined_data['inpatient-outpatient'])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    output_path = r\"C:\\Users\\User\\Zigna AI Corp\\Zigna AI Corp - RightPx\\Hospital Application_2022-03-09\\Automation_task\\outputs\\Wideformat16_{}.csv\"\n",
    "    Combined_data.to_csv(output_path.format(k[1]), index=False)\n",
    "    return Combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4a777313",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### wideFormat44 ###################\n",
    "def wideFormat44(CNames):\n",
    "    global df7\n",
    "    \n",
    "    Combined_data = []\n",
    "    combined_final = []\n",
    "    non_prep_data = []\n",
    "\n",
    "\n",
    "    #Getting the details as list from files\n",
    "    for k in CNames.itertuples(index=False):\n",
    "        f=k[0] \n",
    "        #Checking the file type- xlsx   \n",
    "        if k[2]== 'csv':\n",
    "            try:\n",
    "                DF_FINAL=pd.read_csv(f)\n",
    "            except:\n",
    "                DF_FINAL=pd.read_csv(f,encoding='latin1')\n",
    "\n",
    "            non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        elif k[2]== 'xlsx':\n",
    "            sheet_to = pd.read_excel(f,sheet_name=None,dtype=str,header=None)\n",
    "\n",
    "            for sh in sheet_to.keys():\n",
    "\n",
    "                DF_FINAL = pd.read_excel(f,sheet_name=sh,dtype=str)\n",
    "                print(sh)\n",
    "                non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        for j in df7.itertuples(index=False):\n",
    "            if str(k[1]) == str(j[0]):\n",
    "                s = j[1]\n",
    "\n",
    "        for DF_FINAL in non_prep_data:\n",
    "            try:\n",
    "                if DF_FINAL.iloc[:, [s]].empty == False:\n",
    "\n",
    "\n",
    "                    DF_10 = DF_FINAL.iloc[:,[s]]\n",
    "                    m=0\n",
    "                    c=0\n",
    "\n",
    "                    #Getting the count of  empty rows\n",
    "                    for index, row in DF_10.iterrows():\n",
    "                        if(pd.notnull(row[0])): \n",
    "                            m=m+1\n",
    "                            break\n",
    "                        else:\n",
    "                            c=c+1\n",
    "\n",
    "                    if c==0:\n",
    "                    #This Case works when description is in one row\n",
    "                        if \"Unnamed: 5\" in DF_10:\n",
    "                            DF_FINAL=DF_FINAL.iloc[0]\n",
    "                            FINAL=DF_FINAL.drop([c])\n",
    "                            FINAL['id']=k[1]\n",
    "                            FINAL\n",
    "                        else:\n",
    "                            #This Case works when description is not found\n",
    "                            FINAL=DF_FINAL\n",
    "                            FINAL['id']=k[1]\n",
    "                            FINAL\n",
    "\n",
    "                    elif c>=1:\n",
    "                        #This Case works when description is more than 1 row\n",
    "                        #Dropping 'c' rows\n",
    "                        DF_FINAL.iloc[:c,:c] = np.nan\n",
    "\n",
    "                        DF_FINAL[:c] = DF_FINAL[:c].fillna(method='ffill', axis=1)\n",
    "                        DF_FINAL = DF_FINAL.replace(np.nan,'',regex=True)\n",
    "                        idx = DF_FINAL.index.get_loc(c)\n",
    "                        DF_11 = DF_FINAL.iloc[idx - c :]\n",
    "                        j = c+1\n",
    "\n",
    "                        req_rows = np.where(DF_11.index == j)[0][0]\n",
    "                        start = max(0, req_rows - j )\n",
    "                        end = max(1, req_rows)\n",
    "                        DF_12 = DF_11.iloc[start:end]\n",
    "\n",
    "                        DF_12= DF_12.apply(lambda c: ' '.join(c), axis=0)\n",
    "                        DF_12 = DF_12.to_frame()\n",
    "                        DF_13 = DF_12.T\n",
    "\n",
    "                        DF_11.drop(DF_11.head(j).index, inplace = True)\n",
    "                        DF15 = DF_13.append(DF_11)\n",
    "                        DF16 = DF15.reset_index(drop = True)\n",
    "                        DF16.columns = DF16.iloc[0]\n",
    "                        FINAL = DF16[1:]\n",
    "                    else:\n",
    "                        None \n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass\n",
    "\n",
    "        for i in FINAL.columns:    \n",
    "            x = str(i).lower().strip()\n",
    "            FINAL=FINAL.rename(columns= {i:x})\n",
    "\n",
    "        for i in FINAL.columns.tolist():\n",
    "\n",
    "            for k in CNames.itertuples(index=False):\n",
    "\n",
    "                for r in DF6.itertuples(index=False):\n",
    "\n",
    "                    if str(k[1]) == str(r[2]):\n",
    "                        try:\n",
    "\n",
    "                            for i in FINAL.columns.tolist():\n",
    "\n",
    "                                if str(i) == str(r[0]):\n",
    "\n",
    "                                    FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                        except:\n",
    "                                pass\n",
    "\n",
    "        for i in FINAL.columns.tolist():\n",
    "            for r in DF6.itertuples(index=False):\n",
    "                if str(r[2]) == \"nan\" :\n",
    "                    if str(i) == str(r[0]):\n",
    "                        FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "\n",
    "        Search_List = list(DF8[\"Dropping columns\"])\n",
    "            #dropping columns\n",
    "        FINAL= FINAL.drop(columns=[col for col in FINAL if col in Search_List])\n",
    "\n",
    "        column_list = ['inpatient-outpatient']\n",
    "        for col in column_list:\n",
    "            if col not in FINAL.columns:\n",
    "                FINAL[col] = ' '\n",
    "\n",
    "        df2=FINAL\n",
    "        df2 = df_column_uniquify(df2)\n",
    "        #Required format - variable list\n",
    "        Col_list = list(DF5[\"Columns\"])\n",
    "        df3=df2.melt(id_vars=[col for col in df2 if col in Col_list],var_name=\"name\",value_name='cost')\n",
    "\n",
    "        df4=df3\n",
    "        df4=df4[df4['cost'].notnull()]\n",
    "        #Dropping_columns=['Not offered','Not Contracted','N/A','Not a covered service','Not Offered','Not contracted','Not a covered service','N/A']\n",
    "        #df4 = df4[~df4['Cost'].isin(Dropping_columns)]\n",
    "        Combined_data.append(df4)\n",
    "    Combined_data = pd.concat(Combined_data)\n",
    "\n",
    "    Combined_data = Combined_data.drop_duplicates()\n",
    "\n",
    "    try: \n",
    "        Combined_data['inpatient-outpatient'] = np.where((Combined_data['inpatient-outpatient'] ==' ') & (Combined_data['name'].str.contains(' ip')) , 'Inpatient', Combined_data['inpatient-outpatient'])\n",
    "        Combined_data['inpatient-outpatient'] = np.where((Combined_data['inpatient-outpatient'] ==' ') & (Combined_data['name'].str.contains(' op')) , 'Outpatient', Combined_data['inpatient-outpatient'])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    output_path = r\"C:\\Users\\User\\Zigna AI Corp\\Zigna AI Corp - RightPx\\Hospital Application_2022-03-09\\Automation_task\\outputs\\Wideformat44_{}.csv\"\n",
    "    Combined_data.to_csv(output_path.format(k[1]), index=False)\n",
    "    return Combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e692a6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### wideFormat4_4 ###############\n",
    "def wideFormat4_4(CNames):\n",
    "    global df7\n",
    "    \n",
    "    Combined_data = []\n",
    "    combined_final = []\n",
    "    non_prep_data = []\n",
    "\n",
    "    #Getting the details as list from files\n",
    "    for k in CNames.itertuples(index=False):\n",
    "        f=k[0] \n",
    "        #Checking the file type- xlsx   \n",
    "        if k[2]== 'csv':\n",
    "            try:\n",
    "                DF_FINAL=pd.read_csv(f)\n",
    "            except:\n",
    "                DF_FINAL=pd.read_csv(f,encoding='latin1')\n",
    "\n",
    "            non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        elif k[2]== 'xlsx':\n",
    "            sheet_to = pd.read_excel(f,sheet_name=None,dtype=str,header=None)\n",
    "\n",
    "            for sh in sheet_to.keys():\n",
    "\n",
    "                DF_FINAL = pd.read_excel(f,sheet_name=sh,dtype=str)\n",
    "                print(sh)\n",
    "                non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        for j in df7.itertuples(index=False):\n",
    "            if str(k[1]) == str(j[0]):\n",
    "                s = j[1]\n",
    "\n",
    "        for DF_FINAL in non_prep_data:\n",
    "            try:\n",
    "                if DF_FINAL.iloc[:, [s]].empty == False:\n",
    "\n",
    "\n",
    "                    DF_10 = DF_FINAL.iloc[:,[s]]\n",
    "                    m=0\n",
    "                    c=0\n",
    "\n",
    "                    #Getting the count of  empty rows\n",
    "                    for index, row in DF_10.iterrows():\n",
    "                        if(pd.notnull(row[0])): \n",
    "                            m=m+1\n",
    "                            break\n",
    "                        else:\n",
    "                            c=c+1\n",
    "\n",
    "                    if c==0:\n",
    "                    #This Case works when description is in one row\n",
    "                        if \"Unnamed: 5\" in DF_10:\n",
    "                            DF_FINAL.columns=DF_FINAL.iloc[0]\n",
    "                            FINAL=DF_FINAL.drop([c])\n",
    "                            FINAL['id']=k[1]\n",
    "                            FINAL\n",
    "                        else:\n",
    "                            #This Case works when description is not found\n",
    "                            FINAL=DF_FINAL\n",
    "                            FINAL['id']=k[1]\n",
    "                            FINAL\n",
    "\n",
    "                    elif c>=1:\n",
    "                        #This Case works when description is more than 1 row\n",
    "                        #Dropping 'c' rows\n",
    "                        DF_11=DF_FINAL.iloc[c:]\n",
    "                        #row values as column names\n",
    "                        DF_11.columns=DF_11.iloc[0]\n",
    "                        #Dropping the row\n",
    "                        FINAL=DF_11.drop([c])\n",
    "                        FINAL['id']=k[1]\n",
    "                    else:\n",
    "                        None \n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass\n",
    "\n",
    "        lst=['Service Code']\n",
    "        FINAL= FINAL[~FINAL['Service Code'].isin(lst)]   \n",
    "\n",
    "        P=[] \n",
    "        # for the values in the cost column, where ever $ symbol is present it is replaced with an empty string.\n",
    "        for d in FINAL['Service Fee/ Gross Charge']:\n",
    "            yu = d.replace(r'$', '')\n",
    "            yu1= yu.replace(r'/hour', '')\n",
    "            yu2 = yu1.replace(r'/daily charge', '')\n",
    "            P.append(yu2) # Now the new\n",
    "\n",
    "        for index,all in enumerate(P):\n",
    "            if \"-\" in all:\n",
    "                ind = index\n",
    "                l = all.split(\"-\")  # Where we find a \"-\" there the values get split \n",
    "                b =list(map(float,l)) \n",
    "                d =np.mean(b) \n",
    "                      # Mean of two values that are seperated is calculated\n",
    "                P[ind] = d          # The mean value is replaced to their respective index\n",
    "\n",
    "        FINAL['Service Fee/ Gross Charge']=P\n",
    "\n",
    "        for i in FINAL.columns:    \n",
    "            x = str(i).lower().strip()\n",
    "            FINAL=FINAL.rename(columns= {i:x})\n",
    "\n",
    "        for i in FINAL.columns.tolist():\n",
    "\n",
    "            for k in CNames.itertuples(index=False):\n",
    "\n",
    "                for r in DF6.itertuples(index=False):\n",
    "\n",
    "                    if str(k[1]) == str(r[2]):\n",
    "                        try:\n",
    "\n",
    "                            for i in FINAL.columns.tolist():\n",
    "\n",
    "                                if str(i) == str(r[0]):\n",
    "\n",
    "                                    FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                        except:\n",
    "                                pass\n",
    "\n",
    "        for i in FINAL.columns.tolist():\n",
    "            for r in DF6.itertuples(index=False):\n",
    "                if str(r[2]) == \"nan\" :\n",
    "                    if str(i) == str(r[0]):\n",
    "                        FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "\n",
    "        Search_List = list(DF8[\"Dropping columns\"])\n",
    "            #dropping columns\n",
    "        FINAL= FINAL.drop(columns=[col for col in FINAL if col in Search_List])\n",
    "\n",
    "        column_list = ['inpatient-outpatient']\n",
    "        for col in column_list:\n",
    "            if col not in FINAL.columns:\n",
    "                FINAL[col] = ' '\n",
    "\n",
    "        lst=['Service Code']\n",
    "        df1= FINAL[~FINAL['Procedure/Charge Number'].isin(lst)] \n",
    "\n",
    "        P=[] \n",
    "        # for the values in the cost column, where ever $ symbol is present it is replaced with an empty string.\n",
    "        for d in df1['Gross Charge']:\n",
    "            yu = d.replace(r'$', '')\n",
    "            yu1= yu.replace(r'/hour', '')\n",
    "            yu2 = yu1.replace(r'/daily charge', '')\n",
    "            P.append(yu2) # Now the new\n",
    "\n",
    "        for index,all in enumerate(P):\n",
    "            if \"-\" in all:\n",
    "                ind = index\n",
    "                l = all.split(\"-\")  # Where we find a \"-\" there the values get split \n",
    "                b =list(map(float,l)) \n",
    "                d =np.mean(b) \n",
    "                      # Mean of two values that are seperated is calculated\n",
    "                P[ind] = d          # The mean value is replaced to their respective index\n",
    "        df1=FINAL\n",
    "        df1 = df_column_uniquify(df1)\n",
    "        df1['GC_1']=df1['Gross Charge']\n",
    "\n",
    "        Col_list = list(DF5[\"Columns\"])\n",
    "        df2=df1.melt(id_vars=[col for col in df1 if col in Col_list],var_name=\"name\",value_name='cost')\n",
    "\n",
    "        df2['cost1']=None\n",
    "        df2['cost1']=df2['cost'].str.extract('(\\d+(\\.\\d+)?%)')\n",
    "        df2['cost1']=df2['cost1'].str.strip('%')\n",
    "        df2\n",
    "        df2['cost1']=df2['cost1'].astype(float)\n",
    "        df2['cost1'] = df2['cost1'].div(100)\n",
    "        df2['GC_1']=df2['GC_1'].astype(float)\n",
    "        df2['cost1'] = pd.np.where(df2['cost1'].isnull(), df2['cost'],df2['cost1'])\n",
    "\n",
    "        if k[1]=='5291':\n",
    "            try:\n",
    "                df2.drop(['cost','GC_1'],axis=1,inplace=True)\n",
    "\n",
    "            except:\n",
    "                Search_List = list(DF8[\"Dropping columns\"])\n",
    "\n",
    "                df2.drop(columns=[col for col in df2 if col  in Search_List])\n",
    "\n",
    "        for r in DF6.itertuples(index=False):\n",
    "            df2.rename(columns={r[0]:r[1]}, inplace=True)\n",
    "        df4=df2[df2['cost'].notnull()]\n",
    "        df4[\"cost\"]=df4.cost.astype('str')\n",
    "\n",
    "\n",
    "        L=[] \n",
    "        # for the values in the cost column, where ever $ symbol is present it is replaced with an empty string.\n",
    "        for n in df4['cost']:\n",
    "            yu3 = n.replace(r'$', '')\n",
    "            yu4= yu3.replace(r'/hour', '')\n",
    "    #     yu2 = yu1.replace(r'/daily charge', '')\n",
    "\n",
    "            L.append(yu4) # Now the new\n",
    "\n",
    "        for index,all in enumerate(L):\n",
    "            if \"-\" in all:\n",
    "                ind = index\n",
    "                m = all.split(\"-\")  # Where we find a \"-\" there the values get split \n",
    "                n =list(map(float,m)) \n",
    "                o =np.mean(n)\n",
    "                      # Mean of two values that are seperated is calculated\n",
    "                L[ind] = o         # The mean value is replaced to their respective index\n",
    "        df4['cost']=L\n",
    "\n",
    "\n",
    "\n",
    "        Combined_data.append(df4)\n",
    "    Combined_data = pd.concat(Combined_data)\n",
    "\n",
    "    Combined_data = Combined_data.drop_duplicates()\n",
    "    try:\n",
    "\n",
    "        Combined_data['inpatient-outpatient'] = np.where((Combined_data['inpatient-outpatient'] ==' ') & (Combined_data['name'].str.contains(' ip')) , 'Inpatient', Combined_data['inpatient-outpatient'])\n",
    "        Combined_data['inpatient-outpatient'] = np.where((Combined_data['inpatient-outpatient'] ==' ') & (Combined_data['name'].str.contains(' op')) , 'Outpatient', Combined_data['inpatient-outpatient'])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    output_path = r\"C:\\Users\\User\\Zigna AI Corp\\Zigna AI Corp - RightPx\\Hospital Application_2022-03-09\\Automation_task\\outputs\\Wideformat4_4_{}.csv\"\n",
    "    Combined_data.to_csv(output_path.format(k[1]), index=False)\n",
    "    return Combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "873292d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### wideFormat85 ##############\n",
    "def wideFormat85(CNames):\n",
    "    global df7\n",
    "    \n",
    "    Combined_data = []\n",
    "    combined_final = []\n",
    "    non_prep_data = []\n",
    "\n",
    "    for k in CNames.itertuples(index=False):\n",
    "        f=k[0] \n",
    "        #Checking the file type- xlsx   \n",
    "        if k[2]== 'csv':\n",
    "            try:\n",
    "                DF_FINAL=pd.read_csv(f)\n",
    "            except:\n",
    "                DF_FINAL=pd.read_csv(f,encoding='latin1')\n",
    "\n",
    "            non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        elif k[2]== 'xlsx':\n",
    "            sheet_to = pd.read_excel(f,sheet_name=None,dtype=str,header=None)\n",
    "\n",
    "            for sh in sheet_to.keys():\n",
    "\n",
    "                DF_FINAL = pd.read_excel(f,sheet_name=sh,dtype=str)\n",
    "                print(sh)\n",
    "                non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        for j in df7.itertuples(index=False):\n",
    "            if str(k[1]) == str(j[0]):\n",
    "                s = j[1]\n",
    "\n",
    "        for DF_FINAL in non_prep_data:\n",
    "            try:\n",
    "                if DF_FINAL.iloc[:, [s]].empty == False:\n",
    "\n",
    "\n",
    "                    DF_10 = DF_FINAL.iloc[:,[s]]\n",
    "                    m=0\n",
    "                    c=0\n",
    "\n",
    "\n",
    "                    for index, row in DF_10.iterrows():\n",
    "\n",
    "\n",
    "                        if (pd.notnull(row[0])):                       \n",
    "\n",
    "                            m=m+1\n",
    "                            print(m)\n",
    "                            break\n",
    "                        else:\n",
    "                            c=c+1\n",
    "\n",
    "\n",
    "                    if c==0:\n",
    "\n",
    "                    #This Case works when description is in one row\n",
    "                        if \"Unnamed: 2\" in DF_10:\n",
    "                            DF_FINAL.columns=DF_FINAL.iloc[0]\n",
    "                            FINAL=DF_FINAL.drop([c])\n",
    "                            FINAL['id']=k[1]\n",
    "                            FINAL.dropna(how='all', axis=1, inplace=True)\n",
    "                            for i in FINAL.columns:\n",
    "                                x = str(i).lower().strip()\n",
    "                                FINAL=FINAL.rename(columns= {i:x})\n",
    "\n",
    "                            for i in FINAL.columns.tolist():\n",
    "\n",
    "                                for k in CNames.itertuples(index=False):\n",
    "\n",
    "                                    for r in DF6.itertuples(index=False):\n",
    "\n",
    "                                        if str(k[1]) == str(r[2]):\n",
    "                                            try:\n",
    "\n",
    "                                                for i in FINAL.columns.tolist():\n",
    "\n",
    "                                                    if str(i) == str(r[0]):\n",
    "\n",
    "                                                        FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                                            except:\n",
    "                                                    pass\n",
    "\n",
    "                            for i in FINAL.columns.tolist():\n",
    "                                for r in DF6.itertuples(index=False):\n",
    "                                    if str(r[2]) == \"nan\" :\n",
    "                                        if str(i) == str(r[0]):\n",
    "                                            FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                            combined_final.append(FINAL)\n",
    "\n",
    "                        else:\n",
    "\n",
    "                            #This Case works when description is not found\n",
    "                            FINAL=DF_FINAL\n",
    "                            FINAL['id']=k[1]\n",
    "                            FINAL.dropna(how='all', axis=1, inplace=True)\n",
    "                            for i in FINAL.columns:\n",
    "                                x = str(i).lower().strip()\n",
    "                                FINAL=FINAL.rename(columns= {i:x})\n",
    "\n",
    "                            for i in FINAL.columns.tolist():\n",
    "\n",
    "                                for k in CNames.itertuples(index=False):\n",
    "\n",
    "                                    for r in DF6.itertuples(index=False):\n",
    "\n",
    "                                        if str(k[1]) == str(r[2]):\n",
    "                                            try:\n",
    "\n",
    "                                                for i in FINAL.columns.tolist():\n",
    "\n",
    "                                                    if str(i) == str(r[0]):\n",
    "\n",
    "                                                        FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                                            except:\n",
    "                                                    pass\n",
    "\n",
    "                            for i in FINAL.columns.tolist():\n",
    "                                for r in DF6.itertuples(index=False):\n",
    "                                    if str(r[2]) == \"nan\" :\n",
    "                                        if str(i) == str(r[0]):\n",
    "                                            FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                            combined_final.append(FINAL)\n",
    "\n",
    "\n",
    "\n",
    "                    elif c>=1:\n",
    "\n",
    "                        #This Case works when description is more than 1 row\n",
    "                        #Dropping 'c' rows\n",
    "                        DF_11=DF_FINAL.iloc[c:]\n",
    "                        #row values as column names\n",
    "                        DF_11.columns=DF_11.iloc[0]\n",
    "                        #Dropping the row\n",
    "                        FINAL=DF_11.drop([c])\n",
    "                        FINAL['id']=k[1]\n",
    "                        FINAL.dropna(how='all', axis=1, inplace=True)\n",
    "                        for i in FINAL.columns:\n",
    "                            x = str(i).lower().strip()\n",
    "                            FINAL=FINAL.rename(columns= {i:x})\n",
    "\n",
    "                        for i in FINAL.columns.tolist():\n",
    "\n",
    "                            for k in CNames.itertuples(index=False):\n",
    "\n",
    "                                for r in DF6.itertuples(index=False):\n",
    "\n",
    "                                    if str(k[1]) == str(r[2]):\n",
    "                                        try:\n",
    "\n",
    "                                            for i in FINAL.columns.tolist():\n",
    "\n",
    "                                                if str(i) == str(r[0]):\n",
    "\n",
    "                                                    FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                                        except:\n",
    "                                                pass\n",
    "\n",
    "                        for i in FINAL.columns.tolist():\n",
    "                            for r in DF6.itertuples(index=False):\n",
    "                                if str(r[2]) == \"nan\" :\n",
    "                                    if str(i) == str(r[0]):\n",
    "                                        FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                        combined_final.append(FINAL)\n",
    "\n",
    "\n",
    "                    else:\n",
    "                        None\n",
    "\n",
    "\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass\n",
    "\n",
    "                    #if CNames['ID'].isin(['992331','1898']).any():\n",
    "            #FINAL['Cpt code'].isnull().sum()  \n",
    "            FINAL = pd.concat(combined_final) \n",
    "            FINAL['description'].fillna(method='ffill', inplace=True)\n",
    "            FINAL[\"LineItem_cnt\"] = FINAL.groupby([\"description\"])[\"description\"].transform('count')\n",
    "            FINAL[\"LineItem_cnt\"]=FINAL[\"LineItem_cnt\"]-1\n",
    "            FINAL = FINAL.drop_duplicates(subset=['description'],keep='first')\n",
    "            column_list = ['inpatient-outpatient']\n",
    "            for col in column_list:\n",
    "                if col not in FINAL.columns:\n",
    "                    FINAL[col] = ' '\n",
    "\n",
    "            df2=FINAL\n",
    "            df2 = df_column_uniquify(df2)\n",
    "            #Required format - variable list\n",
    "            Col_list = list(DF5[\"Columns\"])\n",
    "            df3=df2.melt(id_vars=[col for col in df2 if col in Col_list],var_name=\"name\",value_name='cost')\n",
    "            #df3=df1.melt(id_vars=['ID','Description','Cpt Code','Rev_Cd','Units'],var_name=\"Name\",value_name='Cost')\n",
    "\n",
    "            #df3['payer'] = None\n",
    "            #df3['insurance Type'] = None\n",
    "            #df3['Benefit Type']=None\n",
    "\n",
    "            #Name_List = list(DF1[\"Payers\"])\n",
    "\n",
    "            #Name_List1 = list(DF2[\"Insurance Type\"])\n",
    "\n",
    "\n",
    "            #Name_List2 = list(DF3[\"Benefit Type\"])\n",
    "\n",
    "            #Finding Payers from the list\n",
    "            #for i in Name_List:\n",
    "            #    df3['payer'][(df3['name'].str.contains(i,case=False,na=False))] = i\n",
    "            #Finding Insurancetype from the list    \n",
    "            #for j in Name_List1:\n",
    "            #    df3['insurance Type'][(df3['name'].str.contains(j,case=False,na=False))] = j\n",
    "\n",
    "            #Finding Benefit Type from the list  \n",
    "            #for k in Name_List2:\n",
    "            #    df3['Benefit Type'][(df3['name'].str.contains(k,case=False,na=False))] = k \n",
    "\n",
    "            df4=df3\n",
    "            df4=df4[df4['cost'].notnull()]\n",
    "\n",
    "            #Dropping_columns=['Not offered','Not Contracted','N/A','Not a covered service','Not Offered','Not contracted','Not a covered service','N/A']\n",
    "            #df4 = df4[~df4['Cost'].isin(Dropping_columns)]\n",
    "            df4\n",
    "            Combined_data.append(df4)\n",
    "    Combined_data = pd.concat(Combined_data)\n",
    "    Combined_data\n",
    "    #Combined_data[\"id\"]=Combined_data.id.astype('int64')\n",
    "    #Combined_data.dtypes\n",
    "\n",
    "    #Joining both hospital data with shoppable data by ID\n",
    "    #Sample_output=pd.merge(left=DHC_Hosp_data1, right=Combined_data,how='inner',left_on=['Hospital_Id'],right_on=['id'])\n",
    "    Sample_output = Combined_data\n",
    "\n",
    "    Combined_data = Sample_output.drop_duplicates()\n",
    "    try:\n",
    "\n",
    "        Combined_data['inpatient-outpatient'] = np.where((Combined_data['inpatient-outpatient'] ==' ') & (Combined_data['name'].str.contains(' ip')) , 'Inpatient', Combined_data['inpatient-outpatient'])\n",
    "        Combined_data['inpatient-outpatient'] = np.where((Combined_data['inpatient-outpatient'] ==' ') & (Combined_data['name'].str.contains(' op')) , 'Outpatient', Combined_data['inpatient-outpatient'])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "    output_path = r\"C:\\Users\\User\\Zigna AI Corp\\Zigna AI Corp - RightPx\\Hospital Application_2022-03-09\\Automation_task\\outputs\\Wideformat85_{}.csv\"\n",
    "    Combined_data.to_csv(output_path.format(k[1]), index=False)\n",
    "    return Combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fd9b9bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "################## wideFormat86 #################\n",
    "def wideFormat86(CNames):\n",
    "    global df7\n",
    "    \n",
    "    Combined_data = []\n",
    "    combined_final = []\n",
    "    non_prep_data = []\n",
    "\n",
    "    #Getting the details as list from files\n",
    "    for k in CNames.itertuples(index=False):\n",
    "        f=k[0] \n",
    "        #Checking the file type- xlsx   \n",
    "        if k[2]== 'csv':\n",
    "            try:\n",
    "                DF_FINAL=pd.read_csv(f)\n",
    "            except:\n",
    "                DF_FINAL=pd.read_csv(f,encoding='latin1')\n",
    "\n",
    "            non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        elif k[2]== 'xlsx':\n",
    "            sheet_to = pd.read_excel(f,sheet_name=None,dtype=str,header=None)\n",
    "\n",
    "            for sh in sheet_to.keys():\n",
    "\n",
    "                DF_FINAL = pd.read_excel(f,sheet_name=sh,dtype=str)\n",
    "                print(sh)\n",
    "                non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        for j in df7.itertuples(index=False):\n",
    "            if str(k[1]) == str(j[0]):\n",
    "                s = j[1]\n",
    "\n",
    "        for DF_FINAL in non_prep_data:\n",
    "            try:\n",
    "                if DF_FINAL.iloc[:, [s]].empty == False:\n",
    "\n",
    "\n",
    "                    DF_10 = DF_FINAL.iloc[:,[s]]\n",
    "                    m=0\n",
    "                    c=0\n",
    "                                    #Getting the count of  empty rows\n",
    "                    for index, row in DF_10.iterrows():\n",
    "                        if(pd.notnull(row[0])): \n",
    "                            m=m+1\n",
    "                            break\n",
    "                        else:\n",
    "                            c=c+1\n",
    "\n",
    "                    if c==0:\n",
    "                    #This Case works when description is in one row\n",
    "                        if \"Unnamed: 5\" in DF_10:\n",
    "                            DF_FINAL.columns=DF_FINAL.iloc[0]\n",
    "                            FINAL=DF_FINAL.drop([c])\n",
    "                            FINAL['id']=k[1]\n",
    "                            FINAL\n",
    "                        else:\n",
    "                            #This Case works when description is not found\n",
    "                            FINAL=DF_FINAL\n",
    "                            FINAL['id']=k[1]\n",
    "                            FINAL\n",
    "\n",
    "                    elif c>=1:\n",
    "                        #This Case works when description is more than 1 row\n",
    "                        #Dropping 'c' rows\n",
    "\n",
    "                        DF_11=DF_FINAL.iloc[c:]\n",
    "                        #DF_111 = DF_11\n",
    "                        #print(DF_11)\n",
    "\n",
    "                        list1=['CMS-Specified Shoppable Service, Evaluation & Management Services','Shoppable LEVEL OF CARE Service Description','Shoppable DRG Service Description','CMS-Specified Shoppable Service, Laboratory & Pathology Services','CMS-Specified Shoppable Service, Radiology Services','CMS-Specified Shoppable Service, Medicine and Surgery Services']\n",
    "                        DF_11[\"ROW\"] = DF_11.iloc[:,0].isin(list1)\n",
    "                        DF_11= DF_11.reset_index(drop=True)\n",
    "                        n =0\n",
    "                        for index, row in DF_11['ROW'].iteritems():\n",
    "                            if row == True:\n",
    "                                n += 1\n",
    "                                DF_11['ROW'][index] = n\n",
    "                            else:\n",
    "                                DF_11['ROW'][index] = np.nan\n",
    "                                DF_11['ROW'].fillna(method='ffill', inplace=True)\n",
    "                        List_ids=[]\n",
    "                        for i in DF_11['ROW']:\n",
    "                            List_ids.append(i)\n",
    "                            List_ids=list(set(List_ids))\n",
    "                        list2 = []\n",
    "                        for i in List_ids:\n",
    "                            DF = DF_11[DF_11['ROW']==i]\n",
    "                            DF = DF.drop(['ROW'],axis=1)\n",
    "                            DF.columns = DF.iloc[0]\n",
    "                            DF = DF.iloc[1:]\n",
    "                            DF = DF.dropna(how='all',axis=1)\n",
    "                            DF = DF.dropna(how='all',axis=0)\n",
    "                            DF = DF.reset_index(drop=True)\n",
    "                            DF['id']=k[1]\n",
    "\n",
    "                            for i in DF.columns:\n",
    "                                x = str(i).lower().strip()\n",
    "                                DF=DF.rename(columns= {i:x})\n",
    "                            #print(DF_FINAL1.columns)\n",
    "                            for i in DF.columns.tolist():\n",
    "                                for r in DF6.itertuples(index=False):\n",
    "                                    if str(i) == str(r[0]):\n",
    "                                        DF.rename(columns={i:r[1]}, inplace=True)\n",
    "                            list2.append(DF)\n",
    "                        # combined_df.append(list2)\n",
    "                        FINAL = pd.concat(list2)\n",
    "                    else:\n",
    "                        None\n",
    "\n",
    "\n",
    "            except Exception as e:    \n",
    "                print(e)\n",
    "                pass\n",
    "\n",
    "        try:\n",
    "            FINAL = pd.concat(combined_final)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        Search_List = list(DF8[\"Dropping columns\"])\n",
    "        #dropping columns\n",
    "        FINAL= FINAL.drop(columns=[col for col in FINAL if col  in Search_List])\n",
    "\n",
    "\n",
    "        #Checking the  Inpatient/Outpatient column exists or not\n",
    "        column_list = ['inpatient-outpatient']\n",
    "        for col in column_list:\n",
    "            if col not in FINAL.columns:\n",
    "                FINAL[col] = ' '\n",
    "\n",
    "        #Search_List = list(DF3[\"Keeping columns\"])\n",
    "        #Keeping columns\n",
    "        #df1= FINAL.drop(columns=[col for col in FINAL if col not in Search_List])\n",
    "        #Removing the empty rows from'cpt code'\n",
    "        #df2 = df1.dropna(axis=0, subset=['Cpt Code'])\n",
    "        #try:\n",
    "        #    if 'cpt code'=='cpt code':\n",
    "        #        df2=FINAL[FINAL['cpt code'].notnull()] \n",
    "        #    elif 'hcpcs code'=='hcpcs code':\n",
    "        #        df2=FINAL[FINAL['hcpcs code'].notnull()]\n",
    "        #except:\n",
    "        #    None\n",
    "\n",
    "        df2=FINAL  \n",
    "        df2 = df_column_uniquify(df2)\n",
    "        #Required format - variable list\n",
    "        Col_list = list(DF5[\"Columns\"])\n",
    "        df3=df2.melt(id_vars=[col for col in df2 if col in Col_list],var_name=\"name\",value_name='cost')\n",
    "        #df3=df1.melt(id_vars=['ID','Description','Cpt Code','Rev_Cd','Units'],var_name=\"Name\",value_name='Cost')\n",
    "        #df3=df3[df3['name'].notnull()] \n",
    "\n",
    "        #df3['payer'] = None\n",
    "        #df3['insurance Type'] = None\n",
    "        #df3['Benefit Type']=None\n",
    "\n",
    "        #Name_List = list(DF1[\"Payers\"])\n",
    "\n",
    "        #Name_List1 = list(DF2[\"Insurance Type\"])\n",
    "\n",
    "        #Name_List2 = list(DF3[\"Benefit Type\"])\n",
    "\n",
    "        #Finding Payers from the list\n",
    "        #for i in Name_List:\n",
    "        #    df3['payer'][(df3['name'].str.contains(i,case=False,na=False))] = i\n",
    "        #Finding Insurancetype from the list    \n",
    "        #for j in Name_List1:\n",
    "        #    df3['insurance Type'][(df3['name'].str.contains(j,case=False,na=False))] = j\n",
    "\n",
    "        #Finding Benefit Type from the list  \n",
    "        #for k in Name_List2:\n",
    "        #    df3['Benefit Type'][(df3['name'].str.contains(k,case=False,na=False))] = k  \n",
    "\n",
    "        df4=df3\n",
    "        df4=df4[df4['cost'].notnull()]\n",
    "        df4=df4[df4['name'].notnull()]\n",
    "        #df4=df4[df4['Cpt code'].notnull()]\n",
    "        #Dropping_columns=['Not offered','Not Contracted','N/A','Not a covered service','Not Offered','Not contracted','Not a covered service','N/A']\n",
    "        #df4 = df4[~df4['Cost'].isin(Dropping_columns)]\n",
    "        df4\n",
    "        Combined_data.append(df4)\n",
    "    Combined_data = pd.concat(Combined_data)\n",
    "\n",
    "    Combined_data = Combined_data.drop_duplicates()\n",
    "    #Combined_data[\"id\"]=Combined_data.id.astype('int64')\n",
    "    #Combined_data.dtypes\n",
    "    Sample_output = Combined_data\n",
    "    #Joining both hospital data with shoppable data by ID\n",
    "    #Sample_output=pd.merge(left=DHC_Hosp_data1, right=Combined_data,how='inner',left_on=['Hospital_Id'],right_on=['id'])\n",
    "\n",
    "    #Dropping the columns\n",
    "    #Sample_output.drop([\"id\"], axis = 1, inplace = True)\n",
    "    Sample_output['inpatient-outpatient'] = np.where((Sample_output['inpatient-outpatient'] ==' ') & (Sample_output['name'].str.contains(' ip')) , 'Inpatient', Sample_output['inpatient-outpatient'])\n",
    "    Sample_output['inpatient-outpatient'] = np.where((Sample_output['inpatient-outpatient'] ==' ') & (Sample_output['name'].str.contains(' op')) , 'Outpatient', Sample_output['inpatient-outpatient'])\n",
    "    #Sample_output['inpatient-outpatient'] = np.where((Sample_output['inpatient-outpatient'] ==' ') & (Sample_output['name'].str.contains(' ip')) , 'Inpatient', Sample_output['inpatient-outpatient'])\n",
    "    Sample_output['inpatient-outpatient'] = np.where((Sample_output['inpatient-outpatient'] ==' ') & (Sample_output['name'].str.contains(' op')) , 'Outpatient', Sample_output['inpatient-outpatient'])\n",
    "    Sample_output['inpatient-outpatient'] = np.where((Sample_output['inpatient-outpatient'] ==' ') & (Sample_output['name'].str.contains('inpatient')) , 'Inpatient', Sample_output['inpatient-outpatient'])\n",
    "    Sample_output['inpatient-outpatient'] = np.where((Sample_output['inpatient-outpatient'] ==' ') & (Sample_output['name'].str.contains('outpatient')) , 'Outpatient', Sample_output['inpatient-outpatient'])\n",
    "\n",
    "    output_path = r\"C:\\Users\\User\\Zigna AI Corp\\Zigna AI Corp - RightPx\\Hospital Application_2022-03-09\\Automation_task\\outputs\\Wideformat86_{}.csv\"\n",
    "    Sample_output.to_csv(output_path.format(k[1]), index=False)\n",
    "    return Sample_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8e1d610b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### wideFormat99 #################\n",
    "def wideFormat99(CNames):\n",
    "    global df7\n",
    "    \n",
    "    Combined_data = []\n",
    "    combined_final = []\n",
    "    non_prep_data = []\n",
    "\n",
    "    #Getting the details as list from files\n",
    "    for k in CNames.itertuples(index=False):\n",
    "        f=k[0] \n",
    "        #Checking the file type- xlsx   \n",
    "        if k[2]== 'csv':\n",
    "            try:\n",
    "                DF_FINAL=pd.read_csv(f)\n",
    "            except:\n",
    "                DF_FINAL=pd.read_csv(f,encoding='latin1')\n",
    "\n",
    "            non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        elif k[2]== 'xlsx':\n",
    "            sheet_to = pd.read_excel(f,sheet_name=None,dtype=str,header=None)\n",
    "\n",
    "            for sh in sheet_to.keys():\n",
    "\n",
    "                DF_FINAL = pd.read_excel(f,sheet_name=sh,dtype=str)\n",
    "                print(sh)\n",
    "                non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        for j in df7.itertuples(index=False):\n",
    "            if str(k[1]) == str(j[0]):\n",
    "                s = j[1]\n",
    "\n",
    "        for DF_FINAL in non_prep_data:\n",
    "            try:\n",
    "                if DF_FINAL.iloc[:, [s]].empty == False:\n",
    "\n",
    "\n",
    "                    DF_10 = DF_FINAL.iloc[:,[s]]\n",
    "                    m=0\n",
    "                    c=0\n",
    "\n",
    "\n",
    "                    for index, row in DF_10.iterrows():\n",
    "\n",
    "\n",
    "                        if (pd.notnull(row[0])):                       \n",
    "\n",
    "                            m=m+1\n",
    "                            print(m)\n",
    "                            break\n",
    "                        else:\n",
    "                            c=c+1\n",
    "\n",
    "\n",
    "                    if c==0:\n",
    "\n",
    "                    #This Case works when description is in one row\n",
    "                        if \"Unnamed: 2\" in DF_10:\n",
    "                            DF_FINAL.columns=DF_FINAL.iloc[0]\n",
    "                            FINAL=DF_FINAL.drop([c])\n",
    "                            FINAL['id']=k[1]\n",
    "                            FINAL.dropna(how='all', axis=1, inplace=True)\n",
    "                            FINAL\n",
    "\n",
    "                        else:\n",
    "\n",
    "                            #This Case works when description is not found\n",
    "                            FINAL=DF_FINAL\n",
    "                            FINAL['id']=k[1]\n",
    "                            FINAL.dropna(how='all', axis=1, inplace=True)\n",
    "                            FINAL\n",
    "\n",
    "                    elif c>=1:\n",
    "\n",
    "                        #This Case works when description is more than 1 row\n",
    "                        #Dropping 'c' rows\n",
    "                        DF_11=DF_FINAL.iloc[c:]\n",
    "                        #row values as column names\n",
    "                        DF_11.columns=DF_11.iloc[0]\n",
    "                        #Dropping the row\n",
    "                        FINAL=DF_11.drop([c])\n",
    "                        FINAL['id']=k[1]\n",
    "                        FINAL.dropna(how='all', axis=1, inplace=True)\n",
    "                        FINAL\n",
    "\n",
    "\n",
    "                    else:\n",
    "                        None\n",
    "\n",
    "\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass\n",
    "            FINAL[\"Code Type1\"] = FINAL['Code Type'].str.contains('Charge')\n",
    "            column_list = ['Code1']\n",
    "            for col in column_list:\n",
    "                if col not in FINAL.columns:\n",
    "                    FINAL[col] = ' '\n",
    "            FINAL[\"Code1\"]= np.where((FINAL[\"Code Type1\"].apply(lambda x:x==False)), FINAL['Code'].apply(lambda x: x.split(\" \", 1)[0]),FINAL[\"Code1\"])\n",
    "            FINAL[\"description\"]= np.where((FINAL[\"Code Type1\"].apply(lambda x:x==False)), FINAL['Description'], 'nan')\n",
    "\n",
    "            FINAL['description'] = FINAL['description'].replace('nan', np.nan, regex=True)\n",
    "            FINAL['Code1'] = FINAL['Code1'].replace(' ', np.nan, regex=True)\n",
    "\n",
    "            FINAL['description'].fillna(method='ffill', inplace=True,axis=0)\n",
    "            FINAL['Code1'].fillna(method='ffill', inplace=True,axis=0)\n",
    "\n",
    "            FINAL.drop(['Code Type','Description','Code','Notes/Disclaimer','Code Type1'],axis=1,inplace = True)\n",
    "\n",
    "            all_columns = list(FINAL)\n",
    "            #FINAL[all_columns] = FINAL[all_columns].replace('\\$|,', '', regex=True)\n",
    "            cols=[i for i in FINAL.columns if i not in ['id','Code1', 'description']]\n",
    "\n",
    "            for col in cols:\n",
    "                FINAL[col] = pd.to_numeric(FINAL[col], errors='coerce')\n",
    "\n",
    "            #FINAL = FINAL.drop_duplicates(keep='first', inplace=False)\n",
    "\n",
    "\n",
    "            FINAL[\"LineItem_cnt\"] = FINAL.groupby([\"Code1\",\"description\"])[\"Code1\"].transform('count')\n",
    "            FINAL[\"LineItem_cnt\"]=FINAL[\"LineItem_cnt\"]-1\n",
    "\n",
    "            FINAL=FINAL.groupby(['id','Code1', 'description','LineItem_cnt']).aggregate(['sum']).reset_index()\n",
    "            FINAL.columns = FINAL.columns.get_level_values(0)\n",
    "            FINAL   \n",
    "\n",
    "\n",
    "\n",
    "            for i in FINAL.columns:\n",
    "                x = str(i).lower().strip()\n",
    "                FINAL=FINAL.rename(columns= {i:x})\n",
    "\n",
    "            for i in FINAL.columns.tolist():\n",
    "\n",
    "                for k in CNames.itertuples(index=False):\n",
    "\n",
    "                    for r in DF6.itertuples(index=False):\n",
    "\n",
    "                        if str(k[1]) == str(r[2]):\n",
    "                            try:\n",
    "\n",
    "                                for i in FINAL.columns.tolist():\n",
    "\n",
    "                                    if str(i) == str(r[0]):\n",
    "\n",
    "                                        FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                            except:\n",
    "                                    pass\n",
    "\n",
    "            for i in FINAL.columns.tolist():\n",
    "                for r in DF6.itertuples(index=False):\n",
    "                    if str(r[2]) == \"nan\" :\n",
    "                        if str(i) == str(r[0]):\n",
    "                            FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "\n",
    "            Search_List = list(DF8[\"Dropping columns\"])\n",
    "            #dropping columns\n",
    "            FINAL= FINAL.drop(columns=[col for col in FINAL if col  in Search_List])\n",
    "\n",
    "            FINAL=FINAL.rename(columns = {'code1': \"CPT/HCPCS/DRG\"}) \n",
    "\n",
    "           #Checking the  Inpatient/Outpatient column exists or not\n",
    "            column_list = ['inpatient-outpatient']\n",
    "            for col in column_list:\n",
    "                if col not in FINAL.columns:\n",
    "                    FINAL[col] = ' '\n",
    "\n",
    "        #Search_List = list(DF3[\"Keeping columns\"])\n",
    "        #Keeping columns\n",
    "        #df1= FINAL.drop(columns=[col for col in FINAL if col not in Search_List])\n",
    "        #Removing the empty rows from'cpt code'\n",
    "        #df2 = df1.dropna(axis=0, subset=['Cpt Code'])\n",
    "        #try:\n",
    "        #    if 'cpt code'=='cpt code':\n",
    "        #        df2=FINAL[FINAL['cpt code'].notnull()] \n",
    "        #    elif 'hcpcs code'=='hcpcs code':\n",
    "        #        df2=FINAL[FINAL['hcpcs code'].notnull()]\n",
    "        #except:\n",
    "        #    None\n",
    "\n",
    "            df2=FINAL\n",
    "            df2 = df_column_uniquify(df2)\n",
    "           #Required format - variable list\n",
    "            Col_list = list(DF5[\"Columns\"])\n",
    "            df3=df2.melt(id_vars=[col for col in df2 if col in Col_list],var_name=\"name\",value_name='cost')\n",
    "           #df3=df1.melt(id_vars=['ID','Description','Cpt Code','Rev_Cd','Units'],var_name=\"Name\",value_name='Cost')\n",
    "            df3=df3[df3['name'].notnull()] \n",
    "\n",
    "           #df3['payer'] = None\n",
    "           #df3['insurance Type'] = None\n",
    "           #df3['Benefit Type']=None\n",
    "\n",
    "           #Name_List = list(DF1[\"Payers\"])\n",
    "\n",
    "            #Name_List1 = list(DF2[\"Insurance Type\"])\n",
    "\n",
    "            #Name_List2 = list(DF3[\"Benefit Type\"])\n",
    "\n",
    "            #Finding Payers from the list\n",
    "            #for i in Name_List:\n",
    "            #    df3['payer'][(df3['name'].str.contains(i,case=False,na=False))] = i\n",
    "            #Finding Insurancetype from the list    \n",
    "            #for j in Name_List1:\n",
    "            #    df3['insurance Type'][(df3['name'].str.contains(j,case=False,na=False))] = j\n",
    "\n",
    "            #Finding Benefit Type from the list  \n",
    "            #for k in Name_List2:\n",
    "            #    df3['Benefit Type'][(df3['name'].str.contains(k,case=False,na=False))] = k  \n",
    "\n",
    "            df4=df3\n",
    "            df4[\"cost\"] = df4[\"cost\"].replace('',np.nan)\n",
    "\n",
    "            df4=df4[df4['cost'].notnull()]\n",
    "            #Dropping_columns=['Not offered','Not Contracted','N/A','Not a covered service','Not Offered','Not contracted','Not a covered service','N/A']\n",
    "            #df4 = df4[~df4['Cost'].isin(Dropping_columns)]\n",
    "            df4\n",
    "            Combined_data.append(df4)\n",
    "    Combined_data = pd.concat(Combined_data)\n",
    "\n",
    "    #Combined_data[\"id\"]=Combined_data.id.astype('int64')\n",
    "    #Combined_data.dtypes\n",
    "    Sample_output = Combined_data\n",
    "\n",
    "    Combined_data = Sample_output.drop_duplicates()\n",
    "    try:\n",
    "\n",
    "        Combined_data['inpatient-outpatient'] = np.where((Combined_data['inpatient-outpatient'] ==' ') & (Combined_data['name'].str.contains(' ip')) , 'Inpatient', Combined_data['inpatient-outpatient'])\n",
    "        Combined_data['inpatient-outpatient'] = np.where((Combined_data['inpatient-outpatient'] ==' ') & (Combined_data['name'].str.contains(' op')) , 'Outpatient', Combined_data['inpatient-outpatient'])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "    output_path = r\"C:\\Users\\User\\Zigna AI Corp\\Zigna AI Corp - RightPx\\Hospital Application_2022-03-09\\Automation_task\\outputs\\Wideformat99_{}.csv\"\n",
    "    Combined_data.to_csv(output_path.format(k[1]), index=False)\n",
    "    return Combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3795a620",
   "metadata": {},
   "outputs": [],
   "source": [
    "################# wideFormat18_1 #################\n",
    "def wideFormat18_1(CNames):\n",
    "    global df7\n",
    "    \n",
    "    Combined_data = []\n",
    "    combined_final = []\n",
    "    non_prep_data = []\n",
    "    #Getting the details as list from files\n",
    "    for k in CNames.itertuples(index=False):\n",
    "        f=k[0] \n",
    "        #Checking the file type- xlsx   \n",
    "        if k[2]== 'csv':\n",
    "            try:\n",
    "                DF_FINAL=pd.read_csv(f)\n",
    "            except:\n",
    "                DF_FINAL=pd.read_csv(f,encoding='latin1')\n",
    "\n",
    "\n",
    "        elif k[2]== 'xlsx':\n",
    "            sheet_to = pd.read_excel(f,sheet_name=None,dtype=str)\n",
    "\n",
    "            for sh in sheet_to.keys():\n",
    "\n",
    "                DF_FINAL = pd.read_excel(f,sheet_name=sh,dtype=str)\n",
    "                print(sh)\n",
    "\n",
    "\n",
    "                non_prep_data.append(DF_FINAL)\n",
    "\n",
    "        for j in df2.itertuples(index=False):\n",
    "            if str(k[1]) == str(j[0]):\n",
    "                s = j[1]\n",
    "\n",
    "\n",
    "\n",
    "        for DF_FINAL in non_prep_data:\n",
    "\n",
    "\n",
    "            try:\n",
    "                if DF_FINAL.iloc[:, [s]].empty == False:\n",
    "\n",
    "\n",
    "                    DF_10 = DF_FINAL.iloc[:,[s]]\n",
    "                    m=0\n",
    "                    c=0\n",
    "\n",
    "            #Getting the count of  empty rows\n",
    "                for index, row in DF_10.iterrows():\n",
    "                    if(pd.notnull(row[0])): \n",
    "                        m=m+1\n",
    "                        break\n",
    "                    else:\n",
    "                        c=c+1\n",
    "\n",
    "                if c==0:\n",
    "                #This Case works when description is in one row\n",
    "                    if \"Unnamed: 2\" in DF_10:\n",
    "                        DF_FINAL.columns=DF_FINAL.iloc[0]\n",
    "                        FINAL=DF_FINAL.drop([c])\n",
    "                        FINAL['id']=k[1]\n",
    "                        FINAL\n",
    "                    else:\n",
    "                        #This Case works when description is not found\n",
    "                        FINAL=DF_FINAL\n",
    "                        FINAL['id']=k[1]\n",
    "                        FINAL\n",
    "\n",
    "                elif c>=1:\n",
    "                    #This Case works when description is more than 1 row\n",
    "                    #Dropping 'c' rows\n",
    "                    DF_11=DF_FINAL.iloc[c:]\n",
    "                    #row values as column names\n",
    "                    DF_11.columns=DF_11.iloc[0]\n",
    "                    #Dropping the row\n",
    "                    FINAL=DF_11.drop([c])\n",
    "                    FINAL['id']=k[1]\n",
    "                else:\n",
    "                    None \n",
    "\n",
    "        #Checking the file type- csv\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass\n",
    "        for i in FINAL.columns:\n",
    "\n",
    "            x = str(i).lower().strip()\n",
    "            FINAL=FINAL.rename(columns= {i:x})\n",
    "\n",
    "        for i in FINAL.columns.tolist():\n",
    "\n",
    "            for k in CNames.itertuples(index=False):\n",
    "\n",
    "                for r in DF6.itertuples(index=False):\n",
    "\n",
    "                    if str(k[1]) == str(r[2]):\n",
    "                        try:\n",
    "\n",
    "                            for i in FINAL.columns.tolist():\n",
    "\n",
    "                                if str(i) == str(r[0]):\n",
    "\n",
    "                                    FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "                        except:\n",
    "                                pass\n",
    "\n",
    "        for i in FINAL.columns.tolist():\n",
    "            for r in DF6.itertuples(index=False):\n",
    "                if str(r[2]) == \"nan\" :\n",
    "                    if str(i) == str(r[0]):\n",
    "                        FINAL.rename(columns={i:r[1]}, inplace=True)\n",
    "\n",
    "         # FINAL.drop([\"CPT/HCPCS\",\"DESCRIPTION\"], axis = 1, inplace = True)\n",
    "         #FINAL\n",
    "        Search_List = list(DF8[\"Dropping columns\"])\n",
    "            #dropping columns\n",
    "\n",
    "        FINAL= FINAL.drop(columns=[col for col in FINAL if col in Search_List])\n",
    "        column_list = ['inpatient_outpatient']\n",
    "        for col in column_list:\n",
    "            if col not in FINAL.columns:\n",
    "                FINAL[col] = ' '\n",
    "\n",
    "        FINAL['billing_code'].fillna(method='ffill', inplace=True)\n",
    "        try:\n",
    "\n",
    "            FINAL=FINAL[FINAL['procedure_chargenumber'].notnull()]\n",
    "        except:\n",
    "            pass\n",
    "        FINAL[\"LineItem_cnt\"] = FINAL.groupby(\"billing_code\")[\"billing_code\"].transform('count')\n",
    "        FINAL[\"LineItem_cnt\"]=FINAL[\"LineItem_cnt\"]-1\n",
    "\n",
    "        try:\n",
    "\n",
    "            FINAL=FINAL[(FINAL[\"LineItem_cnt\"] ==0) | ((FINAL[\"LineItem_cnt\"] >=1) & (FINAL[\"procedure_chargenumber\"].str.contains(\"CLAIM\",case=False))) ]\n",
    "            FINAL         \n",
    "            #FINAL=FINAL[(FINAL[\"Primary Service and Ancillary Service\"].str.contains(\"CLAIM\",case=False))]\n",
    "            #FINAL         \n",
    "            FINAL.drop([\"procedure_chargenumber\"], axis = 1, inplace = True)        \n",
    "        except:\n",
    "            pass\n",
    "        #Search_List = list(DF3[\"Keeping columns\"])\n",
    "        #Keeping columns\n",
    "        #df1= FINAL.drop(columns=[col for col in FINAL if col not in Search_List])\n",
    "        #Removing the empty rows from'cpt code'\n",
    "        #df2 = df1.dropna(axis=0, subset=['Cpt Code'])\n",
    "\n",
    "        #df2=FINAL[FINAL['cpt code'].notnull()] \n",
    "\n",
    "        df2=FINAL\n",
    "        df2 = df_column_uniquify(df2)\n",
    "        #Required format - variable list\n",
    "        Col_list = list(DF5[\"Columns\"])\n",
    "        df3=df2.melt(id_vars=[col for col in df2 if col in Col_list],var_name=\"name\",value_name='cost')\n",
    "        #df3=df1.melt(id_vars=['ID','Description','Cpt Code','Rev_Cd','Units'],var_name=\"Name\",value_name='Cost')\n",
    "\n",
    "        #df3['payer'] = None\n",
    "        #df3['insurance Type'] = None\n",
    "        #df3['Benefit Type']=None\n",
    "\n",
    "        #Name_List = list(DF1[\"Payers\"])\n",
    "\n",
    "        #Name_List1 = list(DF2[\"Insurance Type\"])\n",
    "\n",
    "        #Name_List2 = list(DF3[\"Benefit Type\"])\n",
    "\n",
    "        #Finding Payers from the list\n",
    "        #for i in Name_List:\n",
    "        #    df3['payer'][(df3['name'].str.contains(i,case=False,na=False))] = i\n",
    "        #Finding Insurancetype from the list    \n",
    "        #for j in Name_List1:\n",
    "        #    df3['insurance Type'][(df3['name'].str.contains(j,case=False,na=False))] = j\n",
    "\n",
    "        #Finding Benefit Type from the list  \n",
    "        #for k in Name_List2:\n",
    "        #    df3['Benefit Type'][(df3['name'].str.contains(k,case=False,na=False))] = k \n",
    "\n",
    "        df4=df3\n",
    "        df4=df4[df4['cost'].notnull()]\n",
    "        #Dropping_columns=['Not offered','Not Contracted','N/A','Not a covered service','Not Offered','Not contracted','Not a covered service','N/A']\n",
    "        #df4 = df4[~df4['Cost'].isin(Dropping_columns)]\n",
    "        df4\n",
    "        Combined_data.append(df4)\n",
    "    Combined_data = pd.concat(Combined_data)\n",
    "\n",
    "    Combined_data\n",
    "    output_path = r\"C:\\Users\\User\\Zigna AI Corp\\Zigna AI Corp - RightPx\\Hospital Application_2022-03-09\\Automation_task\\outputs\\Wideformat18_1_{}.csv\"\n",
    "    Combined_data.to_csv(output_path.format(k[1]), index=False)\n",
    "    return Combined_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
