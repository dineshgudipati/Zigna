# -*- coding: utf-8 -*-
"""
Created on Tue Jul  4 12:38:41 2023

@author: si736338
"""

import requests
from datetime import date, timedelta
import os
import zipfile
import pandas as pd
import numpy as np
import yaml
import datetime

import psycopg2
import logging

# 

#def yammer_extraction_api():
    try:
    
        with open('config.yaml', 'r') as file:
            config = yaml.safe_load(file)
            # return config
        
        
        # Connect to the Greenplum database
        conn = psycopg2.connect(
            host=config['host'],
            port=config['port'],
            database=config['database'],
            user=config['user'],
            password=config['password'],
        )
        
        cursor = conn.cursor()
        
        query = 'select * from sor_yammer.ctl_yammer'
        cursor.execute(query)
        results = cursor.fetchall()
        reference = pd.DataFrame(results)
        column_names = [desc[0] for desc in cursor.description]
        reference.columns = column_names
        
        
        # List of table names
        table_names = ['tags', 'Groups', 'Messages', 'Topics', 'Users']
        
        # Initialize the oldest date
        oldest_date = None
        
        # Iterate over the table names and retrieve the maximum date for each table
        for table_name in table_names:
            query = f'select max("dateto") from sor_yammer.{table_name}'
            cursor.execute(query)
            result = cursor.fetchone()[0]
            
            if result is not None:
                result_date = datetime.datetime.strptime(str(result)[:10], '%Y-%m-%d').date()
                if oldest_date is None or result_date < oldest_date:
                    oldest_date = result_date
        
        # Close the cursor and connection
        cursor.close()
        conn.close()
        
        
        end_date = date.today()
        start_date = oldest_date 
        
        # Bearer token for authentication
        bearer_token = config['yammer_token']
        # bearer_token = '39881-WpJ9XayUXeK6IVXSnvHg'
        
        # Specify your desired output path
        output_path = config['output_directory']
        
        # Specify the CSV files to extract from each zip file
        files_to_extract = ['Groups.csv', 'Tags.csv', 'Topics.csv']
        
        since_date = start_date
        to_date = end_date
        
        url = f"https://www.yammer.com/api/v1/export?since={since_date}&until={to_date}"
        headers = {
            "Authorization": f"Bearer {bearer_token}"
        }
        
        response = requests.get(url, headers=headers, verify=False)
        
        # Save the response content as a zip file
        zip_filename = f"output_{to_date}.zip"
        zip_filepath = os.path.join(output_path, zip_filename)
        
        
        
        with open(zip_filepath, 'wb') as f:
            f.write(response.content)
        
        print(f"Zip file saved: {zip_filepath}")
        
        
       
        
        # ...
        
        with zipfile.ZipFile(zip_filepath, 'r') as zip_file:
            for file_to_extract in files_to_extract:
                if file_to_extract in zip_file.namelist():
                    # Read the file from the zip without extracting it
                    with zip_file.open(file_to_extract) as file:
                        # Read the extracted CSV file into a DataFrame
                        df = pd.read_csv(file)
                        
                   # Strip the ".csv" extension from the file name for matching with the reference
                    file_to_match = file_to_extract.replace('.csv', '')
                    
                    # Get the entity columns for the current file from the reference file
                    entity_columns = reference_df.loc[reference_df['File name'] == file_to_match]['entity columns'].values[0]
                    entity_columns = [col.strip() for col in entity_columns.split(',')]
                    
                    # Select the columns present in both the DataFrame and the entity columns
                    selected_columns = [col for col in entity_columns if col in df.columns]
                    
        
                    # Add new columns to the DataFrame
                    df['DateFrom'] = since_date
                    df['DateTo'] = to_date
                    df['ctl_ins_ts'] =  datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    df["ctl_elt_job_id"] = np.nan
                    df["ctl_src_cd"] = "yammer"
                    df["src_filename".upper()] = f"{file_to_extract.split('.')[0]}_{since_date}.csv"
                    df['src_line_no'] = df.index
                    for column_name in column_names:
                        df[column_name.upper()] = np.nan
                    # Save the DataFrame to a new CSV file
                    new_file_name = f"{file_to_extract.split('.')[0]}_{to_date}.csv"
                    new_file_path = os.path.join(output_path, new_file_name)
                    df.to_csv(new_file_path, index=False)
        
                    print(f"Modified CSV file saved: {new_file_path}")
                else:
                    print(f"Skipping {file_to_extract} - File not found in the zip file.")
        
        # Delete the zip file
        os.remove(zip_filepath)
        print(f"Zip file deleted: {zip_filepath}")
    except Exception as e:
    # Log the error message
        error_message = str(e)
        logging.error("An error occurred during data retrieval and processing: %s", error_message)
        raise Exception("An error occurred during data retrieval and processing: " + error_message)
