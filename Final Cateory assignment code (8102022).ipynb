{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b407b43",
   "metadata": {},
   "source": [
    "importing required packages & Reading files from folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d85d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "### importing required libraries...............\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import numpy as np\n",
    "import xlwings as xw\n",
    "from xlwings import Range, constants\n",
    "import time\n",
    "from datetime import datetime\n",
    "# from fuzzywuzzy import fuzz\n",
    "# from fuzzywuzzy import process\n",
    "\n",
    "#Get the List of files from path\n",
    "os.chdir(r\"D:\\Zigna AI Corp\\Zigna AI Corp - Hospital Application_2022-03-09\\21 files\")\n",
    "\n",
    "path = os.getcwd()\n",
    "files = os.listdir(path)\n",
    "#List of Files \n",
    "mylinks=[]\n",
    "for l in files:\n",
    "    l\n",
    "    mylinks.append(l)\n",
    "mylinks  \n",
    "\n",
    "cols=['FILE_NAMES']\n",
    "#Creating the dataframe\n",
    "CNames=pd.DataFrame(mylinks,columns=cols)\n",
    "CNames\n",
    "\n",
    "#extracting ids and type of file from CNames dataframe\n",
    "CNames[['ID']]=CNames.FILE_NAMES.str.extract('(\\d+)')\n",
    "CNames['Type'] = CNames.FILE_NAMES.str.split('.',expand=True)[1]\n",
    "CNames\n",
    "CNames['Errors'] = \"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a15b0b5",
   "metadata": {},
   "source": [
    "Readign files and doing all preprocessing techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a831ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_final1 = []\n",
    "combined_data= []\n",
    "dataframe = []\n",
    "count = 0\n",
    "raw = []\n",
    "start = time.time()\n",
    "for k in CNames.itertuples(index = False):\n",
    "    f = k[0]\n",
    "    combined_final = []\n",
    "    if k[2] == 'csv':\n",
    "        try:\n",
    "            df =pd.read_csv(f)\n",
    "            df['Hospital_Id'] = k[1]\n",
    "            dataframe.append(df)\n",
    "        except:\n",
    "            df=pd.read_csv(f,encoding='latin1')\n",
    "            df['Hospital_Id'] = k[1]\n",
    "            dataframe.append(df)\n",
    "            \n",
    "    elif k[2] == 'xlsx':\n",
    "        df = pd.read_excel(f)\n",
    "        df['Hospital_Id'] = k[1]\n",
    "        dataframe.append(df)\n",
    "    else:\n",
    "        None\n",
    "    \n",
    "    df1 = df.columns\n",
    "    df2 = pd.Series(df1)\n",
    "    raw_colnames = df2.to_frame(name=\"Columns\")\n",
    "    raw_colnames['ID'] = k[1]\n",
    "    \n",
    "    ################################   cleaing raw column names array          ###################################\n",
    "    # raw_colnames['Columns'] = raw_colnames['Columns'].str.replace('#' ,'nmbr')\n",
    "    raw_colnames['Columns'] = raw_colnames['Columns'].map(lambda x: str(x.lower().strip()))\n",
    "    raw_colnames['Columns'] = raw_colnames['Columns'].str.replace('[^\\w\\s]',' ')\n",
    "    raw_colnames['Columns'] = raw_colnames['Columns'].str.replace('_',' ')\n",
    "    raw_colnames['Columns'] = raw_colnames['Columns'].str.replace(' +', ' ')        \n",
    "    raw_colnames['Columns'] = raw_colnames['Columns'].str.replace('\\n', ' ')        \n",
    "    raw_colnames['Category'] = np.nan\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b5d273",
   "metadata": {},
   "source": [
    "Passing through the exceptions(hospital id & sheet name), cost column strings and exclude strings on the raw columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a880137",
   "metadata": {},
   "outputs": [],
   "source": [
    "    for j in exceptions_str:\n",
    "        raw_colnames['Category'] = np.where((raw_colnames['Columns'] == j), raw_colnames['Columns'], raw_colnames['Category'])\n",
    "    \n",
    "    cost_list = pd.read_excel(r\"D:\\Copy of Json Renaming Local.xlsx\",sheet_name='name')\n",
    "    cost_list1 = cost_list['Cost_columns']\n",
    "    cost_str = [item for item in cost_list1 if not(pd.isna(item)) == True]\n",
    "    \n",
    "    exclude_list = cost_list['Exclude']\n",
    "    exclude_str = [item for item in exclude_list if not(pd.isna(item)) == True]\n",
    "    \n",
    "    ##########################  mapping with cost strings with string contains and exclude list   ###########################\n",
    "    for x in cost_str:\n",
    "        raw_colnames['Category'] = np.where((raw_colnames['Columns'].str.contains(x)), \"name\", raw_colnames['Category'])\n",
    "    \n",
    "    for e in exclude_str:\n",
    "        raw_colnames['Category'] = np.where((raw_colnames['Columns'].str.contains(e)), np.nan, raw_colnames['Category'])\n",
    "    \n",
    "    ################################################################################################################\n",
    "    ######################taking mapped columns and appending into list  #############################################\n",
    "    cost_mappings = raw_colnames[raw_colnames['Category'].notnull()]\n",
    "    cost_mappings['type'] = 'cost strings mapping'\n",
    "    combined_final.append(cost_mappings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a25ad64",
   "metadata": {},
   "source": [
    "doing Hard match for unmapped columns with lookup values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9642ae5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #########################################   Hard Match  ##########################################################\n",
    "    raw_colnames1 = raw_colnames[raw_colnames['Category'].isnull()]\n",
    "    for (colname,colval) in patterns.iteritems():\n",
    "        colvalue = [item for item in colval if not(pd.isna(item)) == True]\n",
    "        for index,j in raw_colnames1['Columns'].iteritems():\n",
    "            if pd.isnull(raw_colnames1['Category'][index]):\n",
    "                try:                \n",
    "                    Sheet = [ele for ele in colvalue if(ele == j)][0]\n",
    "                    raw_colnames1['Category'][index] = colname\n",
    "                except:\n",
    "                    None\n",
    "    #################################################################################################################\n",
    "    Unmap_columns = raw_colnames1[raw_colnames1['Category'].isnull()]\n",
    "    col_list = Unmap_columns['Columns'].values.tolist()\n",
    "    Unmapped_columns1 = pd.Series(col_list)\n",
    "\n",
    "    map_columns = raw_colnames1[raw_colnames1['Category'].notnull()]\n",
    "    map_columns['type'] = 'Hard Match'\n",
    "    combined_final.append(map_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb97da7",
   "metadata": {},
   "source": [
    "Taking unmapped columns from the above steps and doing patterns with three conditions like\n",
    "    Mapping by adding trailing and leading underscores.\n",
    "    Mapping by adding leading underscore \n",
    "    Mapping by adding trailing underscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0138cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "################# cleaning unmapped columns cleaning for patterns match  ########################################\n",
    "    Unmap_columns['Columns'] = Unmap_columns['Columns'].str.replace('[^\\w\\s]','_')\n",
    "    Unmap_columns['Columns'] = Unmap_columns['Columns'].map(lambda x: '_' + str(x.lower().strip()) + '_')\n",
    "    Unmap_columns['Columns'] = Unmap_columns['Columns'].str.replace(\" \", \"_\")\n",
    "    Unmap_columns['Columns'] = Unmap_columns['Columns'].str.replace('_+', '_')\n",
    "    \n",
    "    ######################  adding leading $ trailing underscores for pattern match  ################################\n",
    "    patterns1 = patterns.copy()\n",
    "    for u in patterns1.columns:\n",
    "        patterns1[u] = patterns1[u].astype('str')\n",
    "        patterns1[u] = patterns1[u].str.strip()\n",
    "        patterns1[u] = patterns1[u].str.lower()\n",
    "    \n",
    "    for v in patterns1.columns:\n",
    "        patterns1[v] = patterns1[v].map(lambda x: '_' + x + '_')\n",
    "        patterns1[v] = patterns1[v].map(lambda x: str(x.replace(\" \", \"_\")))\n",
    "        patterns1[v] = patterns1[v].str.replace('_+', '_')\n",
    "    ###############################################################################################################\n",
    "    \n",
    "    ################  patterns match with trailing & leading underscores  #########################################\n",
    "    colnum = pd.read_excel(r\"D:\\Copy of Json Renaming Local.xlsx\",sheet_name='column_namelist')\n",
    "    for (colname,colval) in patterns1.iteritems():\n",
    "        colvalue = [item for item in colval if not(pd.isna(item)) == True or item == '_nan_']\n",
    "        for index,j in Unmap_columns['Columns'].iteritems():\n",
    "            if pd.isnull(Unmap_columns['Category'][index]):\n",
    "                try:\n",
    "                    Sheet = [ele for ele in colvalue if(ele in j)][0]\n",
    "                    Unmap_columns['Category'][index] = colname\n",
    "                except:\n",
    "                    None\n",
    "                    \n",
    "    ############################################################################################################\n",
    "    \n",
    "    #####################  patterns match with only trailing underscore  ##########################################\n",
    "    # Mapping by adding leading underscore    \n",
    "    patterns2 = patterns.copy()\n",
    "    for u in patterns2.columns:\n",
    "        patterns2[u] = patterns2[u].astype('str')\n",
    "        patterns2[u] = patterns2[u].str.strip()\n",
    "        patterns2[u] = patterns2[u].str.lower()\n",
    "    \n",
    "    for v in patterns2.columns:\n",
    "        patterns2[v] = patterns2[v].map(lambda x: '_' + x)\n",
    "        patterns2[v] = patterns2[v].map(lambda x: str(x.replace(\" \", \"_\")))\n",
    "        patterns2[v] = patterns2[v].str.replace('_+', '_')\n",
    "    \n",
    "    for (colname,colval) in patterns2.iteritems():\n",
    "        colvalue = [item for item in colval if not(pd.isna(item)) == True or item == '_nan']\n",
    "        for index,j in Unmap_columns['Columns'].iteritems():\n",
    "            if pd.isnull(Unmap_columns['Category'][index]):\n",
    "                try:\n",
    "                    Sheet = [ele for ele in colvalue if(ele in j)][0]\n",
    "                    Unmap_columns['Category'][index] = colname\n",
    "                except:\n",
    "                    None\n",
    "    ##################################################################################################################\n",
    "\n",
    "    ################  patterns match with only leading underscore  ###############################################\n",
    "    #Mapping by adding trailing underscore.\n",
    "    patterns3 = patterns.copy()\n",
    "    for u in patterns3.columns:\n",
    "        patterns3[u] = patterns3[u].astype('str')\n",
    "        patterns3[u] = patterns3[u].str.strip()\n",
    "        patterns3[u] = patterns3[u].str.lower()\n",
    "    \n",
    "    for v in patterns3.columns:\n",
    "        patterns3[v] = patterns3[v].str.replace(' +', ' ')\n",
    "        patterns3[v] = patterns3[v].map(lambda x: x + '_')\n",
    "        patterns3[v] = patterns3[v].map(lambda x: str(x.replace(\" \", \"_\")))\n",
    "        patterns3[v] = patterns3[v].str.replace('_+', '_')\n",
    "    \n",
    "    for (colname,colval) in patterns3.iteritems():\n",
    "        colvalue = [item for item in colval if not(pd.isna(item)) == True or item == 'nan_']\n",
    "        for index,j in Unmap_columns['Columns'].iteritems():\n",
    "            if pd.isnull(Unmap_columns['Category'][index]):\n",
    "                try:\n",
    "                    Sheet = [ele for ele in colvalue if(ele in j)][0]\n",
    "                    Unmap_columns['Category'][index] = colname\n",
    "                except:\n",
    "                    None  \n",
    "    ################################################################################################################## \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae08fbad",
   "metadata": {},
   "source": [
    "Modifier check: checking for the fourth character it should be(I/_/numeric) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dd2d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "    Unmap_columns = Unmap_columns.reset_index(drop=True)\n",
    "    ############################## modifier exception   #########################################################\n",
    "    for index, x in Unmap_columns['Category'].iteritems():\n",
    "        if x == 'modifier':\n",
    "            raw_name = Unmap_columns['Columns'][index]\n",
    "            \n",
    "            s = (raw_name.split(\"mod\",1)[1])[0]\n",
    "            \n",
    "            if s == '_' or s == 'i' or s.isdigit():\n",
    "                Unmap_columns['Category'][index] = 'modifier'\n",
    "            else:\n",
    "                Unmap_columns['Category'][index] = 'name'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c195960",
   "metadata": {},
   "source": [
    "Data type check for (inpatient-outpatient, payer name, benefit type): By raw column datatype and top 100 values check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521c3f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "    df.columns = df.columns.str.replace('[^\\w\\s]','_')\n",
    "    df.columns = df.columns.map(lambda x: '_' + str(x.lower().strip()) + '_')\n",
    "    df.columns = df.columns.str.replace('\\n', ' ')        \n",
    "    df.columns = df.columns.str.replace(\" \", \"_\")\n",
    "    df.columns = df.columns.str.replace('_+', '_')\n",
    "    ########################taking sub dataframe with 500 rows    ##############################################################\n",
    "    \n",
    "    # if df.shape[0] > 500:\n",
    "    #     df1 = df.iloc[:500,:]\n",
    "    # else:\n",
    "        # df1 = df\n",
    "\n",
    "    #################  type check list (ip-op, payername, benefit type)   ########################################\n",
    "    \n",
    "    Dtype_list = pd.read_excel(r\"D:\\Copy of Json Renaming Local.xlsx\",sheet_name='Dtype check list')\n",
    "    Dtype_str = Dtype_list['Category']   \n",
    "    \n",
    "    ###########################  type check code for above 3 categories   #####################################################\n",
    "    for x in Dtype_str:\n",
    "        for index, j in Unmap_columns['Category'].iteritems():\n",
    "            if j == x:\n",
    "                column = df[Unmap_columns['Columns'][index]].to_frame()\n",
    "                column = column.dropna(axis = 0,inplace = False)\n",
    "                column = column.drop_duplicates()\n",
    "                   \n",
    "                column1 = column.head(500)\n",
    "                column1 = column1.astype(str)\n",
    "                try:\n",
    "                    column1[Unmap_columns['Columns'][index]] = column1[Unmap_columns['Columns'][index]].str.replace('*', ' ')\n",
    "                    column1[Unmap_columns['Columns'][index]] = column1[Unmap_columns['Columns'][index]].str.replace('$', ' ')\n",
    "                except:\n",
    "                    column1[Unmap_columns['Columns'][index]] = column1[Unmap_columns['Columns'][index]].str.replace('$', ' ')\n",
    "                    \n",
    "                else:\n",
    "                    column1[Unmap_columns['Columns'][index]] = column1[Unmap_columns['Columns'][index]].str.replace('*', ' ')\n",
    "                    \n",
    "                try:\n",
    "                    column1[Unmap_columns['Columns'][index]] = column1[Unmap_columns['Columns'][index]].str.strip()\n",
    "                except:\n",
    "                    None\n",
    "                    \n",
    "                for index1, a in column1[Unmap_columns['Columns'][index]].iteritems():\n",
    "                    try:\n",
    "                        a1 = float(a)\n",
    "                        column1[Unmap_columns['Columns'][index]][index1] = a1\n",
    "                    except:\n",
    "                        None\n",
    "                        \n",
    "                if df[Unmap_columns['Columns'][index]].dtypes == object and len([ele for ele in column1[Unmap_columns['Columns'][index]] if pd.isna(ele) == False and type(ele) != str]) == 0:\n",
    "                    Unmap_columns['Category'][index] = Unmap_columns['Category'][index]\n",
    "                elif df[Unmap_columns['Columns'][index]].dtypes == object and len([ele for ele in column1[Unmap_columns['Columns'][index]] if pd.isna(ele) == False and type(ele) != str]) > 0:\n",
    "                    Unmap_columns['Category'][index] = 'name'\n",
    "                else:\n",
    "                    Unmap_columns['Category'][index] = 'name'\n",
    "            else:\n",
    "                None\n",
    "                \n",
    "    patt_map_columns = Unmap_columns[Unmap_columns['Category'].notnull()]\n",
    "    patt_map_columns['type'] = 'patterns match'\n",
    "    combined_final.append(patt_map_columns)\n",
    "    \n",
    "    patt_unmap_columns = Unmap_columns[Unmap_columns['Category'].isnull()]\n",
    "    col_list = patt_unmap_columns['Columns'].values.tolist()\n",
    "    patt_unmap_columns['Category'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feae0757",
   "metadata": {},
   "source": [
    "By taking remaining unmapped columns from the above steps we are doing fuzzy match algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e629b73",
   "metadata": {},
   "source": [
    "fuzzy match algorithm: fuzz token sort ratio with 80% threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a2fba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "  ####################################### fuzzy match   ############################################################\n",
    "    myList1 = patt_unmap_columns['Columns'].tolist()\n",
    "    \n",
    "    for i in patterns.columns:\n",
    "        myList2 = [item for item in patterns[i] if not(item == '_nan_' or pd.isna(item) == True)]\n",
    "        threshold = 80\n",
    "        match1 = []\n",
    "        \n",
    "        for x in myList1:\n",
    "            match1.append(process.extractOne(x, myList2, scorer=fuzz.token_sort_ratio))\n",
    "        \n",
    "        patt_unmap_columns['matches'] = match1\n",
    "        \n",
    "        for index, j in patt_unmap_columns['matches'].iteritems():\n",
    "            if j[1] >= threshold:\n",
    "                if pd.isnull(patt_unmap_columns['Category'][index]):\n",
    "                    patt_unmap_columns['Category'][index] = i\n",
    "    \n",
    "    fuzz_map_columns = patt_unmap_columns[patt_unmap_columns['Category'].notnull()]\n",
    "    fuzz_map_columns['type'] = 'fuzz match'\n",
    "    combined_final.append(fuzz_map_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1651d082",
   "metadata": {},
   "source": [
    "Making all unmapped columns into name category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decf2975",
   "metadata": {},
   "outputs": [],
   "source": [
    "    ###########  Final unmapped columns into name category  ##########################################################\n",
    "    fuzz_unmap_columns = patt_unmap_columns[patt_unmap_columns['Category'].isnull()]\n",
    "    fuzz_unmap_columns = fuzz_unmap_columns.drop(['matches'], axis=1)\n",
    "    fuzz_unmap_columns['Category'] = np.where(fuzz_unmap_columns['Category'].isnull() , 'name', fuzz_unmap_columns['Category'])\n",
    "    fuzz_unmap_columns['type'] = 'Final name'\n",
    "    ####################################################################################################################    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c105cf5",
   "metadata": {},
   "source": [
    "Various checks in final name category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c45c414",
   "metadata": {},
   "source": [
    "inpatient outpatient category check in final name category by passing inpatient outpatient lookup values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283928b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "  #########  mapping with inpatient outpatient lookup values in final name category  ###############################\n",
    "    ipop_list = pd.read_excel(r\"D:\\Copy of Json Renaming Local.xlsx\",sheet_name='inpatient-outpatient')\n",
    "    ipop_str = ipop_list['ipop_columns']   \n",
    "    ipop_str = ipop_str.str.replace('_' , ' ')\n",
    "    ipop_str = ipop_str.str.strip()\n",
    "    \n",
    "    # df1 = df.copy()\n",
    "    # df1 = df1.dropna(axis=\"columns\", how=\"any\")\n",
    "    \n",
    "    fuzz_unmap_columns = fuzz_unmap_columns.reset_index(drop= True)\n",
    "    for index,j in fuzz_unmap_columns['Columns'].iteritems():\n",
    "        print(df[j])\n",
    "        column = df[j].to_frame()\n",
    "        column = column.dropna(axis = 0,inplace = False)\n",
    "        column = column.drop_duplicates()\n",
    "        for v in column.columns:\n",
    "            column[v] = column[v].astype(str)\n",
    "            column[v] = column[v].str.lower()\n",
    "            \n",
    "        column1 = column.head(20)\n",
    "        column1 = column1.astype(str)\n",
    "        for k in ipop_str:\n",
    "            for i in column1[j]:\n",
    "                # print(i)\n",
    "                if str(i)==str(k):\n",
    "                    print(True)\n",
    "                    print(column1[j])\n",
    "                    fuzz_unmap_columns['Category'][index] = 'inpatient_outpatient'\n",
    "            else:\n",
    "                None\n",
    "                \n",
    "    #################################################################################################################\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593b51e5",
   "metadata": {},
   "source": [
    "Import all reqrired filles (reference tables and stop word ref files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc65b90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "    #############################  importing all required reference files  ################################################\n",
    "    df1 = pd.read_excel(r\"D:\\Zigna AI Corp\\Zigna AI Corp - Hospital Application_2022-03-09\\Structured files\\Code library\\Codes\\Consumer Friendly Descriptors.xlsx\")\n",
    "    df1['CPT Code'] = df1['CPT Code'].apply(lambda x: str(x).zfill(5))\n",
    "    \n",
    "    df2=pd.read_excel(r\"D:\\Zigna AI Corp\\Zigna AI Corp - Hospital Application_2022-03-09\\Structured files\\Code library\\Codes\\HCPC codes till 9.27.2021.xlsx\")\n",
    "    df3=pd.read_excel(r\"D:\\Zigna AI Corp\\Zigna AI Corp - Hospital Application_2022-03-09\\Structured files\\Code library\\Codes\\MS DRG 2008-2022.xlsx\", dtype = str)\n",
    "    df3['CODE'] = df3['CODE'].apply(lambda x: str(x).zfill(3))\n",
    " \n",
    "    df4=pd.read_excel(r\"D:\\Zigna AI Corp\\Zigna AI Corp - Hospital Application_2022-03-09\\Structured files\\Code library\\Codes\\APR DRG-2018-07-01_final_weights.xlsx\", skiprows = 2)\n",
    "    df4['APR-DRG'] = df4['APR-DRG'].apply(lambda x: str(x).zfill(4))\n",
    "    df5=pd.read_excel(r\"D:\\Zigna AI Corp\\Zigna AI Corp - Hospital Application_2022-03-09\\Structured files\\Code library\\Codes\\PCS master excel upto 2022.xlsx\")\n",
    "    \n",
    "    ####################################################################################################################\n",
    "    stopword_ref = r\"D:\\Zigna AI Corp\\Zigna AI Corp - Hospital Application_2022-03-09\\Structured files\\Code library\\Codes\\stopword_ref_file.xlsx\"\n",
    "    sw_ref = pd.read_excel(stopword_ref)# This dataframe has all the values that to be stripped out from the code columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a248c7",
   "metadata": {},
   "source": [
    "In final name category, if category is name then we are going check with reference tables by taking top 100 raw column values and if the 50 % of the values matches with the any one of the reference tables then those columns will assigned to procedure codes.\n",
    "Hierarchy of the check:\n",
    "    By Taking the top 100rows (excluding nan's and dropping duplicates) from the raw column  \n",
    "\n",
    "    We are mapping these 100 values with reference tables \n",
    "\n",
    "    Process we followed: \n",
    "\n",
    "    First, we have created empty columns like cpt,hcpcs,drg,aprdrg,icd for storing mapped codes from the refernce tables. \n",
    "\n",
    "    Fixed the length of refernce tables like for cpt (length 5),drg(length 3),aprdrg(length 4). \n",
    "\n",
    "    And mapped the raw columns with the refernce tables. \n",
    "\n",
    "    If any of the above 5 columns are filled with mapped values, then it will be assigned to 'procedure code' category. \n",
    "\n",
    "    out of 100 rows if any of the 50 rows matches with reference tables then only it will be assigned as procedure code. \n",
    "\n",
    "    After the above check also, we added some conditions in file level, those are briefed below. \n",
    "\n",
    "    Case1: \n",
    "\n",
    "            Here we are considering other than the final name category (i.e., Hard match, patterns match and fuzzy match) if it has procedure code assigned to any of the columns, then we will check in final name category. \n",
    "\n",
    "            for procedure code assigned columns, if the procedure codes are assigned to more than 1 column then, we will assign it as cost column or else it will remain same. \n",
    "\n",
    "    Case 2: \n",
    "\n",
    "            if Hard match, patterns match and fuzzy match does not have any procedure code assigned category then we will check in final name assigned procedure code category, if the procedure codes in final name is equal to 1, then we will assign it as procedure code, or else all the columns in final name category will fall into name category. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44865ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "   #####################################  mappping with reference tables  ##############################################\n",
    "    for index,j in fuzz_unmap_columns['Category'].iteritems():\n",
    "        if str(j) == 'name':\n",
    "            # print(True)\n",
    "            column = df[fuzz_unmap_columns['Columns'][index]].to_frame()\n",
    "            column = column.dropna(axis = 0,inplace = False)\n",
    "            column = column.drop_duplicates()\n",
    "            column2 = column.head(100)\n",
    "            column2 = column2.astype(str)\n",
    "            # column2 = column2.len(5)\n",
    "            column2=column2.replace('\\.0', '', regex=True)\n",
    "            \n",
    "            #Passing the list of unnecessary  strings to remove from the codes like CPT,MS,APR etc......\n",
    "            p = re.compile('|'.join(map(re.escape, list(sw_ref[\"strings\"].astype(str))))) # escape to handle metachars\n",
    "            for i in column2.columns:\n",
    "                column2[i] = column2[i].astype(str)                 # Making the values into strings in all the code columns\n",
    "                column2[i] = column2[i].str.encode('ascii', 'ignore').str.decode('ascii')  # If any ascii characters are present they are encoded and then decoded immediately. So the special characters are cleaned up\n",
    "                column2[i] = [p.sub('', s) for s in column2[i]]     # substitutes the matching strings from p with ''\n",
    "                column2[i] = column2[i].astype(str)                 # Making the values into strings in all the code columns\n",
    "                column2[i] = column2[i].str.strip()                 # strips out any spaces in the values\n",
    "                # Data3[i] = Data3[i].replace('\\.0', '', regex=True) # remove .0 from codes if exists\n",
    "                column2[i] = column2[i].map(lambda x: re.sub(r'\\W+', '', x)) # Removing special characters if we have any in the code columns\n",
    "\n",
    "            \n",
    "            column2[fuzz_unmap_columns['Columns'][index]] = column2[fuzz_unmap_columns['Columns'][index]].apply(lambda x: x[:5])\n",
    "            \n",
    "            # column1 = column1.str.strip()\n",
    "            for v in column2.columns:\n",
    "                column2[v] = column2[v].str.strip()\n",
    "                \n",
    "            column2[['cpt', 'hcpcs', 'drg', 'apr', 'icd']] = np.nan\n",
    "            \n",
    "            #getting all mapped codes\n",
    "            FINAL = pd.merge(column2,df1['CPT Code'],how='left',left_on=fuzz_unmap_columns['Columns'][index],right_on='CPT Code')\n",
    "            FINAL['cpt'] = np.where(FINAL['cpt'].isnull(), FINAL['CPT Code'], FINAL['cpt'])\n",
    "            FINAL.drop('CPT Code', axis= 1, inplace=True)\n",
    "            FINAL1 = FINAL.copy()\n",
    "            \n",
    "            FINAL= pd.merge(column2,df2['HCPC'],how='left',left_on=fuzz_unmap_columns['Columns'][index],right_on='HCPC')\n",
    "            FINAL1['hcpcs'] = np.where(FINAL1['hcpcs'].isnull(), FINAL['HCPC'], FINAL1['hcpcs'])\n",
    "            FINAL.drop('HCPC', axis= 1, inplace=True)\n",
    "\n",
    "            df3['CODE'] = df3['CODE'].astype(str)\n",
    "            FINAL = pd.merge(column2,df3['CODE'],how='left',left_on=fuzz_unmap_columns['Columns'][index],right_on='CODE')\n",
    "            FINAL1['drg'] = np.where(FINAL1['drg'].isnull(), FINAL['CODE'], FINAL1['drg'])\n",
    "            FINAL.drop('CODE', axis= 1, inplace=True)\n",
    "            \n",
    "            df4['APR-DRG'] = df4['APR-DRG'].astype(str)\n",
    "            FINAL = pd.merge(column2,df4['APR-DRG'],how='left',left_on=fuzz_unmap_columns['Columns'][index],right_on='APR-DRG')\n",
    "            FINAL1['apr'] = np.where(FINAL1['apr'].isnull(), FINAL['APR-DRG'], FINAL1['apr'])\n",
    "            FINAL.drop('APR-DRG', axis= 1, inplace=True)\n",
    "            \n",
    "            FINAL = pd.merge(column2,df5['ICD 10 PCS'],how='left',left_on=fuzz_unmap_columns['Columns'][index],right_on='ICD 10 PCS')\n",
    "            FINAL1['icd'] = np.where(FINAL1['icd'].isnull(), FINAL['ICD 10 PCS'], FINAL1['icd'])\n",
    "            FINAL.drop('ICD 10 PCS', axis= 1, inplace=True)\n",
    "            \n",
    "            FINAL1[\"count\"] = FINAL1.iloc[:,-5:].count(axis=1)\n",
    "            \n",
    "            # s = [ele for ele in FINAL1['count'] if ele >0] \n",
    "            if len([ele for ele in FINAL1['count'] if ele >0]) >50:\n",
    "                fuzz_unmap_columns['Category'][index] = 'procedure code'\n",
    "                \n",
    "    ################################################################################################################\n",
    "    combined_final.append(fuzz_unmap_columns)\n",
    "    uni_id = pd.concat(combined_final)\n",
    "    # a = a.drop_duplicates()\n",
    "    uni_id = uni_id.reset_index(drop=True)\n",
    "    uni_id.drop('matches', axis = 1, inplace = True)\n",
    "\n",
    "    ############# logic for procedure code exceptions in final name category ###############################\n",
    "    test = []\n",
    "    test1 = []\n",
    "\n",
    "    for k in uni_id.itertuples(index = False):\n",
    "        # print(k)\n",
    "        if k[3] != 'Final name':\n",
    "            if k[2] == 'procedure code':\n",
    "                test.append(k[2])\n",
    "                \n",
    "    for k in uni_id.itertuples(index = False):\n",
    "        # print(k)\n",
    "        if k[3] == 'Final name':\n",
    "            if k[2] == 'procedure code':\n",
    "                test1.append(k[2])\n",
    "                \n",
    "    if len(test) > 0 and len(test1) >1:\n",
    "        print(len(test))\n",
    "        for index,k in uni_id['type'].iteritems():\n",
    "            if k == 'Final name' and uni_id['Category'][index] == 'procedure code':\n",
    "                uni_id['Category'][index] = 'name'      #          k[2] = 'name'\n",
    "            else:\n",
    "                None\n",
    "                \n",
    "    elif len(test) == 0 and len(test1) > 2:\n",
    "        for index,k in uni_id['type'].iteritems():\n",
    "            if k == 'Final name' and uni_id['Category'][index] == 'procedure code':\n",
    "                uni_id['Category'][index] = 'name'      #          k[2] = 'name'\n",
    "            else:\n",
    "                None\n",
    "    else:\n",
    "        None\n",
    "    #####################################################################################################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821f08b4",
   "metadata": {},
   "source": [
    "Finally we are updating the lookup tables with columns mapped in (Patterns match & Fuzzy match & corrected categories in final name category.\n",
    "For that we are using column_namelist sheet and appending through loop at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546d4f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "   ####### mapped column in patterns match Updation into lookup tables ########################################\n",
    "    \n",
    "    colcount = 0\n",
    "    for i in patterns.columns:\n",
    "        for r, index1 in colnum['Number'].iteritems():\n",
    "            if r == colcount:\n",
    "                ass = colnum['col name'][index1]\n",
    "                print(ass)\n",
    "        arr = []\n",
    "        for index, g in uni_id['Category'].iteritems():\n",
    "            # print(g)\n",
    "            if i == g:\n",
    "                print(True)\n",
    "                arr.append(uni_id['Columns'][index])\n",
    "            else:\n",
    "                None\n",
    "        if len(arr) > 0:\n",
    "            Mapped_names= pd.Series(arr)\n",
    "            app = xw.App(visible=False)\n",
    "            wb = xw.Book(r\"C:\\Users\\User\\Downloads\\Copy of Json Renaming Local.xlsx\")\n",
    "            a = wb.sheets[0].range(str(ass) + str(wb.sheets[0].cells.last_cell.row)).end('up').row\n",
    "            sheet = wb.sheets[\"cleaned\"]                                  \n",
    "            sheet.range(str(ass) +'' + str(a+1)).options(index=False).value = Mapped_names\n",
    "            wb.save()\n",
    "            wb.close()\n",
    "            app.quit()\n",
    "        else:\n",
    "            None\n",
    "        colcount += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636e2d2b",
   "metadata": {},
   "source": [
    "Need to check the final name category and if we have incorrect mappings we need to do manual mappings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89dc6b7",
   "metadata": {},
   "source": [
    "Writing into an csv file for manual check into the same raw file folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea7a561",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #######################################################################################################################\n",
    "    combined_final1.append(uni_id)\n",
    "    end = time.time()\n",
    "\n",
    "Final_Cate = pd.concat(combined_final1)\n",
    "\n",
    "Final_Cate.to_csv(r'Category assignmentoutput.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
